# ğŸ¯ Insights da ComparaÃ§Ã£o de Algoritmos - Dataset CICIoT2023
## AnÃ¡lise Baseada em 270 Experimentos (3M+ samples)

**Data:** 17 de outubro de 2025  
**Fonte:** Resultados consolidados (old/1760364824_consolidation2/)  
**ConfiguraÃ§Ã£o:** 9 algoritmos Ã— 10 configs Ã— 3 runs = 270 experimentos  

---

## ğŸ“Š **1. PERFORMANCE vs CUSTO COMPUTACIONAL**

### ğŸ† Top 3 Performance (F1-Score)

| Rank | Algoritmo | F1-Score | Tempo | Relative Speed |
|------|-----------|----------|-------|----------------|
| ğŸ¥‡ | **GradientBoosting** | 99.65% | 17.5h | 1Ã— (baseline) |
| ğŸ¥ˆ | **RandomForest** | 99.64% | 4.9h | **3.5Ã— mais rÃ¡pido** |
| ğŸ¥‰ | **LogisticRegression** | 99.35% | 16min | **64Ã— mais rÃ¡pido** |

### ğŸ’¡ **INSIGHT PRINCIPAL**

> **RandomForest oferece 99.98% da performance do GradientBoosting com apenas 28% do tempo!**
>
> - DiferenÃ§a de F1: 0.01% (praticamente idÃªntico)
> - DiferenÃ§a de tempo: 12.6h (3.5Ã— mais rÃ¡pido)
> - **ConclusÃ£o**: GradientBoosting nÃ£o justifica o custo em produÃ§Ã£o

---

## âš¡ **2. ALGORITMOS ULTRARRÃPIDOS PARA IoT**

### ğŸš€ Top 3 Velocidade

| Rank | Algoritmo | Tempo | F1-Score | EficiÃªncia (F1/s) |
|------|-----------|-------|----------|-------------------|
| ğŸ¥‡ | **SGDOneClassSVM** | 36s (0.6min) | 99.05% | **0.0275** |
| ğŸ¥ˆ | **IsolationForest** | 317s (5min) | 98.94% | 0.0031 |
| ğŸ¥‰ | **SGDClassifier** | 358s (6min) | 99.33% | 0.0028 |

### ğŸ’¡ **INSIGHT PARA IoT/EDGE**

> **SGDClassifier** Ã© **1.750Ã— mais rÃ¡pido que GradientBoosting** perdendo apenas **0.32% F1-Score**.
>
> - Tempo: 6 minutos vs 17.5 horas
> - Performance: 99.33% vs 99.65%
> - **ViÃ¡vel para treinamento em edge/fog nodes!**

---

## ğŸ¯ **3. BALANCED ACCURACY: REVELANDO O PROBLEMA**

### âš ï¸ DESCOBERTA CRÃTICA: Dataset Desbalanceado

**Dataset CICIoT2023:**
- 97.7% trÃ¡fego malicioso
- 2.3% trÃ¡fego benigno

**ComparaÃ§Ã£o: Accuracy vs Balanced Accuracy**

| Algoritmo | Accuracy | Balanced Acc | **GAP** | ClassificaÃ§Ã£o |
|-----------|----------|--------------|---------|---------------|
| **LinearSVC** | 98.7% | 84.9% | **13.8%** | ğŸ”´ CrÃ­tico |
| **SGDClassifier** | 98.7% | 82.6% | **16.1%** | ğŸ”´ CrÃ­tico |
| **LogisticRegression** | 98.7% | 85.1% | **13.6%** | ğŸ”´ CrÃ­tico |
| **GradientBoosting** | 99.3% | 91.7% | 7.6% | ğŸŸ¡ Moderado |
| **RandomForest** | 99.3% | 91.5% | 7.8% | ğŸŸ¡ Moderado |
| **EllipticEnvelope** | 98.0% | 93.2% | 4.8% | ğŸŸ¢ Bom |
| **SGDOneClassSVM** | 98.2% | 96.9% | **1.3%** | ğŸŸ¢ Excelente |

### ğŸ’¡ **INSIGHT CRÃTICO**

> **Algoritmos lineares** (LogReg, LinearSVC, SGD) **sacrificam classe minoritÃ¡ria** (benigna) para maximizar accuracy geral.
>
> **Anomaly detection dedicada** (SGDOneClassSVM, EllipticEnvelope) **protege melhor a classe benigna!**
>
> **ImplicaÃ§Ã£o prÃ¡tica:** 
> - LinearSVC com 98.7% accuracy parece Ã³timo
> - MAS detecta apenas 84.9% do trÃ¡fego benigno corretamente
> - **13.8% dos pacotes benignos sÃ£o marcados como ataques!**

---

## ğŸ“ˆ **4. TRADE-OFF PERFORMANCE Ã— TEMPO Ã— CONTEXTO IoT**

### ğŸ–ï¸ RecomendaÃ§Ãµes por CenÃ¡rio

| CenÃ¡rio IoT | Algoritmo Recomendado | F1-Score | Tempo | Justificativa |
|-------------|----------------------|----------|-------|---------------|
| **Edge Devices** | SGDOneClassSVM | 99.05% | 36s | Tempo real + Melhor BA (96.9%) |
| **Fog Nodes** | IsolationForest | 98.94% | 5min | Stream processing + RÃ¡pido |
| **Gateway** | LogisticRegression | 99.35% | 16min | Balanceado + InterpretÃ¡vel |
| **Edge Servers** | SGDClassifier | 99.33% | 6min | RÃ¡pido + Online learning |
| **Cloud (Batch)** | RandomForest | 99.64% | 4.9h | Top performance + ViÃ¡vel |
| **Research Only** | GradientBoosting | 99.65% | 17.5h | Baseline (nÃ£o produÃ§Ã£o) |

### ğŸ’¡ **INSIGHT: SWEET SPOT IoT**

> Existe um **"sweet spot" entre 90s-1000s** (1.5-17min) onde algoritmos entregam **>99.3% F1** com **viabilidade IoT**!
>
> **Algoritmos nessa faixa:**
> - LogisticRegression (16min): 99.35% F1
> - SGDClassifier (6min): 99.33% F1
> - IsolationForest (5min): 98.94% F1
>
> **Trade-off Ã³timo:** Tempo de treinamento aceitÃ¡vel + Performance competitiva

---

## ğŸ”¬ **5. CONSISTÃŠNCIA E REPRODUTIBILIDADE**

### ğŸ“Š Variabilidade entre ConfiguraÃ§Ãµes

| Algoritmo | Best F1 | Mean F1 | **DiferenÃ§a** | ClassificaÃ§Ã£o |
|-----------|---------|---------|---------------|---------------|
| **LinearSVC** | 99.34% | 99.34% | **0.00%** | ğŸŸ¢ Muito Consistente |
| **LogisticRegression** | 99.35% | 99.34% | **0.01%** | ğŸŸ¢ Muito Consistente |
| **RandomForest** | 99.64% | 99.60% | 0.04% | ğŸŸ¢ Consistente |
| **GradientBoosting** | 99.65% | 99.59% | 0.06% | ğŸŸ¢ Consistente |
| **LocalOutlierFactor** | 99.09% | 98.96% | 0.13% | ğŸŸ¡ Moderado |
| **IsolationForest** | 98.94% | 90.87% | **8.07%** | ğŸ”´ Altamente InstÃ¡vel |

### ğŸ’¡ **INSIGHT: PRODUÃ‡ÃƒO vs PESQUISA**

> **IsolationForest** Ã© **altamente instÃ¡vel**: VariaÃ§Ã£o de 8% no F1 entre configuraÃ§Ãµes!
>
> - Best config: 98.94% F1 âœ…
> - Worst config: ~83% F1 âŒ
> - **Causa provÃ¡vel:** Sensibilidade extrema ao parÃ¢metro `contamination`
>
> **RecomendaÃ§Ã£o:**
> - âœ… Usar para pesquisa/exploraÃ§Ã£o
> - âŒ Evitar em produÃ§Ã£o sem tuning cuidadoso
> - âœ… Alternativa: Ensemble de mÃºltiplos IsolationForests

---

## ğŸ¯ **6. PONTOS A PESQUISAR (PRÃ“XIMOS PASSOS)**

### ğŸ“Œ Prioridade ALTA

#### **6.1. Por que LinearSVC/SGD sacrificam classe minoritÃ¡ria?**

**ObservaÃ§Ã£o:**
- LinearSVC: GAP de 13.8% (Acc: 98.7%, BA: 84.9%)
- SGDClassifier: GAP de 16.1% (Acc: 98.7%, BA: 82.6%)

**HipÃ³teses:**
1. FunÃ§Ã£o de loss otimiza accuracy global, nÃ£o balanced
2. Class imbalance (97.7% vs 2.3%) domina o gradiente
3. Default threshold (0.5) nÃ£o Ã© adequado para dados desbalanceados

**Experimentos propostos:**
- âœ… Testar `class_weight='balanced'`
- âœ… Ajustar threshold de decisÃ£o (threshold tuning)
- âœ… Comparar loss functions (hinge vs log-loss)
- âœ… Testar over/under-sampling (SMOTE, RandomUnderSampler)

**ReferÃªncias:**
- Chawla et al. (2002): SMOTE for imbalanced datasets
- Japkowicz & Stephen (2002): Class imbalance problem
- He & Garcia (2009): Learning from imbalanced data

---

#### **6.2. RandomForest como alternativa viÃ¡vel ao GradientBoosting?**

**HipÃ³tese:**
- RandomForest = 99.98% da performance com 28% do tempo
- DiferenÃ§a: 0.01% F1-Score
- Economiza: 12.6 horas de treinamento

**Experimentos propostos:**
- âœ… Testar em deployment real (latÃªncia de inferÃªncia)
- âœ… Medir uso de memÃ³ria (RF tende a usar mais RAM)
- âœ… Comparar interpretabilidade (feature importance)
- âœ… Avaliar robustez a drift (concept drift)

**Trade-offs a investigar:**
- **Tempo de treinamento:** RF 3.5Ã— mais rÃ¡pido âœ…
- **Tempo de inferÃªncia:** RF pode ser mais lento â“
- **MemÃ³ria:** RF armazena mÃºltiplas Ã¡rvores â“
- **ParalelizaÃ§Ã£o:** RF naturalmente paralelo âœ…

**ReferÃªncias:**
- Breiman (2001): Random Forests (paper original)
- FernÃ¡ndez-Delgado et al. (2014): Do we need hundreds of classifiers?

---

#### **6.3. SGDOneClassSVM: Melhor Balanced Accuracy, mas F1 inferior**

**ObservaÃ§Ã£o paradoxal:**
- SGDOneClassSVM: BA = 96.9% (melhor), F1 = 99.05%
- GradientBoosting: BA = 91.7%, F1 = 99.65% (melhor)

**AnÃ¡lise:**
```
SGDOneClassSVM:
â”œâ”€ Detecta melhor trÃ¡fego benigno (classe minoritÃ¡ria)
â”œâ”€ Menos False Negatives (benigno â†’ malicioso)
â””â”€ Mas: F1 ligeiramente inferior (mais False Positives?)

Trade-off:
â”œâ”€ Minimiza alarmes em trÃ¡fego legÃ­timo âœ…
â””â”€ Pode perder alguns ataques reais â“
```

**QuestÃµes a investigar:**
1. **Contexto de uso:** Quando BA Ã© mais importante que F1?
2. **Custo de erros:** FP (falso alarme) vs FN (ataque perdido)
3. **AplicaÃ§Ã£o IoT:** Edge devices preferem menos FP?

**Experimentos propostos:**
- âœ… Analisar confusion matrix detalhada
- âœ… Calcular custo ponderado: Cost = Î±Ã—FP + Î²Ã—FN
- âœ… Comparar em cenÃ¡rios com diferentes custos de erro
- âœ… Testar threshold tuning para ajustar FP/FN trade-off

**ReferÃªncias:**
- SchÃ¶lkopf et al. (2001): OneClassSVM original
- Tax & Duin (2004): Support vector data description
- Chandola et al. (2009): Anomaly detection survey

---

### ğŸ“Œ Prioridade MÃ‰DIA

#### **6.4. Instabilidade do IsolationForest**

**Problema:**
- VariÃ¢ncia de 8% no F1 entre configuraÃ§Ãµes
- Mean F1: 90.87% vs Best F1: 98.94%

**HipÃ³teses:**
1. ParÃ¢metro `contamination` domina performance
2. Subsampling aleatÃ³rio causa alta variÃ¢ncia
3. Dataset desbalanceado amplifica instabilidade

**Experimentos propostos:**
- âœ… Grid search detalhado em `contamination` (0.01-0.30)
- âœ… Testar diferentes `n_estimators` (50, 100, 200, 500)
- âœ… Implementar ensemble voting de mÃºltiplos IFs
- âœ… Comparar com Extended Isolation Forest

**ReferÃªncias:**
- Liu et al. (2008): Isolation Forest (paper original)
- Hariri et al. (2019): Extended Isolation Forest
- Campos et al. (2016): On the evaluation of anomaly detection

---

#### **6.5. Custo-benefÃ­cio do GradientBoosting**

**AnÃ¡lise de valor:**
```
GradientBoosting vs RandomForest:
â”œâ”€ Ganho: +0.01% F1 (99.65% vs 99.64%)
â”œâ”€ Custo: +12.6 horas de treinamento
â””â”€ Valor: 0.01% / 12.6h = 0.0008% por hora
```

**QuestÃ£o:** Vale a pena 17.5h para 0.01% de ganho?

**Alternativas modernas:**
- âœ… LightGBM: ImplementaÃ§Ã£o mais rÃ¡pida do GB
- âœ… CatBoost: Melhor para dados categÃ³ricos
- âœ… XGBoost: VersÃ£o otimizada com GPU support

**Experimentos propostos:**
- âœ… Benchmark GradientBoosting vs LightGBM vs XGBoost
- âœ… Testar subsample agressivo (0.5-0.7) para speedup
- âœ… Early stopping para reduzir iteraÃ§Ãµes
- âœ… Avaliar se 0.01% Ã© estatisticamente significativo

**ReferÃªncias:**
- Friedman (2001): Greedy function approximation (GB)
- Ke et al. (2017): LightGBM (Microsoft)
- Chen & Guestrin (2016): XGBoost

---

## ğŸ¤ **7. MENSAGEM PARA APRESENTAÃ‡ÃƒO (1 SLIDE)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ PRINCIPAIS DESCOBERTAS - 270 Experimentos (3M+ samples)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚ 1ï¸âƒ£  PERFORMANCE vs CUSTO                                         â”‚
â”‚     RandomForest = 99.98% da performance do GradientBoosting     â”‚
â”‚     com apenas 28% do tempo (4.9h vs 17.5h)                      â”‚
â”‚     â†’ GradientBoosting nÃ£o justifica custo em produÃ§Ã£o           â”‚
â”‚                                                                   â”‚
â”‚ 2ï¸âƒ£  DATASET DESBALANCEADO REVELADO                               â”‚
â”‚     Algoritmos lineares sacrificam classe minoritÃ¡ria            â”‚
â”‚     GAP de 13-16% entre Accuracy e Balanced Accuracy             â”‚
â”‚     â†’ LinearSVC: 98.7% Acc, mas apenas 84.9% BA                  â”‚
â”‚                                                                   â”‚
â”‚ 3ï¸âƒ£  IoT EDGE COMPUTING VIÃVEL                                    â”‚
â”‚     SGDClassifier: 99.33% F1 em apenas 6 minutos                 â”‚
â”‚     1.750Ã— mais rÃ¡pido que GradientBoosting (-0.32% F1)          â”‚
â”‚     â†’ Treinamento viÃ¡vel em edge/fog nodes                       â”‚
â”‚                                                                   â”‚
â”‚ 4ï¸âƒ£  PROTEÃ‡ÃƒO DA CLASSE MINORITÃRIA                               â”‚
â”‚     SGDOneClassSVM: Melhor Balanced Accuracy (96.9%)             â”‚
â”‚     â†’ Detecta 96.9% do trÃ¡fego benigno corretamente              â”‚
â”‚     â†’ Algoritmos de anomaly detection protegem melhor benignos   â”‚
â”‚                                                                   â”‚
â”‚ 5ï¸âƒ£  SWEET SPOT IoT                                               â”‚
â”‚     Faixa 90s-1000s: >99.3% F1 + Tempo viÃ¡vel                    â”‚
â”‚     â†’ LogReg (16min), SGDClassifier (6min), IsolationForest (5m) â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š **8. TABELA RESUMO COMPARATIVA**

| Algoritmo | F1 | BA | Tempo | Efic. | **RecomendaÃ§Ã£o** |
|-----------|----|----|-------|-------|------------------|
| **GradientBoosting** | 99.65% ğŸ¥‡ | 91.7% | 17.5h | 0.00002 | âŒ Research only |
| **RandomForest** | 99.64% ğŸ¥ˆ | 91.5% | 4.9h | 0.00006 | âœ… Cloud batch |
| **LogisticRegression** | 99.35% ğŸ¥‰ | 85.1% | 16min | 0.00102 | âœ… Gateway |
| **SGDClassifier** | 99.33% | 82.6% ğŸ”´ | 6min | 0.00277 | âœ… Edge server |
| **LinearSVC** | 99.34% | 84.9% ğŸ”´ | 74min | 0.00022 | âš ï¸ Tuning needed |
| **SGDOneClassSVM** | 99.05% | 96.9% ğŸ¥‡ | 36s ğŸ¥‡ | 0.02751 ğŸ¥‡ | âœ… Edge device |
| **LocalOutlierFactor** | 99.09% | 92.6% | 2.4h | 0.00011 | âœ… Anomaly detect |
| **EllipticEnvelope** | 98.96% | 93.2% | 42min | 0.00039 | âœ… Anomaly detect |
| **IsolationForest** | 98.94% | 88.6% | 5min | 0.00312 | âš ï¸ InstÃ¡vel (CV 8%) |

**Legenda:**
- ğŸ¥‡ = Melhor da categoria
- âœ… = Recomendado para uso
- âš ï¸ = Requer cuidado/tuning
- âŒ = NÃ£o recomendado para produÃ§Ã£o
- ğŸ”´ = Problema detectado (baixo BA)

---

## ğŸ“š **9. REFERÃŠNCIAS PARA DISCUSSÃƒO**

### Algoritmos e OtimizaÃ§Ãµes
- **Friedman, J. H. (2001).** "Greedy Function Approximation: A Gradient Boosting Machine." *The Annals of Statistics*, 29(5), 1189-1232.
- **Friedman, J. H. (2002).** "Stochastic Gradient Boosting." *Computational Statistics & Data Analysis*, 38(4), 367-378.
- **Breiman, L. (2001).** "Random Forests." *Machine Learning*, 45(1), 5-32.

### Anomaly Detection
- **SchÃ¶lkopf, B., et al. (2001).** "Estimating the Support of a High-Dimensional Distribution." *Neural Computation*, 13(7), 1443-1471.
- **Liu, F. T., et al. (2008).** "Isolation Forest." *IEEE ICDM*, 413-422.
- **Chandola, V., et al. (2009).** "Anomaly Detection: A Survey." *ACM Computing Surveys*, 41(3), 1-58.

### Imbalanced Learning
- **Chawla, N. V., et al. (2002).** "SMOTE: Synthetic Minority Over-sampling Technique." *Journal of Artificial Intelligence Research*, 16, 321-357.
- **He, H., & Garcia, E. A. (2009).** "Learning from Imbalanced Data." *IEEE TKDE*, 21(9), 1263-1284.
- **Japkowicz, N., & Stephen, S. (2002).** "The Class Imbalance Problem: A Systematic Study." *Intelligent Data Analysis*, 6(5), 429-449.

### IoT Security
- **Neto et al. (2023).** "CICIoT2023: A Real-Time Dataset and Benchmark for Large-Scale Attacks in IoT Environment." *Sensors*, 23(13), 5941.
- **Papadopoulos et al. (2019).** "Benchmarking and Optimization of Edge Computing Systems." *IEEE Access*, 7, 17222-17237.

### Evaluation Metrics
- **Brodersen, K. H., et al. (2010).** "The Balanced Accuracy and Its Posterior Distribution." *ICPR*, 3121-3124.
- **GarcÃ­a, V., et al. (2012).** "On the k-NN performance in a challenging scenario of imbalance and overlapping." *Pattern Analysis and Applications*, 15(3), 341-354.

---

## ğŸ¯ **10. CONCLUSÃ•ES E PRÃ“XIMOS PASSOS**

### âœ… ConclusÃµes Validadas

1. **RandomForest Ã© a melhor opÃ§Ã£o para produÃ§Ã£o Cloud/Batch**
   - Performance equivalente ao GradientBoosting
   - 3.5Ã— mais rÃ¡pido
   - Mais fÃ¡cil de paralelizar

2. **SGDClassifier/SGDOneClassSVM sÃ£o viÃ¡veis para Edge/Fog**
   - Treinamento em minutos
   - Performance >99%
   - SGDOneClassSVM protege melhor classe minoritÃ¡ria

3. **Balanced Accuracy Ã© essencial para datasets desbalanceados**
   - Accuracy tradicional esconde problemas na classe minoritÃ¡ria
   - DiferenÃ§as de 13-16% revelam algoritmos problemÃ¡ticos

### ğŸ”¬ PrÃ³ximas InvestigaÃ§Ãµes (Ordem de Prioridade)

1. **Testar `class_weight='balanced'` nos algoritmos lineares**
2. **Benchmark RandomForest vs GradientBoosting em deployment real**
3. **AnÃ¡lise de custo de erros (FP vs FN) no contexto IoT**
4. **Estabilizar IsolationForest com ensemble/tuning**
5. **Comparar com algoritmos modernos (LightGBM, XGBoost)**

---

**ğŸ“… Data da AnÃ¡lise:** 17 de outubro de 2025  
**ğŸ‘¤ Autor:** Augusto (Mestrando)  
**ğŸ¯ Base de Dados:** 270 experimentos Ã— 3M+ samples (CICIoT2023)  
**â±ï¸ Tempo Total de Experimentos:** 27.1 horas (97,683 segundos)

---

*Documento preparado para apresentaÃ§Ã£o de mestrado - 2025-10-17*

