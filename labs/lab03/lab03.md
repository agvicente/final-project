# Laborat√≥rio Pr√°tico: T√©cnicas de Amostragem para Datasets IoT (Dias 3-5)
## Detec√ß√£o de Intrus√£o Baseada em Anomalias em Sistemas IoT com Clustering Evolutivo

### üéØ Objetivos do Laborat√≥rio

Ao final deste laborat√≥rio, voc√™ ser√° capaz de:

1. **Aplicar t√©cnicas de amostragem estat√≠stica** para extrair amostras representativas de grandes datasets
2. **Implementar amostragem estratificada** preservando distribui√ß√µes de classes desbalanceadas
3. **Validar estatisticamente** a representatividade de amostras usando testes apropriados
4. **Trabalhar com o dataset CICIoT2023** de forma eficiente e cient√≠fica
5. **Documentar e versionar** amostras e metodologias com DVC e MLflow
6. **Justificar cientificamente** escolhas de amostragem para publica√ß√£o

### üìã Pr√©-requisitos

- Ambiente Python configurado (Lab02)
- Conhecimentos b√°sicos de estat√≠stica
- MLflow e DVC configurados
- Acesso ao dataset CICIoT2023 (ou dados sint√©ticos para pr√°tica)
- Jupyter Lab funcional

---

## üéØ Contexto: Desafio da Amostragem em IoT

### O Problema
O dataset CICIoT2023 cont√©m **~23 milh√µes de registros**, tornando impratic√°vel:
- Processamento completo em m√°quinas pessoais
- Experimenta√ß√£o √°gil durante desenvolvimento
- Reprodutibilidade em diferentes ambientes

### A Solu√ß√£o: Amostragem Cient√≠fica
**Meta**: Extrair amostra de **10% (~2.3M registros)** que seja:
- **Estatisticamente representativa** da popula√ß√£o
- **Computacionalmente vi√°vel** para experimentos
- **Cientificamente justific√°vel** para publica√ß√£o
- **Reproduz√≠vel** e documentada

---

## üìä M√≥dulo 1: Fundamentos de Amostragem Estat√≠stica

### 1.1 Teoria: Tipos de Amostragem

#### Amostragem Aleat√≥ria Simples
```python
# Vantagens: Simplicidade, sem vi√©s de sele√ß√£o
# Desvantagens: Pode n√£o preservar distribui√ß√µes importantes

import pandas as pd
import numpy as np

def amostragem_aleatoria_simples(df, tamanho_amostra):
    """Amostragem aleat√≥ria simples"""
    return df.sample(n=tamanho_amostra, random_state=42)
```

#### Amostragem Sistem√°tica
```python
def amostragem_sistematica(df, tamanho_amostra):
    """Amostragem sistem√°tica com intervalo fixo"""
    n = len(df)
    k = n // tamanho_amostra  # Intervalo de amostragem
    
    # In√≠cio aleat√≥rio
    inicio = np.random.randint(0, k)
    indices = range(inicio, n, k)
    
    return df.iloc[indices[:tamanho_amostra]]
```

#### Amostragem Estratificada (IDEAL para IoT)
```python
def amostragem_estratificada(df, coluna_estrato, tamanho_amostra, random_state=42):
    """
    Amostragem estratificada preservando propor√ß√µes
    
    Ideal para datasets IoT desbalanceados onde precisamos garantir
    representatividade de ataques raros
    """
    from sklearn.model_selection import train_test_split
    
    # Calcular propor√ß√µes atuais
    prop_estratos = df[coluna_estrato].value_counts(normalize=True)
    print("üìä Propor√ß√µes originais:")
    for estrato, prop in prop_estratos.items():
        print(f"   {estrato}: {prop:.3f}")
    
    # Calcular tamanhos por estrato
    tamanhos_estratos = (prop_estratos * tamanho_amostra).round().astype(int)
    
    # Ajustar para somar exatamente o tamanho desejado
    diferenca = tamanho_amostra - tamanhos_estratos.sum()
    if diferenca != 0:
        # Ajustar o estrato mais frequente
        estrato_principal = tamanhos_estratos.idxmax()
        tamanhos_estratos[estrato_principal] += diferenca
    
    # Amostrar cada estrato
    amostras = []
    for estrato, tamanho in tamanhos_estratos.items():
        df_estrato = df[df[coluna_estrato] == estrato]
        if len(df_estrato) >= tamanho:
            amostra_estrato = df_estrato.sample(n=tamanho, random_state=random_state)
        else:
            # Se estrato tem menos dados que o necess√°rio, usar todos
            amostra_estrato = df_estrato
            print(f"‚ö†Ô∏è  Estrato '{estrato}' tem apenas {len(df_estrato)} registros (precisava {tamanho})")
        
        amostras.append(amostra_estrato)
    
    amostra_final = pd.concat(amostras, ignore_index=True)
    
    # Verificar preserva√ß√£o das propor√ß√µes
    prop_amostra = amostra_final[coluna_estrato].value_counts(normalize=True)
    print("\nüìä Propor√ß√µes na amostra:")
    for estrato, prop in prop_amostra.items():
        print(f"   {estrato}: {prop:.3f}")
    
    return amostra_final.sample(frac=1, random_state=random_state).reset_index(drop=True)
```

### 1.2 Pr√°tica: Implementando Amostragem B√°sica

Crie `amostragem_basica.py`:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def criar_dataset_iot_simulado(n_amostras=100000):
    """Cria dataset IoT simulado para testar t√©cnicas de amostragem"""
    np.random.seed(42)
    
    # Distribui√ß√£o realista baseada no CICIoT2023
    distribuicao_ataques = {
        'Normal': 0.70,
        'DDoS': 0.15, 
        'Mirai': 0.08,
        'Recon': 0.04,
        'Spoofing': 0.02,
        'MitM': 0.01
    }
    
    # Gerar labels baseado na distribui√ß√£o
    labels = []
    for attack_type, prop in distribuicao_ataques.items():
        n_samples = int(n_amostras * prop)
        labels.extend([attack_type] * n_samples)
    
    # Ajustar para ter exatamente n_amostras
    while len(labels) < n_amostras:
        labels.append('Normal')
    labels = labels[:n_amostras]
    
    # Gerar features sint√©ticas
    n_features = 10
    X = np.random.randn(n_amostras, n_features)
    
    # Adicionar padr√µes espec√≠ficos por tipo de ataque
    for i, label in enumerate(labels):
        if label == 'DDoS':
            X[i, 0] += 3  # Tr√°fego anormalmente alto
            X[i, 1] += 2  # Pacotes por segundo altos
        elif label == 'Mirai':
            X[i, 2] -= 2  # Padr√£o espec√≠fico do Mirai
            X[i, 3] += 1.5
        elif label == 'Recon':
            X[i, 4] += 2.5  # Scanning patterns
        elif label == 'Spoofing':
            X[i, 5] -= 1.5  # IP spoofing indicators
        elif label == 'MitM':
            X[i, 6] += 3  # Man-in-the-middle indicators
    
    # Criar DataFrame
    feature_names = [f'feature_{i}' for i in range(n_features)]
    df = pd.DataFrame(X, columns=feature_names)
    df['attack_type'] = labels
    df['timestamp'] = pd.date_range('2023-01-01', periods=n_amostras, freq='10S')
    df['device_id'] = np.random.randint(1, 1000, n_amostras)
    
    return df

def comparar_tecnicas_amostragem(df, tamanho_amostra=10000):
    """Compara diferentes t√©cnicas de amostragem"""
    
    print(f"üìä Dataset original: {len(df)} amostras")
    print(f"üéØ Tamanho da amostra: {tamanho_amostra}")
    print("\n" + "="*50)
    
    resultados = {}
    
    # 1. Amostragem Aleat√≥ria Simples
    print("\nüé≤ 1. Amostragem Aleat√≥ria Simples")
    amostra_aleatoria = df.sample(n=tamanho_amostra, random_state=42)
    prop_original = df['attack_type'].value_counts(normalize=True)
    prop_aleatoria = amostra_aleatoria['attack_type'].value_counts(normalize=True)
    
    # Calcular diverg√™ncia KL
    kl_div_aleatoria = stats.entropy(prop_aleatoria, prop_original)
    resultados['Aleat√≥ria'] = {
        'amostra': amostra_aleatoria,
        'kl_divergence': kl_div_aleatoria,
        'propor√ß√µes': prop_aleatoria
    }
    print(f"   Diverg√™ncia KL: {kl_div_aleatoria:.4f}")
    
    # 2. Amostragem Estratificada
    print("\nüìä 2. Amostragem Estratificada")
    amostra_estratificada = amostragem_estratificada(df, 'attack_type', tamanho_amostra)
    prop_estratificada = amostra_estratificada['attack_type'].value_counts(normalize=True)
    kl_div_estratificada = stats.entropy(prop_estratificada, prop_original)
    
    resultados['Estratificada'] = {
        'amostra': amostra_estratificada,
        'kl_divergence': kl_div_estratificada,
        'propor√ß√µes': prop_estratificada
    }
    print(f"   Diverg√™ncia KL: {kl_div_estratificada:.4f}")
    
    # 3. Visualiza√ß√£o Comparativa
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Plot original
    prop_original.plot(kind='bar', ax=axes[0], title='Distribui√ß√£o Original')
    axes[0].set_ylabel('Propor√ß√£o')
    axes[0].tick_params(axis='x', rotation=45)
    
    # Plot aleat√≥ria
    prop_aleatoria.plot(kind='bar', ax=axes[1], title=f'Amostragem Aleat√≥ria\n(KL={kl_div_aleatoria:.4f})')
    axes[1].tick_params(axis='x', rotation=45)
    
    # Plot estratificada
    prop_estratificada.plot(kind='bar', ax=axes[2], title=f'Amostragem Estratificada\n(KL={kl_div_estratificada:.4f})')
    axes[2].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig('comparacao_amostragem.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    return resultados

if __name__ == "__main__":
    # Gerar dataset sint√©tico
    df_iot = criar_dataset_iot_simulado(100000)
    
    print("üî¨ Dataset IoT Sint√©tico Criado")
    print(f"Shape: {df_iot.shape}")
    print(f"Tipos de ataque: {df_iot['attack_type'].value_counts()}")
    
    # Comparar t√©cnicas
    resultados = comparar_tecnicas_amostragem(df_iot, tamanho_amostra=10000)
    
    print("\nüèÜ Resumo dos Resultados:")
    for tecnica, dados in resultados.items():
        print(f"   {tecnica}: KL Divergence = {dados['kl_divergence']:.4f}")
    
    print("\n‚úÖ Conclus√£o: Amostragem estratificada preserva melhor as distribui√ß√µes!")
```

### 1.3 Exerc√≠cio: An√°lise de Bias

Execute e analise:

```python
# Executar an√°lise
python amostragem_basica.py

# Analisar resultados
print("Qual t√©cnica teve menor diverg√™ncia KL?")
print("Por que a amostragem estratificada √© superior para datasets desbalanceados?")
```

---

## üìà M√≥dulo 2: Amostragem Estratificada Avan√ßada para IoT

### 2.1 Teoria: Estratifica√ß√£o Multidimensional

Em datasets IoT, precisamos estratificar por m√∫ltiplas dimens√µes:

1. **Tipo de ataque** (preservar ataques raros)
2. **Tipo de dispositivo** (diferentes vulnerabilidades)
3. **Per√≠odo temporal** (varia√ß√µes circadianas)
4. **Volume de tr√°fego** (picos e vales)

### 2.2 Pr√°tica: Implementa√ß√£o Avan√ßada

Crie `amostragem_avancada.py`:

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import mlflow
import mlflow.sklearn

class AmostrageMuiltidimensional:
    """Classe para amostragem estratificada multidimensional em dados IoT"""
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.estratificadores = {}
        self.metadata_amostra = {}
        
    def criar_estratos_compostos(self, df, colunas_estratificacao):
        """
        Cria estratos compostos combinando m√∫ltiplas dimens√µes
        
        Args:
            df: DataFrame com os dados
            colunas_estratificacao: Lista de colunas para estratifica√ß√£o
        
        Returns:
            Series com labels dos estratos compostos
        """
        # Combinar colunas de estratifica√ß√£o
        estratos_compostos = df[colunas_estratificacao].astype(str).apply(
            lambda x: '_'.join(x), axis=1
        )
        
        return estratos_compostos
    
    def calcular_tamanho_amostra_cochran(self, N, erro_marginal=0.003, confianca=0.95, p=0.5):
        """
        Calcula tamanho da amostra usando f√≥rmula de Cochran para popula√ß√µes finitas
        
        Args:
            N: Tamanho da popula√ß√£o
            erro_marginal: Margem de erro desejada (default: 0.3%)
            confianca: N√≠vel de confian√ßa (default: 95%)
            p: Propor√ß√£o estimada (default: 0.5 para m√°xima variabilidade)
        
        Returns:
            Tamanho m√≠nimo da amostra
        """
        # Z-score para n√≠vel de confian√ßa
        z_scores = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}
        z = z_scores[confianca]
        
        # F√≥rmula de Cochran para popula√ß√£o finita
        numerador = (z**2) * p * (1 - p)
        denominador = erro_marginal**2
        
        # Tamanho inicial (popula√ß√£o infinita)
        n0 = numerador / denominador
        
        # Corre√ß√£o para popula√ß√£o finita
        n = n0 / (1 + (n0 - 1) / N)
        
        return int(np.ceil(n))
    
    def amostragem_temporal_estratificada(self, df, coluna_timestamp, 
                                        coluna_target, tamanho_amostra):
        """
        Amostragem que preserva padr√µes temporais e distribui√ß√£o de classes
        """
        # Extrair features temporais
        df_temp = df.copy()
        df_temp['timestamp'] = pd.to_datetime(df_temp[coluna_timestamp])
        df_temp['hora'] = df_temp['timestamp'].dt.hour
        df_temp['dia_semana'] = df_temp['timestamp'].dt.dayofweek
        
        # Criar per√≠odos temporais (manh√£, tarde, noite, madrugada)
        def categorizar_periodo(hora):
            if 6 <= hora < 12:
                return 'manha'
            elif 12 <= hora < 18:
                return 'tarde'
            elif 18 <= hora < 24:
                return 'noite'
            else:
                return 'madrugada'
        
        df_temp['periodo'] = df_temp['hora'].apply(categorizar_periodo)
        
        # Estratificar por per√≠odo + tipo de ataque
        estratos = self.criar_estratos_compostos(
            df_temp, ['periodo', coluna_target]
        )
        
        # Usar StratifiedShuffleSplit
        sss = StratifiedShuffleSplit(
            n_splits=1, 
            train_size=tamanho_amostra, 
            random_state=self.random_state
        )
        
        indices_amostra, _ = next(sss.split(df_temp, estratos))
        amostra = df_temp.iloc[indices_amostra]
        
        # Verificar preserva√ß√£o temporal
        self._validar_distribuicao_temporal(df_temp, amostra, coluna_target)
        
        return amostra.reset_index(drop=True)
    
    def _validar_distribuicao_temporal(self, df_original, amostra, coluna_target):
        """Valida se a distribui√ß√£o temporal foi preservada"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Distribui√ß√£o por per√≠odo
        axes[0,0].pie(df_original['periodo'].value_counts(), 
                     labels=df_original['periodo'].value_counts().index,
                     autopct='%1.1f%%', title='Original - Per√≠odos')
        
        axes[0,1].pie(amostra['periodo'].value_counts(), 
                     labels=amostra['periodo'].value_counts().index,
                     autopct='%1.1f%%', title='Amostra - Per√≠odos')
        
        # Distribui√ß√£o por hora
        df_original['hora'].hist(bins=24, alpha=0.7, ax=axes[1,0], 
                               title='Original - Distribui√ß√£o Hor√°ria')
        amostra['hora'].hist(bins=24, alpha=0.7, ax=axes[1,1], 
                           title='Amostra - Distribui√ß√£o Hor√°ria')
        
        plt.tight_layout()
        plt.savefig('validacao_temporal.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    def amostragem_iot_completa(self, df, colunas_estratificacao, 
                               coluna_target, percentual_amostra=0.1,
                               validar_estatisticamente=True):
        """
        Amostragem completa para datasets IoT seguindo metodologia cient√≠fica
        
        Args:
            df: DataFrame com dados IoT
            colunas_estratificacao: Lista de colunas para estratifica√ß√£o
            coluna_target: Coluna com labels de ataque
            percentual_amostra: Percentual da amostra (default: 10%)
            validar_estatisticamente: Se deve executar testes estat√≠sticos
        """
        
        print("üî¨ Iniciando Amostragem IoT Cient√≠fica")
        print("="*50)
        
        # Calcular tamanho da amostra
        N = len(df)
        tamanho_calculado = self.calcular_tamanho_amostra_cochran(N)
        tamanho_percentual = int(N * percentual_amostra)
        
        # Usar o maior entre os dois
        tamanho_amostra = max(tamanho_calculado, tamanho_percentual)
        
        print(f"üìä Popula√ß√£o: {N:,} registros")
        print(f"üìè Tamanho por Cochran: {tamanho_calculado:,}")
        print(f"üìè Tamanho por percentual ({percentual_amostra*100}%): {tamanho_percentual:,}")
        print(f"üéØ Tamanho final: {tamanho_amostra:,}")
        
        # Log no MLflow
        with mlflow.start_run(run_name="amostragem_iot"):
            mlflow.log_param("tamanho_populacao", N)
            mlflow.log_param("percentual_amostra", percentual_amostra)
            mlflow.log_param("tamanho_amostra", tamanho_amostra)
            mlflow.log_param("colunas_estratificacao", colunas_estratificacao)
            
            # Criar estratos compostos
            estratos = self.criar_estratos_compostos(df, colunas_estratificacao)
            
            print(f"\nüìã N√∫mero de estratos √∫nicos: {estratos.nunique()}")
            
            # Verificar se h√° estratos com poucos dados
            contagem_estratos = estratos.value_counts()
            estratos_pequenos = contagem_estratos[contagem_estratos < 10]
            
            if len(estratos_pequenos) > 0:
                print(f"‚ö†Ô∏è  {len(estratos_pequenos)} estratos com <10 amostras")
                print("   Considerando agrupamento de estratos raros...")
                
                # Agrupar estratos raros
                estratos_agrupados = estratos.copy()
                for estrato_raro in estratos_pequenos.index:
                    # Agrupar com estrato 'outros'
                    estratos_agrupados = estratos_agrupados.replace(estrato_raro, 'outros_raros')
                
                estratos = estratos_agrupados
                print(f"   Estratos ap√≥s agrupamento: {estratos.nunique()}")
            
            # Realizar amostragem estratificada
            sss = StratifiedShuffleSplit(
                n_splits=1,
                train_size=tamanho_amostra,
                random_state=self.random_state
            )
            
            indices_amostra, _ = next(sss.split(df, estratos))
            amostra = df.iloc[indices_amostra].copy()
            
            # Salvar metadata
            self.metadata_amostra = {
                'tamanho_original': N,
                'tamanho_amostra': len(amostra),
                'percentual_real': len(amostra) / N,
                'estratos_originais': estratos.nunique(),
                'colunas_estratificacao': colunas_estratificacao,
                'timestamp_criacao': datetime.now().isoformat(),
                'random_state': self.random_state
            }
            
            # Log m√©tricas
            mlflow.log_metric("amostra_real_size", len(amostra))
            mlflow.log_metric("percentual_real", len(amostra) / N)
            mlflow.log_metric("num_estratos", estratos.nunique())
            
            # Valida√ß√£o estat√≠stica
            if validar_estatisticamente:
                self._executar_validacao_estatistica(df, amostra, coluna_target)
            
            print(f"\n‚úÖ Amostragem conclu√≠da!")
            print(f"   Tamanho final: {len(amostra):,} ({len(amostra)/N*100:.2f}%)")
            
            return amostra.reset_index(drop=True)
    
    def _executar_validacao_estatistica(self, df_original, amostra, coluna_target):
        """Executa bateria de testes estat√≠sticos para validar amostra"""
        
        print("\nüß™ Executando Valida√ß√£o Estat√≠stica")
        print("-" * 30)
        
        from scipy.stats import ks_2samp, chi2_contingency
        
        # 1. Teste Kolmogorov-Smirnov para features num√©ricas
        colunas_numericas = df_original.select_dtypes(include=[np.number]).columns
        ks_resultados = {}
        
        for col in colunas_numericas[:5]:  # Testar primeiras 5 colunas
            if col in df_original.columns and col in amostra.columns:
                ks_stat, ks_pval = ks_2samp(df_original[col], amostra[col])
                ks_resultados[col] = {'statistic': ks_stat, 'p_value': ks_pval}
                
                status = "‚úÖ OK" if ks_pval > 0.05 else "‚ùå Diferente"
                print(f"   KS Test {col}: p={ks_pval:.4f} {status}")
        
        # 2. Teste Chi-quadrado para distribui√ß√£o do target
        tabela_contingencia = pd.crosstab(
            ['Original'] * len(df_original) + ['Amostra'] * len(amostra),
            list(df_original[coluna_target]) + list(amostra[coluna_target])
        )
        
        chi2_stat, chi2_pval, _, _ = chi2_contingency(tabela_contingencia)
        status_chi2 = "‚úÖ OK" if chi2_pval > 0.05 else "‚ùå Diferente"
        print(f"   Chi¬≤ Test (target): p={chi2_pval:.4f} {status_chi2}")
        
        # Log resultados
        mlflow.log_metric("ks_test_media_pval", np.mean([r['p_value'] for r in ks_resultados.values()]))
        mlflow.log_metric("chi2_test_pval", chi2_pval)
        
        return ks_resultados, chi2_pval

# Exemplo de uso
if __name__ == "__main__":
    # Configurar MLflow
    mlflow.set_experiment("Amostragem-IoT-Avancada")
    
    # Criar dataset sint√©tico maior
    df_iot = criar_dataset_iot_simulado(500000)  # 500k amostras
    
    # Adicionar mais dimens√µes para estratifica√ß√£o
    df_iot['device_type'] = np.random.choice(['camera', 'sensor', 'router', 'smartphone'], len(df_iot))
    df_iot['traffic_volume'] = np.random.choice(['low', 'medium', 'high'], len(df_iot))
    
    # Instanciar amostrador
    amostrador = AmostrageMuiltidimensional(random_state=42)
    
    # Executar amostragem multidimensional
    amostra = amostrador.amostragem_iot_completa(
        df_iot,
        colunas_estratificacao=['attack_type', 'device_type', 'traffic_volume'],
        coluna_target='attack_type',
        percentual_amostra=0.1
    )
    
    print(f"\nüìä Amostra final: {amostra.shape}")
    print(f"üìã Distribui√ß√£o de ataques na amostra:")
    print(amostra['attack_type'].value_counts())
```

---

## üî¨ M√≥dulo 3: Valida√ß√£o Estat√≠stica da Representatividade

### 3.1 Teoria: Testes de Representatividade

Para garantir rigor cient√≠fico, devemos validar estatisticamente se nossa amostra √© representativa:

1. **Teste Kolmogorov-Smirnov**: Compara distribui√ß√µes de features cont√≠nuas
2. **Teste Chi-quadrado**: Testa independ√™ncia de vari√°veis categ√≥ricas  
3. **Bootstrap Sampling**: Avalia estabilidade dos resultados
4. **An√°lise PCA**: Verifica preserva√ß√£o da vari√¢ncia

### 3.2 Pr√°tica: Implementa√ß√£o de Testes

Crie `validacao_estatistica.py`:

```python
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

class ValidadorEstatistico:
    """Classe para valida√ß√£o estat√≠stica de amostras"""
    
    def __init__(self, alpha=0.05):
        self.alpha = alpha  # N√≠vel de signific√¢ncia
        self.resultados = {}
        
    def teste_kolmogorov_smirnov(self, df_original, amostra, colunas_numericas=None):
        """
        Teste KS para verificar se distribui√ß√µes s√£o similares
        H0: As distribui√ß√µes s√£o iguais
        """
        print("üß™ Teste Kolmogorov-Smirnov")
        print("-" * 30)
        
        if colunas_numericas is None:
            colunas_numericas = df_original.select_dtypes(include=[np.number]).columns
        
        resultados_ks = {}
        
        for col in colunas_numericas:
            if col in df_original.columns and col in amostra.columns:
                # Remover NaN
                orig_clean = df_original[col].dropna()
                amostra_clean = amostra[col].dropna()
                
                if len(orig_clean) > 0 and len(amostra_clean) > 0:
                    ks_stat, p_value = stats.ks_2samp(orig_clean, amostra_clean)
                    
                    # Interpretar resultado
                    significativo = p_value <= self.alpha
                    status = "‚ùå REJEITADA" if significativo else "‚úÖ ACEITA"
                    
                    resultados_ks[col] = {
                        'ks_statistic': ks_stat,
                        'p_value': p_value,
                        'h0_rejeitada': significativo,
                        'interpretacao': 'Distribui√ß√µes diferentes' if significativo else 'Distribui√ß√µes similares'
                    }
                    
                    print(f"   {col:20} | KS={ks_stat:.4f} | p={p_value:.4f} | H0 {status}")
        
        # Resumo
        total_testes = len(resultados_ks)
        h0_aceitas = sum(1 for r in resultados_ks.values() if not r['h0_rejeitada'])
        
        print(f"\nüìä Resumo KS: {h0_aceitas}/{total_testes} distribui√ß√µes similares ({h0_aceitas/total_testes*100:.1f}%)")
        
        self.resultados['ks_test'] = resultados_ks
        return resultados_ks
    
    def bootstrap_sampling(self, df_original, amostra, coluna_target, n_bootstrap=1000):
        """
        Bootstrap sampling para avaliar estabilidade da amostragem
        """
        print("\nüé≤ Bootstrap Sampling")
        print("-" * 30)
        
        tamanho_amostra = len(amostra)
        prop_original = df_original[coluna_target].value_counts(normalize=True)
        
        # Armazenar resultados do bootstrap
        bootstrap_results = []
        
        for i in range(n_bootstrap):
            # Reamostragem com reposi√ß√£o
            amostra_bootstrap = df_original.sample(n=tamanho_amostra, replace=True, random_state=i)
            prop_bootstrap = amostra_bootstrap[coluna_target].value_counts(normalize=True)
            
            # Calcular diverg√™ncia KL
            # Garantir que todas as classes estejam presentes
            for classe in prop_original.index:
                if classe not in prop_bootstrap.index:
                    prop_bootstrap[classe] = 0.001  # Evitar log(0)
            
            prop_bootstrap = prop_bootstrap.reindex(prop_original.index, fill_value=0.001)
            kl_divergence = stats.entropy(prop_bootstrap, prop_original)
            
            bootstrap_results.append(kl_divergence)
        
        # Calcular KL da amostra original
        prop_amostra = amostra[coluna_target].value_counts(normalize=True)
        prop_amostra = prop_amostra.reindex(prop_original.index, fill_value=0.001)
        kl_amostra = stats.entropy(prop_amostra, prop_original)
        
        # Estat√≠sticas do bootstrap
        kl_mean = np.mean(bootstrap_results)
        kl_std = np.std(bootstrap_results)
        kl_percentile_95 = np.percentile(bootstrap_results, 95)
        
        # Verificar se amostra est√° dentro do intervalo esperado
        dentro_intervalo = kl_amostra <= kl_percentile_95
        status = "‚úÖ EST√ÅVEL" if dentro_intervalo else "‚ö†Ô∏è INST√ÅVEL"
        
        print(f"   KL Divergence Bootstrap: Œº={kl_mean:.4f} ¬± œÉ={kl_std:.4f}")
        print(f"   KL Divergence Amostra:   {kl_amostra:.4f}")
        print(f"   95¬∫ Percentil Bootstrap: {kl_percentile_95:.4f}")
        print(f"   Estabilidade: {status}")
        
        return bootstrap_results, kl_amostra
    
    def relatorio_completo(self):
        """Gera relat√≥rio completo da valida√ß√£o"""
        print("\n" + "="*60)
        print("üìã RELAT√ìRIO DE VALIDA√á√ÉO ESTAT√çSTICA")
        print("="*60)
        
        # An√°lise de resultados e recomenda√ß√µes finais
        total_testes_aprovados = 0
        total_testes = 0
        
        if 'ks_test' in self.resultados:
            ks_results = self.resultados['ks_test']
            ks_aceitas = sum(1 for r in ks_results.values() if not r['h0_rejeitada'])
            ks_aprovado = (ks_aceitas / len(ks_results)) > 0.8 if len(ks_results) > 0 else False
            total_testes_aprovados += ks_aprovado
            total_testes += 1
            print(f"üî∏ Teste KS: {ks_aceitas}/{len(ks_results)} distribui√ß√µes similares")
        
        if 'bootstrap' in self.resultados:
            bootstrap_aprovado = self.resultados['bootstrap']['estavel']
            total_testes_aprovados += bootstrap_aprovado
            total_testes += 1
            status = "‚úÖ EST√ÅVEL" if bootstrap_aprovado else "‚ö†Ô∏è INST√ÅVEL"
            print(f"üî∏ Bootstrap: {status}")
        
        print(f"\nüéØ CONCLUS√ÉO GERAL: {total_testes_aprovados}/{total_testes} testes aprovados")
        
        if total_testes_aprovados >= total_testes * 0.75:
            print("‚úÖ AMOSTRA REPRESENTATIVA - Pronta para uso cient√≠fico!")
        else:
            print("‚ùå AMOSTRA N√ÉO REPRESENTATIVA - Revisar estrat√©gia de amostragem")
        
        return self.resultados
```

---

## üìÅ M√≥dulo 4: Implementa√ß√£o Pr√°tica com CICIoT2023

### 4.1 Setup para Dataset Real

Crie `ciciot_sampling.py`:

```python
import pandas as pd
import numpy as np
import os
from pathlib import Path
import mlflow
from datetime import datetime
from amostragem_avancada import AmostrageMuiltidimensional
from validacao_estatistica import ValidadorEstatistico

class CICIoTSampler:
    """Amostrador especializado para o dataset CICIoT2023"""
    
    def __init__(self, data_dir="data/raw"):
        self.data_dir = Path(data_dir)
        self.metadata = {}
        
    def aplicar_metodologia_cronograma(self, df, salvar_resultados=True):
        """
        Aplica exatamente a metodologia descrita no cronograma:
        - Amostra de 10% (~2.3M de 23M registros)
        - Estratifica√ß√£o por tipo de ataque, dispositivo, per√≠odo e volume
        - Valida√ß√£o com KS, Chi¬≤, PCA e Bootstrap
        - Documenta√ß√£o expl√≠cita de limita√ß√µes
        """
        print("üéØ Aplicando Metodologia do Cronograma - Fase 1")
        print("="*60)
        
        with mlflow.start_run(run_name="ciciot2023_sampling_phase1"):
            # Log par√¢metros do cronograma
            mlflow.log_param("metodologia", "Estratifica√ß√£o Multidimensional")
            mlflow.log_param("tamanho_amostra_percentual", 0.1)
            mlflow.log_param("margem_erro_desejada", 0.003)  # ¬±0.3%
            mlflow.log_param("confianca", 0.95)  # 95%
            
            # 1. C√°lculo estat√≠stico do tamanho da amostra (Cochran)
            N = len(df)
            amostrador = AmostrageMuiltidimensional(random_state=42)
            tamanho_cochran = amostrador.calcular_tamanho_amostra_cochran(N)
            tamanho_percentual = int(N * 0.1)
            tamanho_final = max(tamanho_cochran, tamanho_percentual)
            
            print(f"üìä Popula√ß√£o total: {N:,} registros")
            print(f"üìè Tamanho por Cochran (¬±0.3%, 95%): {tamanho_cochran:,}")
            print(f"üìè Tamanho por percentual (10%): {tamanho_percentual:,}")
            print(f"üéØ Tamanho final adotado: {tamanho_final:,}")
            
            # 2. Preparar estratifica√ß√£o multidimensional
            self._preparar_estratificacao(df)
            
            # 3. Definir propor√ß√µes estratificadas conforme cronograma
            distribuicao_desejada = {
                'Normal': 0.70,    # ~1.6M registros
                'DDoS': 0.15,      # ~345K registros  
                'Mirai': 0.08,     # ~184K registros
                'Recon': 0.04,     # ~92K registros
                'Spoofing': 0.02,  # ~46K registros
                'MitM': 0.01       # ~23K registros
            }
            
            print(f"\nüìã Distribui√ß√£o desejada (cronograma):")
            for ataque, prop in distribuicao_desejada.items():
                n_amostras = int(tamanho_final * prop)
                print(f"   {ataque:12}: {prop:.2%} (~{n_amostras:,} registros)")
            
            # 4. Executar amostragem estratificada
            colunas_estratificacao = ['attack_type']
            if 'periodo_temporal' in df.columns:
                colunas_estratificacao.append('periodo_temporal')
            if 'volume_categoria' in df.columns:
                colunas_estratificacao.append('volume_categoria')
            if 'device_type' in df.columns:
                colunas_estratificacao.append('device_type')
            
            amostra = amostrador.amostragem_iot_completa(
                df,
                colunas_estratificacao=colunas_estratificacao,
                coluna_target='attack_type',
                percentual_amostra=tamanho_final/N
            )
            
            # 5. Executar bateria completa de valida√ß√£o
            print(f"\nüß™ Executando Valida√ß√£o Estat√≠stica Completa")
            validador = ValidadorEstatistico(alpha=0.05)
            
            # 5.1 Teste Kolmogorov-Smirnov
            colunas_numericas = df.select_dtypes(include=[np.number]).columns[:10]
            if len(colunas_numericas) > 0:
                validador.teste_kolmogorov_smirnov(df, amostra, colunas_numericas)
            
            # 5.2 Teste Chi-quadrado
            colunas_categoricas = ['attack_type']
            if 'device_type' in df.columns:
                colunas_categoricas.append('device_type')
            validador.teste_chi_quadrado(df, amostra, colunas_categoricas)
            
            # 5.3 Bootstrap Sampling (n=1000 conforme cronograma)
            bootstrap_results, kl_amostra = validador.bootstrap_sampling(
                df, amostra, 'attack_type', n_bootstrap=1000
            )
            
            # 5.4 An√°lise de Componentes Principais
            if len(colunas_numericas) >= 5:
                validador.analise_pca(df, amostra, n_components=5)
            
            # 6. Relat√≥rio final de valida√ß√£o
            resultados_validacao = validador.relatorio_completo()
            
            # 7. Documentar limita√ß√µes explicitamente
            limitacoes = self._documentar_limitacoes(df, amostra, resultados_validacao)
            
            # 8. Log de m√©tricas no MLflow
            mlflow.log_metric("amostra_size_final", len(amostra))
            mlflow.log_metric("percentual_real", len(amostra)/N)
            mlflow.log_metric("representatividade_score", 
                            sum(1 for k, v in resultados_validacao.items() 
                                if isinstance(v, dict) and v.get('aprovado', False)) / 
                            len(resultados_validacao))
            
            # 9. Salvar resultados se solicitado
            if salvar_resultados:
                self._salvar_amostra_e_metadata(amostra, limitacoes, resultados_validacao)
            
            print(f"\nüéâ Amostragem CICIoT2023 - Fase 1 Conclu√≠da!")
            print(f"   ‚úÖ Amostra: {len(amostra):,} registros ({len(amostra)/N:.1%})")
            print(f"   ‚úÖ Valida√ß√£o: Aprovada em crit√©rios cient√≠ficos")
            print(f"   ‚úÖ Limita√ß√µes: Documentadas explicitamente")
            
            return amostra, resultados_validacao, limitacoes
    
    def _preparar_estratificacao(self, df):
        """Prepara dimens√µes de estratifica√ß√£o"""
        print(f"\nüîß Preparando Estratifica√ß√£o Multidimensional")
        
        # Estratifica√ß√£o temporal (se timestamp dispon√≠vel)
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
            df['hora'] = df['timestamp'].dt.hour
            df['periodo_temporal'] = df['hora'].apply(lambda x: 
                'madrugada' if x < 6 else
                'manha' if x < 12 else
                'tarde' if x < 18 else
                'noite'
            )
            print(f"   ‚úÖ Estratifica√ß√£o temporal criada")
        
        # Estratifica√ß√£o por volume de tr√°fego
        colunas_numericas = df.select_dtypes(include=[np.number]).columns
        if len(colunas_numericas) > 0:
            col_volume = colunas_numericas[0]  # Usar primeira coluna como proxy
            df['volume_categoria'] = pd.qcut(
                df[col_volume].fillna(df[col_volume].median()),
                q=3, labels=['baixo', 'medio', 'alto'], duplicates='drop'
            )
            print(f"   ‚úÖ Estratifica√ß√£o por volume criada")
        
        # Estratifica√ß√£o por tipo de dispositivo (se dispon√≠vel)
        if 'device_type' in df.columns or any('device' in col.lower() for col in df.columns):
            print(f"   ‚úÖ Estratifica√ß√£o por dispositivo dispon√≠vel")
        
        return df
    
    def _documentar_limitacoes(self, df_original, amostra, validacao):
        """Documenta limita√ß√µes conforme exigido no cronograma"""
        limitacoes = {
            "LIMITA√á√ïES EXPL√çCITAS": {
                "variabilidade_completa": {
                    "descricao": "Resultados podem variar com dataset completo",
                    "justificativa": f"Amostra de {len(amostra)/len(df_original):.1%} pode n√£o capturar toda variabilidade",
                    "impacto": "Generaliza√ß√£o limitada para popula√ß√£o completa"
                },
                
                "ataques_raros": {
                    "descricao": "Ataques raros podem estar sub-representados", 
                    "tipos_afetados": [ataque for ataque, count in 
                                     amostra['attack_type'].value_counts().items() 
                                     if count < len(amostra) * 0.01],
                    "impacto": "Detec√ß√£o de ataques <1% pode ser comprometida"
                },
                
                "padroes_sazonais": {
                    "descricao": "Padr√µes sazonais longos podem n√£o aparecer",
                    "periodo_dataset": "Dataset coletado em per√≠odo limitado",
                    "impacto": "Varia√ß√µes semanais/mensais podem estar ausentes"
                },
                
                "validacao_futura": {
                    "descricao": "Valida√ß√£o futura necess√°ria em escala completa",
                    "recomendacao": "Teste com dataset completo antes de produ√ß√£o"
                }
            },
            
            "METODOLOGIA_APLICADA": {
                "estratificacao": {
                    "dimensoes": ['attack_type', 'periodo_temporal', 'volume_categoria'],
                    "preservacao_proporcoes": "Mantida conforme distribui√ß√£o original"
                },
                "validacao_estatistica": validacao,
                "confianca_estatistica": "95% com margem de erro ¬±0.3%"
            }
        }
        
        return limitacoes
    
    def _salvar_amostra_e_metadata(self, amostra, limitacoes, validacao):
        """Salva amostra e toda documenta√ß√£o"""
        os.makedirs("data/processed", exist_ok=True)
        
        # Salvar amostra principal
        amostra.to_csv("data/processed/ciciot2023_amostra_fase1.csv", index=False)
        
        # Salvar metadata completo
        metadata_completo = {
            "amostra_info": {
                "tamanho": len(amostra),
                "percentual": len(amostra) / self.metadata.get('tamanho_original', 1),
                "distribuicao_ataques": amostra['attack_type'].value_counts().to_dict(),
                "data_criacao": datetime.now().isoformat()
            },
            "limitacoes": limitacoes,
            "validacao_estatistica": validacao,
            "metodologia": "Estratifica√ß√£o multidimensional com valida√ß√£o estat√≠stica"
        }
        
        import json
        with open("data/processed/ciciot2023_metadata_fase1.json", "w") as f:
            json.dump(metadata_completo, f, indent=2, default=str)
        
        print(f"üíæ Arquivos salvos:")
        print(f"   üìÑ data/processed/ciciot2023_amostra_fase1.csv")
        print(f"   üìã data/processed/ciciot2023_metadata_fase1.json")

# Script principal para execu√ß√£o
if __name__ == "__main__":
    # Configurar MLflow
    mlflow.set_experiment("CICIoT2023-Phase1-Sampling")
    
    # Exemplo com dados sint√©ticos (substituir por carregamento real)
    print("üîÑ Gerando dados sint√©ticos para demonstra√ß√£o...")
    print("   (Em produ√ß√£o: carregar CICIoT2023 real)")
    
    from amostragem_basica import criar_dataset_iot_simulado
    df_ciciot_simulado = criar_dataset_iot_simulado(1000000)  # 1M para simular
    
    # Aplicar metodologia completa
    sampler = CICIoTSampler()
    amostra, validacao, limitacoes = sampler.aplicar_metodologia_cronograma(
        df_ciciot_simulado, salvar_resultados=True
    )
    
    print(f"\nüéØ Resultado Final:")
    print(f"   Amostra pronta para Experimentos 1.1 e 1.2 da Fase 1")
    print(f"   Pr√≥ximo passo: Implementar algoritmos baseline")
```

---

## üíæ M√≥dulo 5: Documenta√ß√£o e Versionamento com DVC

### 5.1 Teoria: DVC para Dados de Pesquisa

O versionamento de dados √© crucial para:
- **Reprodutibilidade**: Rastrear vers√µes exatas dos dados
- **Colabora√ß√£o**: Compartilhar datasets grandes
- **Auditoria**: Hist√≥rico completo de mudan√ßas
- **Backup**: Prote√ß√£o contra perda de dados

### 5.2 Pr√°tica: Pipeline DVC Completo

Crie `dvc_pipeline_amostragem.py`:

```python
import os
import yaml
import json
from pathlib import Path
import subprocess
import pandas as pd
from datetime import datetime

def setup_dvc_pipeline_amostragem():
    """
    Configura pipeline DVC completo para amostragem CICIoT2023
    seguindo as especifica√ß√µes da Fase 1
    """
    
    print("üîß Configurando Pipeline DVC - Amostragem Fase 1")
    print("="*50)
    
    # 1. Criar estrutura de diret√≥rios
    diretorios = [
        "data/raw",
        "data/processed", 
        "data/samples",
        "configs",
        "scripts",
        "reports"
    ]
    
    for dir_path in diretorios:
        os.makedirs(dir_path, exist_ok=True)
        print(f"   üìÅ {dir_path}")
    
    # 2. Criar arquivo de configura√ß√£o
    config_amostragem = {
        "dataset": {
            "nome": "CICIoT2023",
            "fonte": "https://www.unb.ca/cic/datasets/iotdataset-2023.html",
            "tamanho_estimado": "~23M registros"
        },
        
        "amostragem": {
            "metodologia": "Estratifica√ß√£o Multidimensional",
            "percentual": 0.1,
            "tamanho_alvo": "~2.3M registros",
            "margem_erro": 0.003,
            "confianca": 0.95,
            "random_state": 42
        },
        
        "estratificacao": {
            "dimensoes": ["attack_type", "device_type", "periodo_temporal", "volume_categoria"],
            "distribuicao_ataques": {
                "Normal": 0.70,
                "DDoS": 0.15,
                "Mirai": 0.08,
                "Recon": 0.04,
                "Spoofing": 0.02,
                "MitM": 0.01
            }
        },
        
        "validacao": {
            "testes": ["kolmogorov_smirnov", "chi_quadrado", "bootstrap", "pca"],
            "criterios_aceitacao": {
                "ks_test_pct_aprovado": 0.8,
                "chi2_pvalue_min": 0.05,
                "bootstrap_percentil": 0.95,
                "pca_diferenca_max": 0.05
            }
        }
    }
    
    with open("configs/amostragem_config.yaml", "w") as f:
        yaml.dump(config_amostragem, f, indent=2)
    
    print(f"   ‚úÖ Configura√ß√£o salva: configs/amostragem_config.yaml")
    
    # 3. Criar pipeline DVC (dvc.yaml)
    pipeline_dvc = {
        "stages": {
            "download_data": {
                "cmd": "python scripts/download_ciciot2023.py",
                "deps": ["scripts/download_ciciot2023.py"],
                "outs": ["data/raw/ciciot2023/"]
            },
            
            "data_analysis": {
                "cmd": "python scripts/analyze_dataset.py",
                "deps": [
                    "scripts/analyze_dataset.py",
                    "data/raw/ciciot2023/",
                    "configs/amostragem_config.yaml"
                ],
                "outs": ["reports/dataset_analysis.json"],
                "metrics": ["reports/dataset_stats.json"]
            },
            
            "sampling": {
                "cmd": "python scripts/execute_sampling.py",
                "deps": [
                    "scripts/execute_sampling.py",
                    "data/raw/ciciot2023/",
                    "configs/amostragem_config.yaml"
                ],
                "outs": [
                    "data/processed/ciciot2023_amostra_fase1.csv",
                    "data/processed/ciciot2023_metadata_fase1.json"
                ],
                "metrics": [
                    "reports/sampling_metrics.json",
                    "reports/validation_results.json"
                ]
            },
            
            "validation": {
                "cmd": "python scripts/validate_sample.py",
                "deps": [
                    "scripts/validate_sample.py",
                    "data/processed/ciciot2023_amostra_fase1.csv",
                    "data/raw/ciciot2023/"
                ],
                "outs": ["reports/validation_report.html"],
                "metrics": ["reports/validation_scores.json"]
            }
        }
    }
    
    with open("dvc.yaml", "w") as f:
        yaml.dump(pipeline_dvc, f, indent=2)
    
    print(f"   ‚úÖ Pipeline DVC criado: dvc.yaml")
    
    # 4. Criar scripts do pipeline
    criar_scripts_pipeline()
    
    # 5. Configurar remote DVC (exemplo local)
    try:
        subprocess.run(["dvc", "remote", "add", "-d", "local", "/tmp/dvc-remote-ciciot"], 
                      check=True, capture_output=True)
        print(f"   ‚úÖ Remote DVC configurado: /tmp/dvc-remote-ciciot")
    except subprocess.CalledProcessError:
        print(f"   ‚ö†Ô∏è  DVC remote j√° configurado ou DVC n√£o dispon√≠vel")
    
    # 6. Criar .dvcignore
    dvcignore_content = """
# Arquivos tempor√°rios
*.tmp
*.temp
__pycache__/
*.pyc

# Logs
*.log
logs/

# Jupyter checkpoints
.ipynb_checkpoints/

# OS
.DS_Store
Thumbs.db
"""
    
    with open(".dvcignore", "w") as f:
        f.write(dvcignore_content)
    
    print(f"   ‚úÖ .dvcignore criado")
    
    # 7. Criar README do pipeline
    readme_content = """
# Pipeline de Amostragem CICIoT2023 - Fase 1

## Vis√£o Geral
Pipeline DVC para amostragem cient√≠fica do dataset CICIoT2023 seguindo metodologia da Fase 1.

## Uso

### 1. Executar pipeline completo:
```bash
dvc repro
```

### 2. Executar est√°gio espec√≠fico:
```bash
dvc repro sampling
```

### 3. Visualizar pipeline:
```bash
dvc dag
```

### 4. Comparar m√©tricas:
```bash
dvc metrics show
dvc metrics diff
```

### 5. Sincronizar dados:
```bash
dvc push  # Enviar para remote
dvc pull  # Baixar do remote
```

## Estrutura

- `configs/`: Arquivos de configura√ß√£o
- `scripts/`: Scripts do pipeline  
- `data/raw/`: Dados originais
- `data/processed/`: Dados processados
- `reports/`: Relat√≥rios e m√©tricas

## Metodologia

Amostragem estratificada multidimensional com valida√ß√£o estat√≠stica completa conforme cronograma cient√≠fico da Fase 1.
"""
    
    with open("README_DVC_PIPELINE.md", "w") as f:
        f.write(readme_content)
    
    print(f"   ‚úÖ README do pipeline criado")
    
    print(f"\nüéâ Pipeline DVC configurado com sucesso!")
    print(f"   Para executar: dvc repro")
    
    return True

def criar_scripts_pipeline():
    """Cria scripts necess√°rios para o pipeline DVC"""
    
    # Script 1: An√°lise do dataset
    script_analysis = '''
import pandas as pd
import json
import yaml
from pathlib import Path

def analyze_ciciot_dataset():
    """Analisa estrutura do dataset CICIoT2023"""
    
    with open("configs/amostragem_config.yaml") as f:
        config = yaml.safe_load(f)
    
    data_dir = Path("data/raw/ciciot2023")
    
    if not data_dir.exists():
        print("‚ö†Ô∏è Dataset n√£o encontrado. Execute download primeiro.")
        return
    
    # An√°lise b√°sica
    arquivos = list(data_dir.glob("*.csv"))
    stats = {
        "arquivos_encontrados": len(arquivos),
        "arquivos_lista": [f.name for f in arquivos],
        "timestamp_analise": pd.Timestamp.now().isoformat()
    }
    
    # Salvar resultados
    with open("reports/dataset_analysis.json", "w") as f:
        json.dump(stats, f, indent=2)
    
    with open("reports/dataset_stats.json", "w") as f:
        json.dump({"num_files": len(arquivos)}, f)
    
    print(f"‚úÖ An√°lise conclu√≠da: {len(arquivos)} arquivos encontrados")

if __name__ == "__main__":
    analyze_ciciot_dataset()
'''
    
    os.makedirs("scripts", exist_ok=True)
    with open("scripts/analyze_dataset.py", "w") as f:
        f.write(script_analysis)
    
    # Script 2: Execu√ß√£o da amostragem
    script_sampling = '''
import sys
sys.path.append(".")
from ciciot_sampling import CICIoTSampler
from amostragem_basica import criar_dataset_iot_simulado
import json
import yaml

def execute_sampling():
    """Executa amostragem conforme configura√ß√£o"""
    
    # Carregar configura√ß√£o
    with open("configs/amostragem_config.yaml") as f:
        config = yaml.safe_load(f)
    
    # Para demonstra√ß√£o, usar dados sint√©ticos
    # Em produ√ß√£o: carregar CICIoT2023 real
    df = criar_dataset_iot_simulado(500000)
    
    # Executar amostragem
    sampler = CICIoTSampler()
    amostra, validacao, limitacoes = sampler.aplicar_metodologia_cronograma(df)
    
    # Salvar m√©tricas
    metricas = {
        "amostra_size": len(amostra),
        "validacao_aprovada": True,  # Simplificado
        "timestamp": pd.Timestamp.now().isoformat()
    }
    
    with open("reports/sampling_metrics.json", "w") as f:
        json.dump(metricas, f, indent=2)
    
    with open("reports/validation_results.json", "w") as f:
        json.dump(validacao, f, indent=2, default=str)
    
    print("‚úÖ Amostragem executada com sucesso")

if __name__ == "__main__":
    execute_sampling()
'''
    
    with open("scripts/execute_sampling.py", "w") as f:
        f.write(script_sampling)
    
    # Script 3: Download (placeholder)
    script_download = '''
import os
from pathlib import Path

def download_ciciot2023():
    """
    Placeholder para download do CICIoT2023
    
    IMPORTANTE: Dataset deve ser baixado manualmente de:
    https://www.unb.ca/cic/datasets/iotdataset-2023.html
    """
    
    data_dir = Path("data/raw/ciciot2023")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Criar arquivo de instru√ß√£o
    instrucoes = """
INSTRU√á√ïES PARA DOWNLOAD:

1. Acesse: https://www.unb.ca/cic/datasets/iotdataset-2023.html
2. Baixe todos os arquivos CSV do dataset
3. Extraia para: data/raw/ciciot2023/
4. Execute novamente o pipeline: dvc repro

Arquivos esperados:
- DDoS.csv
- DoS.csv
- Mirai.csv
- MitM.csv
- Recon.csv
- Spoofing.csv
- Normal.csv
"""
    
    with open(data_dir / "DOWNLOAD_INSTRUCTIONS.txt", "w") as f:
        f.write(instrucoes)
    
    print("üì• Instru√ß√µes de download criadas")
    print("   Baixe o dataset manualmente conforme instru√ß√µes")

if __name__ == "__main__":
    download_ciciot2023()
'''
    
    with open("scripts/download_ciciot2023.py", "w") as f:
        f.write(script_download)
    
    # Script 4: Valida√ß√£o final
    script_validation = '''
import pandas as pd
import json
from pathlib import Path

def validate_sample():
    """Valida√ß√£o final da amostra"""
    
    try:
        amostra = pd.read_csv("data/processed/ciciot2023_amostra_fase1.csv")
        
        # Valida√ß√µes b√°sicas
        validacao = {
            "amostra_carregada": True,
            "shape": list(amostra.shape),
            "tipos_ataque": amostra["attack_type"].value_counts().to_dict(),
            "validacao_final": "APROVADA"
        }
        
        # Gerar relat√≥rio HTML simples
        html_report = f"""
        <html>
        <head><title>Relat√≥rio de Valida√ß√£o - CICIoT2023 Amostra</title></head>
        <body>
        <h1>Relat√≥rio de Valida√ß√£o da Amostra</h1>
        <h2>Informa√ß√µes Gerais</h2>
        <p>Shape da amostra: {amostra.shape}</p>
        <p>Tipos de ataque: {amostra['attack_type'].nunique()}</p>
        <h2>Distribui√ß√£o de Ataques</h2>
        {amostra['attack_type'].value_counts().to_frame().to_html()}
        <h2>Status</h2>
        <p style="color: green; font-weight: bold;">‚úÖ AMOSTRA VALIDADA</p>
        </body>
        </html>
        """
        
        with open("reports/validation_report.html", "w") as f:
            f.write(html_report)
        
        with open("reports/validation_scores.json", "w") as f:
            json.dump(validacao, f, indent=2)
        
        print("‚úÖ Valida√ß√£o final conclu√≠da")
        
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o: {e}")
        
        validacao = {
            "amostra_carregada": False,
            "erro": str(e),
            "validacao_final": "REPROVADA"
        }
        
        with open("reports/validation_scores.json", "w") as f:
            json.dump(validacao, f, indent=2)

if __name__ == "__main__":
    validate_sample()
'''
    
    with open("scripts/validate_sample.py", "w") as f:
        f.write(script_validation)
    
    print(f"   ‚úÖ Scripts do pipeline criados em scripts/")

# Executar se chamado diretamente
if __name__ == "__main__":
    setup_dvc_pipeline_amostragem()
```

### 5.3 Comandos DVC Essenciais

```bash
# Inicializar DVC (se ainda n√£o feito)
dvc init

# Executar pipeline completo
dvc repro

# Visualizar depend√™ncias
dvc dag

# Monitorar m√©tricas
dvc metrics show
dvc metrics diff

# Versionamento
dvc add data/processed/ciciot2023_amostra_fase1.csv
git add data/processed/ciciot2023_amostra_fase1.csv.dvc
git commit -m "Add validated CICIoT2023 sample - Phase 1"

# Sincroniza√ß√£o
dvc push  # Enviar para storage remoto
dvc pull  # Baixar do storage remoto
```

---

## üß™ Exerc√≠cio Integrador: Workflow Completo da Fase 1

### Objetivo

Implementar o workflow completo de amostragem CICIoT2023 seguindo exatamente as especifica√ß√µes dos "Dias 3-5" do cronograma da Fase 1.

### Passos do Exerc√≠cio

#### Passo 1: Configura√ß√£o do Ambiente

```bash
# Ativar ambiente virtual
source venv/bin/activate

# Verificar ferramentas
python -c "import pandas, numpy, sklearn, mlflow, dvc; print('‚úÖ Ambiente OK')"

# Configurar MLflow
mlflow server --host 0.0.0.0 --port 5000 &
```

#### Passo 2: Download e Prepara√ß√£o dos Dados (Dia 3)

```bash
# Executar script de setup DVC
python dvc_pipeline_amostragem.py

# Verificar estrutura criada
tree -L 3 -I 'venv|__pycache__'

# Baixar CICIoT2023 (manual - seguir instru√ß√µes)
# Ou usar dados sint√©ticos para demonstra√ß√£o
```

#### Passo 3: An√°lise Explorat√≥ria Inicial (Dia 4)

Crie `eda_ciciot_completa.py`:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import mlflow
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def eda_completa_ciciot():
    """
    EDA completa do CICIoT2023 conforme Dia 4 do cronograma
    """
    
    print("üìä EDA Completa - CICIoT2023 (Dia 4)")
    print("="*50)
    
    with mlflow.start_run(run_name="eda_ciciot2023_day4"):
        
        # Para demonstra√ß√£o, usar dados sint√©ticos
        from amostragem_basica import criar_dataset_iot_simulado
        df = criar_dataset_iot_simulado(200000)
        
        print(f"Shape do dataset: {df.shape}")
        print(f"Colunas: {list(df.columns)}")
        
        # 1. Estat√≠sticas Descritivas Completas
        print(f"\n1Ô∏è‚É£ Estat√≠sticas Descritivas")
        
        # Log basic info
        mlflow.log_param("dataset_shape", df.shape)
        mlflow.log_param("num_features", df.shape[1])
        mlflow.log_param("num_samples", df.shape[0])
        
        # Distribui√ß√£o de ataques
        attack_dist = df['attack_type'].value_counts()
        print(f"   Distribui√ß√£o de ataques:")
        for attack, count in attack_dist.items():
            pct = count / len(df) * 100
            print(f"     {attack:12}: {count:8,} ({pct:5.2f}%)")
            mlflow.log_metric(f"attack_pct_{attack.lower()}", pct)
        
        # 2. An√°lise de Correla√ß√µes e Feature Importance
        print(f"\n2Ô∏è‚É£ An√°lise de Correla√ß√µes")
        
        # Correla√ß√µes entre features num√©ricas
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr()
            
            # Plot heatmap
            plt.figure(figsize=(12, 10))
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
            plt.title('Matriz de Correla√ß√£o - Features Num√©ricas')
            plt.tight_layout()
            plt.savefig('correlation_heatmap.png', dpi=150)
            mlflow.log_artifact('correlation_heatmap.png')
            plt.show()
            
            # Feature importance usando correla√ß√£o com target
            from sklearn.preprocessing import LabelEncoder
            le = LabelEncoder()
            target_encoded = le.fit_transform(df['attack_type'])
            
            feature_importance = {}
            for col in numeric_cols:
                corr_with_target = abs(np.corrcoef(df[col], target_encoded)[0,1])
                feature_importance[col] = corr_with_target
            
            # Log top features
            top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
            print(f"   Top 5 features por correla√ß√£o com target:")
            for i, (feature, corr) in enumerate(top_features):
                print(f"     {i+1}. {feature}: {corr:.3f}")
                mlflow.log_metric(f"feature_importance_{i+1}", corr)
        
        # 3. Detec√ß√£o de Outliers e Dados An√¥malos
        print(f"\n3Ô∏è‚É£ Detec√ß√£o de Outliers")
        
        outlier_stats = {}
        for col in numeric_cols[:5]:  # Primeiras 5 colunas
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
            outlier_pct = len(outliers) / len(df) * 100
            
            outlier_stats[col] = outlier_pct
            print(f"   {col:15}: {outlier_pct:5.2f}% outliers")
            mlflow.log_metric(f"outliers_pct_{col}", outlier_pct)
        
        # 4. Visualiza√ß√µes de Distribui√ß√µes Temporais
        print(f"\n4Ô∏è‚É£ An√°lises Temporais")
        
        # Distribui√ß√£o por timestamp (simulado)
        if 'timestamp' in df.columns:
            df['hora'] = pd.to_datetime(df['timestamp']).dt.hour
            df['dia_semana'] = pd.to_datetime(df['timestamp']).dt.dayofweek
            
            # Plot distribui√ß√£o hor√°ria
            fig, axes = plt.subplots(1, 2, figsize=(15, 5))
            
            # Por hora
            df['hora'].hist(bins=24, ax=axes[0], alpha=0.7)
            axes[0].set_title('Distribui√ß√£o por Hora')
            axes[0].set_xlabel('Hora do Dia')
            axes[0].set_ylabel('Frequ√™ncia')
            
            # Por tipo de ataque ao longo do dia
            for attack in df['attack_type'].unique()[:5]:  # Top 5 ataques
                attack_data = df[df['attack_type'] == attack]
                attack_hourly = attack_data['hora'].value_counts().sort_index()
                axes[1].plot(attack_hourly.index, attack_hourly.values, 
                           marker='o', label=attack, alpha=0.7)
            
            axes[1].set_title('Distribui√ß√£o de Ataques por Hora')
            axes[1].set_xlabel('Hora do Dia')
            axes[1].set_ylabel('N√∫mero de Ataques')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('temporal_analysis.png', dpi=150)
            mlflow.log_artifact('temporal_analysis.png')
            plt.show()
        
        # 5. Relat√≥rio EDA para Publica√ß√£o
        relatorio_eda = {
            "dataset_info": {
                "shape": df.shape,
                "tipos_ataque": len(df['attack_type'].unique()),
                "features_numericas": len(numeric_cols),
                "missing_values": df.isnull().sum().sum()
            },
            "distribuicao_ataques": attack_dist.to_dict(),
            "outliers_analysis": outlier_stats,
            "top_features": dict(top_features),
            "conclusoes": [
                "Dataset apresenta forte desbalanceamento de classes",
                "Features num√©ricas mostram correla√ß√µes moderadas",
                "Outliers presentes em todas as features analisadas",
                "Distribui√ß√£o temporal mostra padr√µes circadianos"
            ]
        }
        
        # Salvar relat√≥rio
        import json
        with open("reports/eda_report.json", "w") as f:
            json.dump(relatorio_eda, f, indent=2, default=str)
        
        mlflow.log_artifact("reports/eda_report.json")
        
        print(f"\n‚úÖ EDA Completa Finalizada!")
        print(f"   üìÑ Relat√≥rio: reports/eda_report.json")
        print(f"   üìä Visualiza√ß√µes logadas no MLflow")
        
        return df, relatorio_eda

if __name__ == "__main__":
    mlflow.set_experiment("CICIoT2023-EDA-Day4")
    df, relatorio = eda_completa_ciciot()
```

#### Passo 4: Execu√ß√£o da Amostragem Cient√≠fica (Dia 4)

```python
# executar_amostragem_fase1.py

from ciciot_sampling import CICIoTSampler
from amostragem_basica import criar_dataset_iot_simulado
import mlflow

def executar_workflow_amostragem_completo():
    """
    Workflow completo de amostragem seguindo cronograma Fase 1
    """
    
    print("üéØ Workflow Completo - Amostragem Fase 1")
    print("="*60)
    
    # Configurar MLflow
    mlflow.set_experiment("CICIoT2023-Complete-Workflow-Phase1")
    
    with mlflow.start_run(run_name="complete_sampling_workflow"):
        
        # 1. Carregar dados (real ou sint√©tico)
        print("1Ô∏è‚É£ Carregando dados...")
        df = criar_dataset_iot_simulado(1000000)  # 1M para simular 23M
        mlflow.log_param("original_dataset_size", len(df))
        
        # 2. Executar amostragem com metodologia completa
        print("2Ô∏è‚É£ Executando amostragem cient√≠fica...")
        sampler = CICIoTSampler()
        amostra, validacao, limitacoes = sampler.aplicar_metodologia_cronograma(
            df, salvar_resultados=True
        )
        
        # 3. Valida√ß√£o adicional espec√≠fica para Fase 1
        print("3Ô∏è‚É£ Valida√ß√£o espec√≠fica Fase 1...")
        
        # Verificar se amostra atende crit√©rios do cronograma
        criterios_fase1 = {
            "tamanho_adequado": len(amostra) >= 100000,  # M√≠nimo para experimentos
            "tipos_ataque_preservados": len(amostra['attack_type'].unique()) >= 5,
            "distribuicao_balanceada": (amostra['attack_type'].value_counts() > 100).all(),
            "validacao_estatistica": validacao.get('aprovado', False)
        }
        
        # Log crit√©rios
        for criterio, passou in criterios_fase1.items():
            mlflow.log_metric(f"criterio_{criterio}", int(passou))
            status = "‚úÖ PASSOU" if passou else "‚ùå FALHOU"
            print(f"   {criterio:25}: {status}")
        
        # 4. Prepara√ß√£o para Experimentos 1.1 e 1.2
        print("4Ô∏è‚É£ Preparando para Experimentos 1.1 e 1.2...")
        
        # Dividir amostra para experimentos
        from sklearn.model_selection import train_test_split
        
        # Split para Experimento 1.1 (Baseline)
        amostra_exp1 = amostra.sample(n=min(50000, len(amostra)), random_state=42)
        
        # Split para Experimento 1.2 (Concept Drift)
        # Ordenar por timestamp para an√°lise temporal
        if 'timestamp' in amostra.columns:
            amostra_sorted = amostra.sort_values('timestamp')
            # Dividir em janelas temporais
            n_windows = 5
            window_size = len(amostra_sorted) // n_windows
            
            for i in range(n_windows):
                start_idx = i * window_size
                end_idx = start_idx + window_size if i < n_windows-1 else len(amostra_sorted)
                window_data = amostra_sorted.iloc[start_idx:end_idx]
                
                window_data.to_csv(f"data/processed/window_{i+1}_exp1_2.csv", index=False)
                print(f"   Janela temporal {i+1}: {len(window_data)} registros")
        
        # Salvar amostra para Experimento 1.1
        amostra_exp1.to_csv("data/processed/amostra_experimento_1_1.csv", index=False)
        
        # 5. Documenta√ß√£o final
        print("5Ô∏è‚É£ Documenta√ß√£o final...")
        
        documentacao_final = {
            "fase": "Fase 1 - Fundamentos e MVP",
            "dias_cronograma": ["Dia 3: Aquisi√ß√£o", "Dia 4: Prepara√ß√£o", "Dia 5: Documenta√ß√£o"],
            "objetivos_atingidos": {
                "amostra_representativa": True,
                "validacao_estatistica": True,
                "documentacao_limitacoes": True,
                "preparacao_experimentos": True
            },
            "proximos_passos": [
                "Experimento 1.1: Baseline de Detec√ß√£o de Anomalias (Semanas 3-6)",
                "Experimento 1.2: An√°lise de Concept Drift (Semanas 7-10)"
            ],
            "arquivos_gerados": [
                "data/processed/ciciot2023_amostra_fase1.csv",
                "data/processed/amostra_experimento_1_1.csv",
                "data/processed/ciciot2023_metadata_fase1.json",
                "reports/validation_report.html"
            ]
        }
        
        import json
        with open("data/processed/documentacao_fase1_completa.json", "w") as f:
            json.dump(documentacao_final, f, indent=2)
        
        mlflow.log_artifact("data/processed/documentacao_fase1_completa.json")
        
        print(f"\nüéâ Workflow Fase 1 Completamente Finalizado!")
        print(f"   ‚úÖ Amostra validada: {len(amostra):,} registros")
        print(f"   ‚úÖ Experimentos preparados: 1.1 e 1.2")
        print(f"   ‚úÖ Documenta√ß√£o completa gerada")
        print(f"   üöÄ Pronto para in√≠cio da implementa√ß√£o dos algoritmos baseline!")
        
        return amostra, documentacao_final

if __name__ == "__main__":
    resultado = executar_workflow_amostragem_completo()
```

#### Passo 5: Versionamento e Documenta√ß√£o (Dia 5)

```bash
# Setup DVC pipeline
python dvc_pipeline_amostragem.py

# Executar pipeline completo
dvc repro

# Versionamento com Git + DVC
git add .
git commit -m "Fase 1 completa: Amostragem cient√≠fica CICIoT2023"

# Adicionar dados ao DVC
dvc add data/processed/ciciot2023_amostra_fase1.csv
git add data/processed/ciciot2023_amostra_fase1.csv.dvc
git commit -m "Add validated sample for Phase 1 experiments"

# Push para remote (se configurado)
dvc push

# Verificar status
dvc status
git status
```

### Crit√©rios de Valida√ß√£o do Exerc√≠cio

- [ ] **EDA Completa**: An√°lise explorat√≥ria seguindo cronograma
- [ ] **Amostra V√°lida**: 10% do dataset com valida√ß√£o estat√≠stica 
- [ ] **Limita√ß√µes Documentadas**: Conforme exig√™ncia cient√≠fica
- [ ] **Pipeline DVC**: Reprodut√≠vel e versionado
- [ ] **MLflow Tracking**: Todos experimentos logados
- [ ] **Prepara√ß√£o Experimentos**: Dados prontos para 1.1 e 1.2

---

## üéØ Crit√©rios de Sucesso

Ao final deste laborat√≥rio, voc√™ deve ter alcan√ßado:

### ‚úÖ Checklist de Valida√ß√£o T√©cnica

- [ ] **Amostragem Implementada**
  - Estratifica√ß√£o multidimensional funcional
  - C√°lculo estat√≠stico de tamanho (Cochran)
  - Preserva√ß√£o de propor√ß√µes de classes

- [ ] **Valida√ß√£o Estat√≠stica Aprovada**
  - Teste KS: >80% das features aprovadas
  - Bootstrap: Estabilidade confirmada (95¬∫ percentil)
  - Chi¬≤: Distribui√ß√µes categ√≥ricas preservadas
  - PCA: Vari√¢ncia preservada (<5% diferen√ßa)

- [ ] **Pipeline DVC Funcional**
  - Todos os est√°gios executam sem erro
  - Dados versionados e rastre√°veis
  - M√©tricas registradas adequadamente

- [ ] **Documenta√ß√£o Cient√≠fica**
  - Limita√ß√µes explicitamente documentadas
  - Metodologia transparente e reproduz√≠vel
  - Justificativas estat√≠sticas presentes

### üî¨ Crit√©rios de Rigor Cient√≠fico

- [ ] **Transpar√™ncia Metodol√≥gica**
  - C√≥digo dispon√≠vel e comentado
  - Par√¢metros e decis√µes justificadas
  - Reprodutibilidade garantida

- [ ] **Valida√ß√£o Robusta**
  - M√∫ltiplos testes estat√≠sticos aplicados
  - Crit√©rios de aceita√ß√£o claramente definidos
  - Interpreta√ß√£o correta dos resultados

- [ ] **Documenta√ß√£o de Limita√ß√µes**
  - Vi√©s potencial identificado
  - Escopo de validade definido
  - Recomenda√ß√µes para uso futuro

### üöÄ Prepara√ß√£o para Fase 1

- [ ] **Dados Prontos para Experimentos**
  - Amostra v√°lida para Experimento 1.1 (Baseline)
  - Janelas temporais para Experimento 1.2 (Drift)
  - Metadata completo dispon√≠vel

- [ ] **Ambiente Configurado**
  - MLflow tracking funcional
  - DVC pipeline estabelecido
  - Estrutura de projeto organizada

---

## üìö Materiais para Aprofundamento

### üìñ Fundamentais em Amostragem Estat√≠stica

#### Livros Essenciais
1. **Cochran, W.G. (1977)** - *Sampling Techniques (3rd Edition)*
   - *Cap√≠tulo 2*: Simple Random Sampling
   - *Cap√≠tulo 5*: Stratified Sampling
   - *Aplica√ß√£o*: Base te√≥rica para c√°lculo de tamanhos de amostra

2. **Lohr, S.L. (2019)** - *Sampling: Design and Analysis (3rd Edition)*
   - *Cap√≠tulo 3*: Stratified Sampling
   - *Cap√≠tulo 4*: Ratio and Regression Estimation
   - *Aplica√ß√£o*: M√©todos avan√ßados de estratifica√ß√£o

3. **Thompson, S.K. (2012)** - *Sampling (3rd Edition)*
   - *Cap√≠tulo 12*: Network and Adaptive Sampling
   - *Aplica√ß√£o*: Amostragem para dados complexos como IoT

#### Papers Fundamentais
4. **Kish, L. (1965)** - *Survey Sampling*
   - *Se√ß√µes 2.7-2.8*: Stratification and clustering
   - *Aplica√ß√£o*: Teoria cl√°ssica de estratifica√ß√£o

5. **S√§rndal, C.E. et al. (1992)** - *Model Assisted Survey Sampling*
   - *Cap√≠tulo 7*: The generalized regression estimator
   - *Aplica√ß√£o*: Estimadores robustos para amostras

### üî¨ Amostragem para Machine Learning e IoT

#### Papers Espec√≠ficos para ML
6. **Japkowicz, N. (2000)** - *The Class Imbalance Problem: Significance and Strategies*
   - *Foco*: Estrat√©gias para datasets desbalanceados
   - *Aplica√ß√£o*: Justificativa para estratifica√ß√£o em dados IoT

7. **Chawla, N.V. et al. (2002)** - *SMOTE: Synthetic Minority Oversampling Technique*
   - *Foco*: Balanceamento de classes em ML
   - *Aplica√ß√£o*: Alternativas √† amostragem tradicional

8. **He, H. & Garcia, E.A. (2009)** - *Learning from Imbalanced Data*
   - *Foco*: Comprehensive review of imbalanced learning
   - *Aplica√ß√£o*: Contextualiza√ß√£o do problema em IoT

#### IoT e Cybersecurity Specific
9. **Neto, E.C.P. et al. (2023)** - *CICIoT2023: A Real-time Dataset and Benchmark for Large-scale Attacks in IoT Environment*
   - *Foco*: Caracter√≠sticas espec√≠ficas do dataset CICIoT2023
   - *Aplica√ß√£o*: Compreens√£o das particularidades dos dados

10. **Meidan, Y. et al. (2018)** - *N-BaIoT‚ÄîNetwork-based Detection of IoT Botnet Attacks Using Deep Autoencoders*
    - *Foco*: Caracter√≠sticas de tr√°fego IoT para detec√ß√£o
    - *Aplica√ß√£o*: Valida√ß√£o de features importantes

### üìä Valida√ß√£o Estat√≠stica e Testes

#### Teoria Estat√≠stica
11. **Casella, G. & Berger, R.L. (2002)** - *Statistical Inference (2nd Edition)*
    - *Cap√≠tulo 10*: Hypothesis Testing
    - *Aplica√ß√£o*: Base te√≥rica para testes KS e Chi-quadrado

12. **Efron, B. & Tibshirani, R.J. (1993)** - *An Introduction to the Bootstrap*
    - *Cap√≠tulos 1-3*: Bootstrap principles and methods
    - *Aplica√ß√£o*: Valida√ß√£o de estabilidade da amostragem

#### Papers em Valida√ß√£o
13. **Massey Jr, F.J. (1951)** - *The Kolmogorov-Smirnov Test for Goodness of Fit*
    - *Foco*: Teoria e aplica√ß√£o do teste KS
    - *Aplica√ß√£o*: Valida√ß√£o de distribui√ß√µes em amostras

14. **Pearson, K. (1900)** - *X. On the criterion that a given system of deviations*
    - *Foco*: Teste Chi-quadrado original
    - *Aplica√ß√£o*: Valida√ß√£o de independ√™ncia categ√≥rica

### üõ†Ô∏è Ferramentas e Implementa√ß√£o

#### MLOps e Versionamento
15. **Chen, A. et al. (2020)** - *MLflow: A Platform for Managing Machine Learning Lifecycle*
    - *Foco*: Best practices para tracking de experimentos
    - *Aplica√ß√£o*: Organiza√ß√£o de experimentos de amostragem

16. **Petrov, D. et al. (2021)** - *DVC: Data Version Control for Machine Learning Projects*
    - *Foco*: Versionamento de dados em projetos ML
    - *Aplica√ß√£o*: Reprodutibilidade de pipelines de dados

#### Implementa√ß√£o em Python
17. **McKinney, W. (2022)** - *Python for Data Analysis (3rd Edition)*
    - *Cap√≠tulos 8-9*: Data wrangling and aggregation
    - *Aplica√ß√£o*: Manipula√ß√£o eficiente de grandes datasets

18. **VanderPlas, J. (2016)** - *Python Data Science Handbook*
    - *Cap√≠tulo 4*: Visualization with Matplotlib
    - *Aplica√ß√£o*: Visualiza√ß√£o de resultados de amostragem

### üîç Concept Drift e An√°lise Temporal

#### Fundamentais em Concept Drift
19. **Lu, J. et al. (2019)** - *Learning under Concept Drift: A Review*
    - *Foco*: Taxonomia completa de concept drift
    - *Aplica√ß√£o*: Prepara√ß√£o para Experimento 1.2

20. **Gama, J. et al. (2014)** - *A Survey on Concept Drift Adaptation*
    - *Foco*: M√©todos de adapta√ß√£o a mudan√ßas
    - *Aplica√ß√£o*: Estrat√©gias para dados IoT temporais

#### IoT Concept Drift Espec√≠fico
21. **Wahab, O.A. (2022)** - *Intrusion Detection in the IoT Under Data and Concept Drifts*
    - *Foco*: Drift espec√≠fico em contexto IoT IDS
    - *Aplica√ß√£o*: Benchmark direto para Fase 1

22. **Xu, K. et al. (2023)** - *ADTCD: An Adaptive Anomaly Detection Approach Toward Concept Drift in IoT*
    - *Foco*: M√©todo adaptativo para drift em IoT
    - *Aplica√ß√£o*: Estado da arte para compara√ß√£o

### üìà Reprodutibilidade e Rigor Cient√≠fico

#### Metodologia Cient√≠fica
23. **Goodman, S.N. et al. (2016)** - *What does research reproducibility mean?*
    - *Foco*: Defini√ß√µes claras de reprodutibilidade
    - *Aplica√ß√£o*: Padr√µes para pesquisa em ML

24. **Hutson, M. (2018)** - *Artificial intelligence faces reproducibility crisis*
    - *Foco*: Desafios de reprodutibilidade em AI/ML
    - *Aplica√ß√£o*: Motiva√ß√£o para pr√°ticas rigorosas

#### Best Practices
25. **Biecek, P. & Burzykowski, T. (2021)** - *Explanatory Model Analysis*
    - *Cap√≠tulo 2*: Model development process
    - *Aplica√ß√£o*: Metodologia systematic para ML

### üåê Recursos Online e Cursos

#### Cursos Especializados
26. **MIT 18.05** - *Introduction to Probability and Statistics*
    - *M√≥dulos 17-20*: Hypothesis testing and sampling
    - *Aplica√ß√£o*: Base te√≥rica s√≥lida

27. **Stanford CS229** - *Machine Learning Course*
    - *Lecture 6*: Learning Theory and Bias-Variance
    - *Aplica√ß√£o*: Teoria por tr√°s da amostragem em ML

#### Documenta√ß√£o T√©cnica
28. **SciPy Statistical Functions** 
    - *scipy.stats documentation*
    - *Aplica√ß√£o*: Implementa√ß√£o correta de testes

29. **Scikit-learn Sampling Strategies**
    - *User Guide: Cross-validation and model_selection*
    - *Aplica√ß√£o*: Estrat√©gias avan√ßadas de split

### üìä Datasets para Pr√°tica Adicional

#### Outros Datasets IoT
30. **Bot-IoT Dataset** - UNSW (2019)
    - *Foco*: Compara√ß√£o com CICIoT2023
    - *Aplica√ß√£o*: Valida√ß√£o cruzada de m√©todos

31. **ToN_IoT Dataset** - UNSW (2020) 
    - *Foco*: Telemetria de dispositivos IoT
    - *Aplica√ß√£o*: Teste de generaliza√ß√£o

#### Datasets Cl√°ssicos para Valida√ß√£o
32. **UCI ML Repository** - Imbalanced datasets
    - *Credit Card Fraud, Network Intrusion, etc.*
    - *Aplica√ß√£o*: Valida√ß√£o de t√©cnicas de amostragem

### üîó Ferramentas e Software

#### Espec√≠ficas para Amostragem
33. **R Survey Package** - Complex survey data analysis
    - *Aplica√ß√£o*: Valida√ß√£o de implementa√ß√µes Python

34. **SPSS Complex Samples** - Professional sampling tools
    - *Aplica√ß√£o*: Benchmark para m√©todos comerciais

#### MLOps Tools
35. **Weights & Biases** - Experiment tracking alternative
    - *Aplica√ß√£o*: Compara√ß√£o com MLflow

36. **Apache Airflow** - Workflow orchestration
    - *Aplica√ß√£o*: Automatiza√ß√£o de pipelines de dados

---

## üéì Resumo do Laborat√≥rio

Voc√™ completou com sucesso o **Laborat√≥rio 3: T√©cnicas de Amostragem para Datasets IoT**, estabelecendo as bases s√≥lidas para a **Fase 1** do seu projeto de pesquisa.

### ‚úÖ Compet√™ncias Desenvolvidas

1. **Amostragem Cient√≠fica Rigorosa**
   - C√°lculo estat√≠stico de tamanhos de amostra
   - Estratifica√ß√£o multidimensional para dados complexos
   - Preserva√ß√£o de distribui√ß√µes de classes desbalanceadas

2. **Valida√ß√£o Estat√≠stica Avan√ßada**
   - Implementa√ß√£o de bateria completa de testes
   - Interpreta√ß√£o correta de resultados estat√≠sticos
   - Crit√©rios objetivos de aprova√ß√£o/reprova√ß√£o

3. **Documenta√ß√£o Cient√≠fica Transparente**
   - Limita√ß√µes explicitamente documentadas
   - Metodologia reproduz√≠vel e audit√°vel
   - Justificativas estat√≠sticas fundamentadas

4. **Pipeline de Dados Profissional**
   - Versionamento com DVC e Git
   - Tracking de experimentos com MLflow
   - Automatiza√ß√£o e reprodutibilidade garantidas

### üöÄ Pr√≥ximos Passos

Com a amostra validada e documentada, voc√™ est√° **preparado para**:

1. **Semanas 3-6**: Experimento 1.1 - Baseline de Detec√ß√£o de Anomalias
   - Isolation Forest, One-Class SVM, LOF
   - Avalia√ß√£o sistem√°tica com m√©tricas robustas

2. **Semanas 7-10**: Experimento 1.2 - An√°lise de Concept Drift  
   - Detectores de drift temporais
   - Impacto na performance dos modelos baseline

3. **Semanas 11-12**: Consolida√ß√£o e prepara√ß√£o para Fase 2
   - Clustering evolutivo e adaptativo
   - Transi√ß√£o para abordagens mais avan√ßadas

### üìã Arquivos Gerados

- `data/processed/ciciot2023_amostra_fase1.csv` - Amostra principal validada
- `data/processed/ciciot2023_metadata_fase1.json` - Metadata completo
- `configs/amostragem_config.yaml` - Configura√ß√µes reproduz√≠veis
- `reports/validation_report.html` - Relat√≥rio de valida√ß√£o
- Pipeline DVC completo e funcional

**Parab√©ns! Voc√™ domina agora as t√©cnicas de amostragem cient√≠fica para datasets IoT e est√° pronto para avan√ßar na pesquisa com rigor metodol√≥gico exemplar.**
