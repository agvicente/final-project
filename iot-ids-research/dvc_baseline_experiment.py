#!/usr/bin/env python3
"""
Arquivo DVC para executar experimentos de baseline com compara√ß√£o de algoritmos de ML

Este script √© usado no pipeline DVC para executar experimentos sistem√°ticos
de compara√ß√£o entre diferentes algoritmos de Machine Learning para detec√ß√£o
de anomalias em dados de IoT.

Data: 2025
"""

import os
import sys
import logging
import yaml
import time
from pathlib import Path

# Configurar logging
# Criar diret√≥rio de logs se n√£o existir
os.makedirs('experiments/logs', exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('experiments/logs/dvc_experiment.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def setup_experiment_environment():
    """
    Configura o ambiente para execu√ß√£o dos experimentos
    """
    logger.info("üîß Configurando ambiente de experimentos...")
    
    # Criar diret√≥rios necess√°rios
    dirs_to_create = [
        'experiments/results',
        'experiments/logs',
        'experiments/models',
        'experiments/artifacts'
    ]
    
    for dir_path in dirs_to_create:
        os.makedirs(dir_path, exist_ok=True)
        logger.info(f"   ‚úÖ Diret√≥rio criado/verificado: {dir_path}")
    
    # Verificar se os dados preprocessados existem
    required_files = [
        'data/processed/binary/X_train_binary.npy',
        'data/processed/binary/X_test_binary.npy', 
        'data/processed/binary/y_train_binary.npy',
        'data/processed/binary/y_test_binary.npy',
        'data/processed/binary/binary_metadata.json'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        logger.error(f"‚ùå Arquivos de dados necess√°rios n√£o encontrados:")
        for file_path in missing_files:
            logger.error(f"   - {file_path}")
        logger.error("Execute primeiro o pipeline de preprocessing (dvc repro preprocess)")
        sys.exit(1)
    
    logger.info("‚úÖ Ambiente configurado com sucesso!")
    return True

def load_experiment_config():
    """
    Carrega configura√ß√µes de experimento
    """
    logger.info("üìÑ Carregando configura√ß√µes de experimento...")
    
    # Configura√ß√µes padr√£o
    config = {
        'experiment': {
            'name': 'baseline_comparison',
            'version': '1.0',
            'test_mode': False,  # Mudar para False para experimento completo
            'description': 'Compara√ß√£o de algoritmos de ML para detec√ß√£o de anomalias em IoT'
        },
        'data': {
            'binary_data_dir': 'data/processed/binary/',
            'sample_size_test': 1000,
            'sample_size_full': None
        },
        'algorithms': {
            'n_runs': 1,  # Para teste r√°pido
            'n_runs_full': 5,  # Para experimento completo
            'random_state': 42
        },
        'mlflow': {
            'tracking_uri': 'http://127.0.0.1:5000',
            'experiment_prefix': 'IoT-IDS-Baseline'
        },
        'output': {
            'results_dir': 'experiments/results',
            'models_dir': 'experiments/models',
            'artifacts_dir': 'experiments/artifacts'
        }
    }
    
    # Verificar se existe arquivo de configura√ß√£o personalizado
    config_file = 'configs/experiment_config.yaml'
    if os.path.exists(config_file):
        logger.info(f"   üìÅ Carregando configura√ß√£o personalizada: {config_file}")
        try:
            with open(config_file, 'r') as f:
                custom_config = yaml.safe_load(f)
            
            # Merge das configura√ß√µes
            def deep_merge(base, custom):
                for key, value in custom.items():
                    if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                        deep_merge(base[key], value)
                    else:
                        base[key] = value
            
            deep_merge(config, custom_config)
            logger.info("   ‚úÖ Configura√ß√£o personalizada carregada")
            
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Erro ao carregar config personalizada: {e}")
            logger.info("   üîÑ Usando configura√ß√µes padr√£o")
    else:
        logger.info("   üîÑ Usando configura√ß√µes padr√£o")
        
        # Criar arquivo de configura√ß√£o padr√£o
        os.makedirs('configs', exist_ok=True)
        with open(config_file, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, indent=2)
        logger.info(f"   üíæ Arquivo de configura√ß√£o padr√£o criado: {config_file}")
    
    return config

def run_experiments(config):
    """
    Executa os experimentos de compara√ß√£o de algoritmos
    """
    logger.info("üöÄ Iniciando execu√ß√£o dos experimentos...")
    
    # Importar o m√≥dulo de compara√ß√£o de algoritmos
    sys.path.insert(0, 'experiments')
    
    try:
        from algorithm_comparison import (
            compare_algorithms, 
            save_results_and_plots,
            TEST_MODE,
            SAMPLE_SIZE,
            N_RUNS
        )
        
        logger.info("   ‚úÖ M√≥dulo de compara√ß√£o importado com sucesso")
        
        # Configurar modo de execu√ß√£o baseado na configura√ß√£o
        test_mode = config['experiment']['test_mode']
        logger.info(f"   üîß Modo de execu√ß√£o: {'TESTE' if test_mode else 'COMPLETO'}")
        
        # Atualizar vari√°veis globais se necess√°rio
        if not test_mode:
            # Para modo completo, sobrescrever as configura√ß√µes
            import algorithm_comparison
            algorithm_comparison.TEST_MODE = True
            algorithm_comparison.SAMPLE_SIZE = config['data']['sample_size_full']
            algorithm_comparison.N_RUNS = config['algorithms']['n_runs_full']
            logger.info("   üîÑ Configura√ß√µes atualizadas para modo teste")
        
        # Executar experimentos
        logger.info("   üî¨ Executando compara√ß√£o de algoritmos...")
        start_time = time.time()
        
        results = compare_algorithms()
        
        execution_time = time.time() - start_time
        logger.info(f"   ‚è±Ô∏è Tempo total de execu√ß√£o: {execution_time:.2f}s")
        
        # Salvar resultados e gerar visualiza√ß√µes
        logger.info("   üìä Salvando resultados e gerando visualiza√ß√µes...")
        results_file = save_results_and_plots(results, config['output']['results_dir'])
        
        # Log estat√≠sticas finais
        successful_results = [r for r in results if r['success']]
        failed_results = [r for r in results if not r['success']]
        
        logger.info(f"   ‚úÖ Experimentos bem-sucedidos: {len(successful_results)}")
        logger.info(f"   ‚ùå Experimentos com falha: {len(failed_results)}")
        
        if failed_results:
            logger.warning("   ‚ö†Ô∏è Experimentos que falharam:")
            for result in failed_results:
                logger.warning(f"      - {result['algorithm']}: {result['error']}")
        
        logger.info(f"   üìÅ Resultados salvos em: {results_file}")
        
        return {
            'success': True,
            'results_file': results_file,
            'total_experiments': len(results),
            'successful_experiments': len(successful_results),
            'failed_experiments': len(failed_results),
            'execution_time': execution_time
        }
        
    except ImportError as e:
        logger.error(f"‚ùå Erro ao importar m√≥dulo de compara√ß√£o: {e}")
        logger.error("Verifique se o arquivo experiments/algorithm_comparison.py existe e est√° correto")
        return {'success': False, 'error': str(e)}
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante execu√ß√£o dos experimentos: {e}")
        return {'success': False, 'error': str(e)}

def save_experiment_metadata(config, results):
    """
    Salva metadados do experimento
    """
    logger.info("üíæ Salvando metadados do experimento...")
    
    metadata = {
        'experiment_info': {
            'timestamp': time.time(),
            'date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'version': config['experiment']['version'],
            'mode': 'TEST' if config['experiment']['test_mode'] else 'FULL'
        },
        'config': config,
        'results': results,
        'system_info': {
            'python_version': sys.version,
            'platform': sys.platform,
            'working_directory': os.getcwd()
        }
    }
    
    metadata_file = os.path.join(
        config['output']['artifacts_dir'], 
        f"experiment_metadata_{int(time.time())}.yaml"
    )
    
    try:
        with open(metadata_file, 'w') as f:
            yaml.dump(metadata, f, default_flow_style=False, indent=2)
        
        logger.info(f"   ‚úÖ Metadados salvos: {metadata_file}")
        return metadata_file
        
    except Exception as e:
        logger.error(f"   ‚ùå Erro ao salvar metadados: {e}")
        return None

def main():
    """
    Fun√ß√£o principal do script DVC
    """
    logger.info("="*80)
    logger.info("üß™ INICIANDO EXPERIMENTOS DE BASELINE - IoT IDS")
    logger.info("="*80)
    
    try:
        # 1. Configurar ambiente
        setup_experiment_environment()
        
        # 2. Carregar configura√ß√µes
        config = load_experiment_config()
        
        # 3. Executar experimentos
        results = run_experiments(config)
        
        # 4. Salvar metadados
        metadata_file = save_experiment_metadata(config, results)
        
        # 5. Resultado final
        if results['success']:
            logger.info("="*80)
            logger.info("‚úÖ EXPERIMENTOS CONCLU√çDOS COM SUCESSO!")
            logger.info(f"üìä Total de experimentos: {results['total_experiments']}")
            logger.info(f"‚úÖ Bem-sucedidos: {results['successful_experiments']}")
            logger.info(f"‚ùå Com falha: {results['failed_experiments']}")
            logger.info(f"‚è±Ô∏è Tempo total: {results['execution_time']:.2f}s")
            logger.info(f"üìÅ Resultados: {results['results_file']}")
            if metadata_file:
                logger.info(f"üìÑ Metadados: {metadata_file}")
            logger.info("="*80)
            return 0
        else:
            logger.error("="*80)
            logger.error("‚ùå EXPERIMENTOS FALHARAM!")
            logger.error(f"Erro: {results.get('error', 'Erro desconhecido')}")
            logger.error("="*80)
            return 1
            
    except Exception as e:
        logger.error("="*80)
        logger.error("üí• ERRO CR√çTICO NO SCRIPT DVC!")
        logger.error(f"Erro: {str(e)}")
        logger.error("="*80)
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
