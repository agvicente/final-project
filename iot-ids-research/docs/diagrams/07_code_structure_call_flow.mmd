%% ========================================
%% Diagrama 7C: Fluxo de Chamadas de Funções
%% Formato: Mermaid (Sequence Diagram)
%% Mostra a sequência de chamadas durante execução de experimento
%% ========================================

sequenceDiagram
    participant CLI as 🖥️ CLI/DVC
    participant Main as 📋 run_single_algorithm.py
    participant Core as 🧠 algorithm_comparison.py
    participant Metrics as 📊 enhanced_metrics_collector
    participant ML as 🤖 sklearn Models
    participant MLflow as 🗂️ MLflow
    participant FS as 💾 File System
    participant Analysis as 📈 individual_analysis.py
    participant Consolidate as 🔗 consolidate_results.py
    
    Note over CLI,Consolidate: Fase 1: Inicialização e Setup
    
    CLI->>Main: python run_single_algorithm.py <algorithm>
    activate Main
    
    Main->>Core: import algorithm_comparison
    Main->>Core: run_experiment(algorithm_name)
    activate Core
    
    Core->>Core: setup_logging()
    Note over Core: Create log file with execution_id<br/>Configure handlers
    
    Core->>Core: create_result_directory()
    Note over Core: experiments/results/test or full/<br/>timestamp_algorithm/
    
    Core->>Metrics: get_system_info()
    activate Metrics
    Metrics-->>Core: system_info dict
    deactivate Metrics
    
    Note over CLI,Consolidate: Fase 2: Carregamento de Dados
    
    Core->>FS: Load binary data
    activate FS
    FS-->>Core: X_train, X_test, y_train, y_test
    deactivate FS
    
    Core->>Core: validate_data_shapes()
    
    alt TEST_MODE = True
        Core->>Core: sample_data(size=1000)
        Note over Core: Reduce dataset for testing
    end
    
    Core->>Core: get_algorithm_configs(algorithm)
    Note over Core: Retrieve hyperparameter grid<br/>from ALGORITHM_CONFIGS dict
    
    Note over CLI,Consolidate: Fase 3: Loop de Execuções (N_RUNS)
    
    loop For each param_config in configs
        loop For run in range(N_RUNS)
            
            Core->>Metrics: monitor_resource_usage_detailed() [START]
            activate Metrics
            Metrics-->>Core: baseline_snapshot
            deactivate Metrics
            
            Note over Core,ML: Fase 3.1: Treinamento
            
            Core->>Core: train_model(X_train, y_train, params)
            activate Core
            
            Core->>ML: model = Algorithm(**params)
            activate ML
            ML-->>Core: model instance
            
            Core->>ML: model.fit(X_train, y_train)
            Note over ML: Training in progress...<br/>Monitor time
            ML-->>Core: fitted model
            deactivate ML
            
            Core->>Core: training_time = end - start
            deactivate Core
            
            Note over Core,ML: Fase 3.2: Predição
            
            Core->>Core: predict_model(model, X_test)
            activate Core
            
            Core->>ML: y_pred = model.predict(X_test)
            activate ML
            ML-->>Core: predictions
            deactivate ML
            
            Core->>Core: prediction_time = end - start
            Core->>Core: throughput = len(X_test) / time
            deactivate Core
            
            Note over Core,ML: Fase 3.3: Métricas
            
            Core->>Core: calculate_metrics(y_test, y_pred)
            activate Core
            
            Core->>ML: accuracy_score(y_test, y_pred)
            activate ML
            ML-->>Core: accuracy
            deactivate ML
            
            Core->>ML: precision_score(...)
            activate ML
            ML-->>Core: precision
            deactivate ML
            
            Core->>ML: recall_score(...)
            activate ML
            ML-->>Core: recall
            deactivate ML
            
            Core->>ML: f1_score(...)
            activate ML
            ML-->>Core: f1
            deactivate ML
            
            Core->>ML: balanced_accuracy_score(...)
            activate ML
            ML-->>Core: balanced_acc
            deactivate ML
            
            Core->>ML: roc_auc_score(...)
            activate ML
            ML-->>Core: roc_auc
            deactivate ML
            
            Core->>ML: confusion_matrix(...)
            activate ML
            ML-->>Core: conf_matrix
            deactivate ML
            
            deactivate Core
            
            Note over Core,Metrics: Fase 3.4: Recursos
            
            Core->>Metrics: monitor_resource_usage_detailed() [END]
            activate Metrics
            Metrics-->>Core: final_snapshot
            deactivate Metrics
            
            Core->>Metrics: collect_enhanced_metrics(baseline, final)
            activate Metrics
            Metrics->>Metrics: calculate_deltas()
            Metrics->>Metrics: get_cpu_details()
            Metrics->>Metrics: get_memory_details()
            Metrics-->>Core: enhanced_metrics
            deactivate Metrics
            
            Note over Core,MLflow: Fase 3.5: Logging
            
            Core->>MLflow: mlflow.start_run()
            activate MLflow
            
            Core->>MLflow: mlflow.log_params(algorithm, config)
            Core->>MLflow: mlflow.log_metrics(accuracy, f1, ...)
            Core->>MLflow: mlflow.log_metrics(training_time, memory, ...)
            Core->>MLflow: mlflow.sklearn.log_model(model)
            
            MLflow-->>Core: run_id
            deactivate MLflow
            
            Note over Core,FS: Fase 3.6: Persistência
            
            Core->>FS: Save results.json
            activate FS
            Note over FS: timestamp_algorithm/results.json<br/>All runs aggregated
            FS-->>Core: success
            deactivate FS
            
        end
    end
    
    Note over CLI,Consolidate: Fase 4: Análise Individual
    
    Core->>Analysis: analyze_single_algorithm(results_dir)
    activate Analysis
    
    Analysis->>FS: Load results.json
    activate FS
    FS-->>Analysis: all_runs_data
    deactivate FS
    
    Analysis->>Analysis: aggregate_by_params()
    Note over Analysis: Calculate mean & std<br/>per param_id
    
    Analysis->>Analysis: generate_plots()
    Note over Analysis: - Performance plots<br/>- Resource usage<br/>- Parameter sensitivity
    
    Analysis->>FS: Save plots & summary
    activate FS
    Note over FS: individual_analysis/<br/>  plots/<br/>  tables/<br/>  summary.json
    FS-->>Analysis: success
    deactivate FS
    
    deactivate Analysis
    
    Core-->>Main: experiment_complete
    deactivate Core
    Main-->>CLI: exit(0)
    deactivate Main
    
    Note over CLI,Consolidate: Fase 5: Consolidação (Após todos algoritmos)
    
    CLI->>Consolidate: python consolidate_results.py
    activate Consolidate
    
    Consolidate->>FS: Load all algorithm results
    activate FS
    loop For each algorithm
        FS-->>Consolidate: summary.json
    end
    deactivate FS
    
    Consolidate->>Consolidate: compare_algorithms()
    Note over Consolidate: Cross-algorithm comparison<br/>Rankings, Pareto frontier
    
    Consolidate->>Consolidate: generate_all_iot_advanced_plots()
    Note over Consolidate: - Comparison charts<br/>- Radar plots<br/>- Scalability analysis
    
    Consolidate->>FS: Save consolidated results
    activate FS
    Note over FS: timestamp_consolidation/<br/>  plots/<br/>  tables/<br/>  consolidated_summary.json
    FS-->>Consolidate: success
    deactivate FS
    
    Consolidate-->>CLI: ✅ All experiments complete
    deactivate Consolidate
    
    Note over CLI,Consolidate: 🎉 Experimentos Concluídos

