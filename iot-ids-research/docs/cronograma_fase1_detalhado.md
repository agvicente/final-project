# Cronograma Detalhado - Fase 1: Fundamentos e MVP
## Detec√ß√£o de Intrus√£o Baseada em Anomalias em Sistemas IoT com Clustering Evolutivo

### üìã Vis√£o Geral da Fase 1
**Dura√ß√£o Total**: 12 semanas (3 meses)  
**Objetivo Principal**: Estabelecer fundamentos s√≥lidos e criar MVP public√°vel  
**Meta de Publica√ß√£o**: 1 workshop paper + 1 conference paper  

---

## üéØ Objetivos Estrat√©gicos da Fase 1

### Objetivos Prim√°rios
1. **Estabelecer Baseline Cient√≠fico**: Criar linha de base robusta para compara√ß√µes futuras
2. **Validar Metodologia de Amostragem**: Demonstrar representatividade estat√≠stica da amostra
3. **Identificar Concept Drift**: Quantificar mudan√ßas temporais em dados IoT
4. **Preparar Base para Fase 2**: Garantir transi√ß√£o suave para clustering evolutivo

### Objetivos Secund√°rios
1. **Setup Completo do Ambiente**: Infraestrutura reproduz√≠vel e escal√°vel
2. **Documenta√ß√£o Cient√≠fica**: Metodologia transparente e replic√°vel
3. **Valida√ß√£o de Hip√≥teses**: Confirma√ß√£o de pressupostos para trabalho futuro
4. **Networking Acad√™mico**: Primeira publica√ß√£o para estabelecer presen√ßa

---

## üìä Metodologia de Amostragem Cient√≠fica

### Estrat√©gia de Amostragem para CICIoT2023

#### Tamanho da Amostra
- **Amostra Principal**: 10% do dataset completo (~2.3M registros de 23M)
- **Justificativa Estat√≠stica**: 
  - Margem de erro: ¬±0.3% (confian√ßa 95%)
  - Power analysis para detectar diferen√ßas de ‚â•5% entre classes
  - Baseado em Cochran (1977) para popula√ß√µes finitas

#### M√©todo de Sele√ß√£o
```python
# Estratifica√ß√£o por:
# 1. Tipo de ataque (propor√ß√£o mantida)
# 2. Tipo de dispositivo (distribui√ß√£o preservada)  
# 3. Per√≠odo temporal (coverage de 24h)
# 4. Volume de tr√°fego (picos e vales representados)

stratified_sample = {
    'normal': 70%,      # ~1.6M registros
    'ddos': 15%,        # ~345K registros  
    'mirai': 8%,        # ~184K registros
    'recon': 4%,        # ~92K registros
    'spoofing': 2%,     # ~46K registros
    'mitm': 1%          # ~23K registros
}
```

#### Valida√ß√£o da Representatividade
1. **Teste Kolmogorov-Smirnov**: Comparar distribui√ß√µes amostra vs. popula√ß√£o
2. **Teste Chi-quadrado**: Verificar independ√™ncia temporal
3. **An√°lise de Componentes Principais**: Preserva√ß√£o da vari√¢ncia
4. **Bootstrap Sampling**: Estabilidade dos resultados (n=1000)

#### Documenta√ß√£o da Limita√ß√£o
```
LIMITA√á√ïES EXPL√çCITAS:
- Resultados podem variar com dataset completo
- Ataques raros podem estar sub-representados
- Padr√µes sazonais longos podem n√£o aparecer
- Valida√ß√£o futura necess√°ria em escala completa
```

---

## üìÖ Cronograma Semanal Detalhado

### **Semanas 1-2: Setup e Prepara√ß√£o**

#### Semana 1: Infraestrutura e Ambiente
**Dias 1-2: Setup do Ambiente**
- [ ] Configura√ß√£o do workspace Python (venv, requirements.txt)
- [ ] Setup MLflow + DVC para tracking
- [ ] Configura√ß√£o Docker para reprodutibilidade
- [ ] Setup Jupyter Lab com extens√µes necess√°rias

**Dias 3-4: Aquisi√ß√£o e Prepara√ß√£o de Dados**
- [ ] Download do CICIoT2023 dataset
- [ ] An√°lise explorat√≥ria inicial (shape, missing values, distributions)
- [ ] Implementa√ß√£o da estrat√©gia de amostragem estratificada
- [ ] Valida√ß√£o estat√≠stica da representatividade

**Dia 5: Documenta√ß√£o e Versionamento**
- [ ] Setup Git LFS para dados grandes
- [ ] Cria√ß√£o da estrutura de pastas do projeto
- [ ] Documenta√ß√£o inicial da metodologia
- [ ] Primeiro commit com ambiente funcionando

**Ferramentas**: Python 3.9+, pandas, numpy, scikit-learn, MLflow, DVC, Docker

#### Semana 2: An√°lise Explorat√≥ria Profunda
**Dias 1-2: EDA Quantitativa**
- [ ] Estat√≠sticas descritivas completas
- [ ] An√°lise de correla√ß√µes e feature importance
- [ ] Detec√ß√£o de outliers e dados an√¥malos
- [ ] Visualiza√ß√µes de distribui√ß√µes temporais

**Dias 3-4: EDA Qualitativa**
- [ ] An√°lise de padr√µes de tr√°fego por tipo de dispositivo
- [ ] Identifica√ß√£o de caracter√≠sticas espec√≠ficas por ataque
- [ ] An√°lise de sazonalidade e tend√™ncias temporais
- [ ] Mapeamento de features mais discriminativas

**Dia 5: Relat√≥rio EDA**
- [ ] Notebook completo com findings
- [ ] Visualiza√ß√µes profissionais para publica√ß√£o
- [ ] Identifica√ß√£o de challenges espec√≠ficos
- [ ] Prepara√ß√£o para pr√≥xima fase

**Leituras Obrigat√≥rias**:
- Neto et al. (2023) - CICIoT2023 dataset paper
- Cook et al. (2020) - Anomaly detection for IoT time-series: A survey
- Benkhelifa et al. (2018) - Critical review of IDS practices in IoT

---

### **Semanas 3-6: Experimento 1.1 - Baseline de Detec√ß√£o de Anomalias**

#### Semana 3: Pr√©-processamento e Feature Engineering
**Dias 1-2: Limpeza e Normaliza√ß√£o**
- [ ] Implementa√ß√£o de pipeline de limpeza robusto
- [ ] Tratamento de valores missing (estrat√©gias m√∫ltiplas)
- [ ] Normaliza√ß√£o e padroniza√ß√£o (StandardScaler, MinMaxScaler)
- [ ] An√°lise de impacto das transforma√ß√µes

**Dias 3-4: Feature Engineering**
- [ ] Cria√ß√£o de features temporais (hora, dia da semana, etc.)
- [ ] Features de agrega√ß√£o (rolling statistics)
- [ ] Encoding de vari√°veis categ√≥ricas
- [ ] Feature selection baseada em m√©trica F1

**Dia 5: Valida√ß√£o do Pipeline**
- [ ] Testes de robustez do pipeline
- [ ] Valida√ß√£o com dados sint√©ticos
- [ ] Documenta√ß√£o completa do processo
- [ ] Benchmark de tempo de processamento

**Ferramentas**: sklearn.preprocessing, pandas.tools, feature-engine

#### Semana 4: Implementa√ß√£o dos Algoritmos Baseline
**Dias 1-2: Isolation Forest**
- [ ] Implementa√ß√£o com hyperparameter tuning
- [ ] Grid search para par√¢metros √≥timos
- [ ] An√°lise de sensibilidade a outliers
- [ ] Estudo de escalabilidade temporal

**Dias 3-4: One-Class SVM e LOF**
- [ ] Implementa√ß√£o e tuning de One-Class SVM
- [ ] Local Outlier Factor com otimiza√ß√£o
- [ ] Compara√ß√£o de kernels (RBF, linear, polynomial)
- [ ] An√°lise de complexidade computacional

**Dia 5: Integra√ß√£o e Testes**
- [ ] Pipeline unificado para os 3 algoritmos
- [ ] Testes de performance e mem√≥ria
- [ ] Valida√ß√£o cruzada temporal
- [ ] Prepara√ß√£o para avalia√ß√£o sistem√°tica

**Leituras Obrigat√≥rias**:
- Liu et al. (2008) - Isolation Forest
- Liu et al. (2012) - Isolation-Based Anomaly Detection
- Laskar et al. (2021) - Extending Isolation Forest via K-Means

#### Semana 5: Avalia√ß√£o Sistem√°tica
**Dias 1-2: M√©tricas Cl√°ssicas**
- [ ] Implementa√ß√£o de m√©tricas robustas (Precision, Recall, F1)
- [ ] ROC-AUC e PR-AUC para classes desbalanceadas
- [ ] Confusion matrices detalhadas por classe
- [ ] An√°lise de erros e casos edge

**Dias 3-4: M√©tricas Espec√≠ficas para IoT**
- [ ] Taxa de falsos positivos por tipo de dispositivo
- [ ] Lat√™ncia de detec√ß√£o (tempo real simulado)
- [ ] Robustez a varia√ß√µes de tr√°fego
- [ ] An√°lise de performance por per√≠odo temporal

**Dia 5: An√°lise Comparativa**
- [ ] Ranking estat√≠stico dos algoritmos
- [ ] Testes de signific√¢ncia (t-test, Wilcoxon)
- [ ] An√°lise de trade-offs (accuracy vs. speed)
- [ ] Identifica√ß√£o do melhor baseline

**Ferramentas**: sklearn.metrics, scipy.stats, seaborn, matplotlib

#### Semana 6: Documenta√ß√£o e Primeira Publica√ß√£o
**Dias 1-2: An√°lise de Resultados**
- [ ] Interpreta√ß√£o estat√≠stica dos resultados
- [ ] Identifica√ß√£o de limita√ß√µes e bias
- [ ] Compara√ß√£o com trabalhos relacionados
- [ ] Insights para melhorias futuras

**Dias 3-4: Reda√ß√£o Cient√≠fica**
- [ ] Abstract e introdu√ß√£o para workshop paper
- [ ] Metodologia detalhada e reproduz√≠vel
- [ ] Se√ß√£o de resultados com visualiza√ß√µes
- [ ] Discuss√£o cr√≠tica e trabalhos futuros

**Dia 5: Submiss√£o e C√≥digo**
- [ ] Revis√£o final do paper
- [ ] Submiss√£o para workshop (SBRC/WebMedia)
- [ ] Release do c√≥digo no GitHub
- [ ] Tag Git para experimento 1.1

**Meta de Publica√ß√£o**: Workshop paper sobre "Comparative Analysis of Classical Anomaly Detection in IoT: A Systematic Evaluation on CICIoT2023 Dataset"

---

### **Semanas 7-10: Experimento 1.2 - An√°lise de Concept Drift**

#### Semana 7: Fundamenta√ß√£o Te√≥rica e Setup
**Dias 1-2: Literatura Espec√≠fica**
- [ ] Estudo detalhado de Lu et al. (2019) - Learning under Concept Drift
- [ ] An√°lise de Wahab (2022) - Concept Drift in IoT IDS
- [ ] Review de m√©todos de detec√ß√£o de drift
- [ ] Identifica√ß√£o de gaps na literatura IoT

**Dias 3-4: Implementa√ß√£o de Detectores**
- [ ] ADWIN (Adaptive Windowing) implementation
- [ ] DDM (Drift Detection Method) implementation
- [ ] Page-Hinkley test para mudan√ßas abruptas
- [ ] KSWIN para drift gradual

**Dia 5: Valida√ß√£o com Dados Sint√©ticos**
- [ ] Cria√ß√£o de datasets com drift conhecido
- [ ] Valida√ß√£o da sensibilidade dos detectores
- [ ] Calibra√ß√£o de thresholds
- [ ] An√°lise de falsos positivos

**Ferramentas**: river (online ML), scipy.stats, numpy

#### Semana 8: An√°lise Temporal do Dataset
**Dias 1-2: Segmenta√ß√£o Temporal**
- [ ] Divis√£o do dataset em janelas temporais (1h, 6h, 24h)
- [ ] An√°lise de stationaridade (ADF test, KPSS test)
- [ ] Identifica√ß√£o de pontos de mudan√ßa
- [ ] Caracteriza√ß√£o de tipos de drift

**Dias 3-4: An√°lise Estat√≠stica de Drift**
- [ ] Teste de mudan√ßa de distribui√ß√£o (KS test)
- [ ] An√°lise de componentes principais temporal
- [ ] Medidas de diverg√™ncia (KL, Wasserstein)
- [ ] Quantifica√ß√£o da magnitude do drift

**Dia 5: Visualiza√ß√£o e Interpreta√ß√£o**
- [ ] Heatmaps de drift por feature
- [ ] Time series plots de m√©tricas de drift
- [ ] Correla√ß√£o entre drift e eventos externos
- [ ] Dashboard interativo para explora√ß√£o

**Leituras Obrigat√≥rias**:
- Xu et al. (2023) - ADTCD: Adaptive Anomaly Detection for IoT
- Bharani et al. (2024) - Comparative Study of Drift Detection
- Yang & Shami (2021) - Lightweight Concept Drift Detection Framework

#### Semana 9: Impacto do Drift nos Modelos Baseline
**Dias 1-2: Avalia√ß√£o Temporal**
- [ ] Re-avalia√ß√£o dos baselines em janelas temporais
- [ ] An√°lise de degrada√ß√£o de performance
- [ ] Identifica√ß√£o de per√≠odos cr√≠ticos
- [ ] Correla√ß√£o entre drift e accuracy

**Dias 3-4: Estrat√©gias de Adapta√ß√£o**
- [ ] Re-training incremental dos modelos
- [ ] Avalia√ß√£o de janelas de adapta√ß√£o
- [ ] Compara√ß√£o: modelo est√°tico vs. adaptativo
- [ ] An√°lise de custo-benef√≠cio da adapta√ß√£o

**Dia 5: S√≠ntese e Insights**
- [ ] Caracteriza√ß√£o completa do concept drift em IoT
- [ ] Recomenda√ß√µes para sistemas adaptativos
- [ ] Identifica√ß√£o de research gaps
- [ ] Prepara√ß√£o para clustering evolutivo

#### Semana 10: Paper de Concept Drift
**Dias 1-3: Reda√ß√£o Cient√≠fica**
- [ ] Introdu√ß√£o: problema do concept drift em IoT
- [ ] Metodologia: detectores e m√©tricas utilizadas
- [ ] Resultados: caracteriza√ß√£o quantitativa do drift
- [ ] Discuss√£o: implica√ß√µes para IDS adaptativos

**Dias 4-5: Revis√£o e Submiss√£o**
- [ ] Revis√£o t√©cnica e lingu√≠stica
- [ ] Submiss√£o para confer√™ncia (BRACIS/ENIAC)
- [ ] Prepara√ß√£o de slides para apresenta√ß√£o
- [ ] Atualiza√ß√£o do reposit√≥rio GitHub

**Meta de Publica√ß√£o**: Conference paper sobre "Characterizing Concept Drift in IoT Traffic: Implications for Adaptive Intrusion Detection Systems"

---

### **Semanas 11-12: Consolida√ß√£o e Transi√ß√£o para Fase 2**

#### Semana 11: Integra√ß√£o e An√°lise Global
**Dias 1-2: S√≠ntese dos Experimentos**
- [ ] Integra√ß√£o dos resultados dos experimentos 1.1 e 1.2
- [ ] An√°lise hol√≠stica: baseline + concept drift
- [ ] Identifica√ß√£o de sinergias e contradi√ß√µes
- [ ] Refinamento das hip√≥teses para Fase 2

**Dias 3-4: Prepara√ß√£o para Clustering Evolutivo**
- [ ] An√°lise de requisitos para algoritmos adaptativos
- [ ] Identifica√ß√£o de features mais est√°veis ao drift
- [ ] Estudo preliminar de Maia et al. (2020) - Mixture of Typicalities
- [ ] Design inicial da arquitetura evolutiva

**Dia 5: Valida√ß√£o da Base Te√≥rica**
- [ ] Review completo da literatura consultada
- [ ] Identifica√ß√£o de gaps para Fase 2
- [ ] Planejamento de leituras complementares
- [ ] Mapeamento de colabora√ß√µes potenciais

#### Semana 12: Documenta√ß√£o Final e Setup Fase 2
**Dias 1-2: Relat√≥rio T√©cnico Completo**
- [ ] Documento t√©cnico consolidado da Fase 1
- [ ] Metodologia reproduz√≠vel documentada
- [ ] Dataset e c√≥digo versionados (DVC + Git)
- [ ] Lessons learned e best practices

**Dias 3-4: Transi√ß√£o para Fase 2**
- [ ] Planejamento detalhado do Experimento 2.1
- [ ] Setup inicial para clustering evolutivo
- [ ] Prepara√ß√£o do ambiente de streaming
- [ ] Review do cronograma da Fase 2

**Dia 5: Checkpoint Final**
- [ ] Avalia√ß√£o dos objetivos alcan√ßados
- [ ] Identifica√ß√£o de desvios e ajustes necess√°rios
- [ ] Comunica√ß√£o de resultados aos orientadores
- [ ] Kick-off da Fase 2

---

## üõ†Ô∏è Ferramentas e Tecnologias por Categoria

### **Ambiente de Desenvolvimento**
```bash
# Core Python Stack
python==3.9.16
pandas==1.5.3
numpy==1.24.3
scikit-learn==1.2.2
matplotlib==3.7.1
seaborn==0.12.2
jupyter==1.0.0

# Machine Learning
isolation-forest==0.5.1
river==0.15.0  # Online ML library
imbalanced-learn==0.10.1

# Experiment Tracking
mlflow==2.3.1
dvc[all]==2.58.2
wandb==0.15.3

# Data Validation
great-expectations==0.16.4
pandas-profiling==3.6.6

# Development Tools
pytest==7.3.1
black==23.3.0
flake8==6.0.0
pre-commit==3.3.2
```

### **Infraestrutura**
- **Containeriza√ß√£o**: Docker + Docker Compose
- **Versionamento**: Git + Git LFS para datasets
- **CI/CD**: GitHub Actions para testes automatizados
- **Storage**: Local + Google Drive backup
- **Compute**: Jupyter Lab + Google Colab Pro (para experimentos pesados)

### **M√©tricas e Avalia√ß√£o**
```python
# M√©tricas Prim√°rias
metrics = {
    'classification': ['accuracy', 'precision', 'recall', 'f1', 'auc_roc', 'auc_pr'],
    'drift_detection': ['drift_magnitude', 'detection_delay', 'false_positive_rate'],
    'computational': ['training_time', 'inference_time', 'memory_usage'],
    'robustness': ['cross_validation_std', 'temporal_stability', 'noise_resistance']
}
```

---

## üìö Bibliografia Organizada por Experimento

### **Experimento 1.1: Baseline de Detec√ß√£o de Anomalias**

#### Leituras Essenciais (Semanas 1-3)
1. **Neto et al. (2023)** - CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment
   - *Foco*: Caracter√≠sticas do dataset, metodologia de coleta, benchmarks existentes
   - *Aplica√ß√£o*: Fundamenta√ß√£o para escolha do dataset e compara√ß√£o com trabalhos anteriores

2. **Liu et al. (2008)** - Isolation Forest  
   - *Foco*: Algoritmo base, complexidade computacional, casos de uso
   - *Aplica√ß√£o*: Implementa√ß√£o correta e otimizada do Isolation Forest

3. **Benkhelifa et al. (2018)** - A Critical Review of Practices and Challenges in Intrusion Detection Systems for IoT
   - *Foco*: Estado da arte em IDS para IoT, challenges espec√≠ficos
   - *Aplica√ß√£o*: Contextualiza√ß√£o do problema e justificativa da abordagem

#### Leituras Complementares (Semanas 4-6)
4. **Cook et al. (2020)** - Anomaly detection for iot time-series data: A survey
   - *Foco*: M√©todos espec√≠ficos para time series IoT
   - *Aplica√ß√£o*: Adapta√ß√µes necess√°rias para dados temporais

5. **Ahmad et al. (2021)** - Network intrusion detection system: A systematic study of machine learning and deep learning approaches
   - *Foco*: Compara√ß√£o sistem√°tica de abordagens ML/DL
   - *Aplica√ß√£o*: Positioning do trabalho no contexto atual

6. **Laskar et al. (2021)** - Extending Isolation Forest for Anomaly Detection in Big Data via K-Means
   - *Foco*: Melhorias do Isolation Forest para big data
   - *Aplica√ß√£o*: Poss√≠veis otimiza√ß√µes para o algoritmo baseline

### **Experimento 1.2: An√°lise de Concept Drift**

#### Leituras Essenciais (Semanas 7-8)
1. **Lu et al. (2019)** - Learning under Concept Drift: A Review
   - *Foco*: Taxonomia completa de concept drift, m√©todos de detec√ß√£o
   - *Aplica√ß√£o*: Base te√≥rica fundamental para an√°lise de drift

2. **Wahab (2022)** - Intrusion Detection in the IoT Under Data and Concept Drifts: Online Deep Learning Approach
   - *Foco*: Concept drift espec√≠fico em contexto IoT IDS
   - *Aplica√ß√£o*: Benchmark e compara√ß√£o direta com trabalho relacionado

3. **Xu et al. (2023)** - ADTCD: An Adaptive Anomaly Detection Approach Toward Concept Drift in IoT
   - *Foco*: M√©todo adaptativo para concept drift em IoT
   - *Aplica√ß√£o*: Estado da arte para compara√ß√£o e inspira√ß√£o

#### Leituras Complementares (Semanas 9-10)
4. **Bharani et al. (2024)** - Adaptive Real-Time Malware Detection for IoT Traffic Streams: A Comparative Study of Concept Drift Detection Techniques
   - *Foco*: Compara√ß√£o de t√©cnicas de detec√ß√£o de drift
   - *Aplica√ß√£o*: Metodologia comparativa e valida√ß√£o de resultados

5. **Yang & Shami (2021)** - A Lightweight Concept Drift Detection and Adaptation Framework for IoT Data Streams
   - *Foco*: Framework lightweight para IoT
   - *Aplica√ß√£o*: Inspira√ß√£o para implementa√ß√£o eficiente

---

## üìä Entreg√°veis Espec√≠ficos da Fase 1

### **Entreg√°veis T√©cnicos**
1. **C√≥digo Fonte Completo**
   - [ ] Pipeline de pr√©-processamento reproduz√≠vel
   - [ ] Implementa√ß√£o dos 3 algoritmos baseline
   - [ ] Framework de detec√ß√£o de concept drift
   - [ ] Scripts de avalia√ß√£o e visualiza√ß√£o
   - [ ] Documenta√ß√£o t√©cnica completa

2. **Datasets e Amostras**
   - [ ] Amostra estratificada do CICIoT2023 (validada estatisticamente)
   - [ ] Metadata completo da amostra
   - [ ] Datasets sint√©ticos para valida√ß√£o de drift
   - [ ] Splits temporais para avalia√ß√£o

3. **Resultados e M√©tricas**
   - [ ] Benchmarks completos dos algoritmos baseline
   - [ ] Caracteriza√ß√£o quantitativa do concept drift
   - [ ] An√°lise de correla√ß√£o drift-performance
   - [ ] M√©tricas de robustez e estabilidade

### **Entreg√°veis Cient√≠ficos**
1. **Workshop Paper** (Semana 6)
   - *T√≠tulo*: "Comparative Analysis of Classical Anomaly Detection in IoT: A Systematic Evaluation on CICIoT2023 Dataset"
   - *Venue*: SBRC Workshop ou WebMedia Workshop
   - *Contribui√ß√£o*: Baseline robusto e metodologia de amostragem

2. **Conference Paper** (Semana 10)
   - *T√≠tulo*: "Characterizing Concept Drift in IoT Traffic: Implications for Adaptive Intrusion Detection Systems"
   - *Venue*: BRACIS, ENIAC, ou SBSeg
   - *Contribui√ß√£o*: Primeira caracteriza√ß√£o abrangente de concept drift em dados IoT

3. **Relat√≥rio T√©cnico** (Semana 12)
   - Documenta√ß√£o completa da metodologia
   - Lessons learned e best practices
   - Roadmap detalhado para Fase 2
   - C√≥digo e dados versionados

### **Entreg√°veis de Infraestrutura**
1. **Ambiente Reproduz√≠vel**
   - [ ] Docker containers configurados
   - [ ] Requirements e environment specifications
   - [ ] Scripts de setup automatizado
   - [ ] CI/CD pipeline b√°sico

2. **Sistema de Tracking**
   - [ ] MLflow setup com experimentos categorizados
   - [ ] DVC pipeline para reprodu√ß√£o
   - [ ] Git hooks para versionamento autom√°tico
   - [ ] Dashboard de monitoramento

---

## üîÑ Crit√©rios de Sucesso e Checkpoints

### **Checkpoint Semana 4: Baseline Estabelecido**
**Crit√©rios de Sucesso:**
- [ ] Pipeline de dados funcionando sem erros
- [ ] 3 algoritmos baseline implementados e validados
- [ ] M√©tricas baseline: F1-Score > 80% para classe Normal
- [ ] Tempo de processamento: < 5min para amostra completa

**A√ß√µes se Crit√©rios n√£o Atingidos:**
- Revis√£o da estrat√©gia de pr√©-processamento
- Simplifica√ß√£o da amostra ou features
- Consulta com orientadores sobre ajustes

### **Checkpoint Semana 8: Concept Drift Identificado**
**Crit√©rios de Sucesso:**
- [ ] Detectores de drift implementados e calibrados
- [ ] Drift quantificado em pelo menos 3 dimens√µes
- [ ] Impacto na performance dos baselines mensurado
- [ ] Visualiza√ß√µes claras e interpret√°veis

**A√ß√µes se Crit√©rios n√£o Atingidos:**
- Revis√£o dos m√©todos de detec√ß√£o de drift
- An√°lise de janelas temporais alternativas
- Consulta da literatura adicional

### **Checkpoint Semana 12: Transi√ß√£o para Fase 2**
**Crit√©rios de Sucesso:**
- [ ] 2 papers submetidos com feedback positivo
- [ ] Base de c√≥digo est√°vel e documentada
- [ ] Insights claros para desenvolvimento do clustering evolutivo
- [ ] Ambiente pronto para Fase 2

**A√ß√µes se Crit√©rios n√£o Atingidos:**
- Extens√£o da Fase 1 por 2-4 semanas
- Prioriza√ß√£o dos elementos essenciais para Fase 2
- Replanejamento do cronograma geral

---

## üöÄ Ponte para Fase 2: Clustering Evolutivo

### **Prepara√ß√£o Espec√≠fica para Clustering Evolutivo**
1. **An√°lise de Features Est√°veis**: Identifica√ß√£o de features menos afetadas por concept drift
2. **Padr√µes Temporais**: Caracteriza√ß√£o de janelas √≥timas para adapta√ß√£o
3. **Metrics Benchmark**: Estabelecimento de m√©tricas base para compara√ß√£o
4. **Infrastructure**: Pipeline de streaming b√°sico preparado

### **Research Questions para Fase 2**
1. Como o clustering evolutivo se compara aos baselines estabelecidos?
2. Qual a frequ√™ncia √≥tima de adapta√ß√£o dos clusters?
3. Como balancear estabilidade vs. adaptabilidade?
4. Quais features s√£o mais importantes para forma√ß√£o de clusters?

### **Hip√≥teses Refinadas**
1. **H1**: Clustering evolutivo ter√° melhor recall para ataques novos/variantes
2. **H2**: Adapta√ß√£o cont√≠nua resultar√° em menor degrada√ß√£o temporal
3. **H3**: Trade-off existir√° entre lat√™ncia e precis√£o adaptativa
4. **H4**: Modelos device-specific superar√£o modelo generalista

---

## üìã Checklist Final de Valida√ß√£o

### **Valida√ß√£o Cient√≠fica**
- [ ] Metodologia de amostragem justificada e validada estatisticamente
- [ ] Limita√ß√µes explicitamente documentadas
- [ ] Resultados reproduz√≠veis com c√≥digo e dados versionados
- [ ] Compara√ß√£o justa com trabalhos relacionados
- [ ] Contribui√ß√µes cient√≠ficas claramente articuladas

### **Valida√ß√£o T√©cnica**
- [ ] C√≥digo passa em todos os testes automatizados
- [ ] Performance satisfaz requisitos de lat√™ncia (<100ms inference)
- [ ] Escalabilidade testada at√© limites da amostra
- [ ] Documenta√ß√£o permite reprodu√ß√£o independente
- [ ] Versionamento permite rollback e compara√ß√µes

### **Valida√ß√£o de Projeto**
- [ ] Cronograma seguido com desvios <10%
- [ ] Objetivos da Fase 1 completamente atendidos
- [ ] Base s√≥lida estabelecida para Fase 2
- [ ] Publica√ß√µes submetidas nos prazos
- [ ] Feedback dos orientadores incorporado

---

**Este cronograma garante uma Fase 1 s√≥lida, public√°vel e que estabelece fundamentos robustos para o desenvolvimento do clustering evolutivo na Fase 2. A aten√ß√£o especial √† metodologia de amostragem e valida√ß√£o estat√≠stica assegura rigor cient√≠fico, enquanto os checkpoints regulares permitem ajustes de curso quando necess√°rio.**