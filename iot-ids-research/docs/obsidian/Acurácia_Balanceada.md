# AcurÃ¡cia Balanceada (Balanced Accuracy)

> **Tipo:** MÃ©trica de AvaliaÃ§Ã£o  
> **Complexidade:** â­â­â˜†â˜†â˜† (IntermediÃ¡rio)  
> **AplicaÃ§Ã£o:** ClassificaÃ§Ã£o com Datasets Desbalanceados

---

## ğŸ¯ DefiniÃ§Ã£o

**AcurÃ¡cia Balanceada** Ã© a mÃ©dia aritmÃ©tica das acurÃ¡cias obtidas em **cada classe individualmente**, resolvendo o problema de [[AcurÃ¡cia|acurÃ¡cia tradicional]] em datasets desbalanceados.

**Pergunta que responde:**
> "Qual a mÃ©dia do meu desempenho em cada classe?"

**Proposta por:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Brodersen et al. (2010)]]

---

## ğŸ“ FÃ³rmula MatemÃ¡tica

### ClassificaÃ§Ã£o BinÃ¡ria

```
Balanced Accuracy = Â½ Ã— (Sensibilidade + Especificidade)

                  = Â½ Ã— (TP/P + TN/N)
                  
                  = Â½ Ã— (TP/(TP+FN) + TN/(TN+FP))
```

Onde:
- **TP/P:** Taxa de acerto na classe **positiva** (Sensibilidade/Recall)
- **TN/N:** Taxa de acerto na classe **negativa** (Especificidade)
- **P = TP + FN:** Total de positivos reais
- **N = TN + FP:** Total de negativos reais

### Forma Geral (Multiclasse)

```
Balanced Accuracy = (1/K) Ã— Î£áµ¢ (AcurÃ¡cia na classe i)
```

Onde K Ã© o nÃºmero de classes.

### Com Custos Personalizados

```
Balanced Accuracy = c Ã— (TP/P) + (1-c) Ã— (TN/N)
```

Onde c âˆˆ [0, 1] Ã© o custo/peso da classe positiva.

---

## ğŸ’¡ IntuiÃ§Ã£o: Por Que Funciona?

### O Problema com [[AcurÃ¡cia]] Tradicional

**CenÃ¡rio:** Dataset com 95 normais e 5 ataques.

**Modelo "preguiÃ§oso"** prevÃª tudo como "normal":

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classe Normal (95 exemplos):       â”‚
â”‚  Acertos: 95/95 = 100% âœ…           â”‚
â”‚                                      â”‚
â”‚  Classe Ataque (5 exemplos):        â”‚
â”‚  Acertos: 0/5 = 0% âŒ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AcurÃ¡cia Tradicional:
(95 + 0) / 100 = 95% â† Parece bom! ğŸ‰

AcurÃ¡cia Balanceada:
Â½(100% + 0%) = 50% â† NÃ­vel do acaso! âš ï¸
```

**A acurÃ¡cia balanceada REVELA a verdade:** o modelo nÃ£o aprendeu nada Ãºtil!

### Analogia do IDS

Imagine um guarda de seguranÃ§a que nunca aciona o alarme:
- **EstatÃ­stica enganosa:** "99% de precisÃ£o" (quase nunca hÃ¡ intrusos)
- **Realidade:** InÃºtil! Todos os intrusos passam!

A acurÃ¡cia balanceada detecta isso porque avalia **separadamente**:
- QuÃ£o bem detecta situaÃ§Ãµes normais?
- QuÃ£o bem detecta intrusos?

---

## ğŸ§® Exemplo Passo a Passo - [[AplicaÃ§Ã£o_ao_IoT_IDS|Sistema IDS]]

### CenÃ¡rio Realista: CICIoT2023

**Dataset de teste:**
- 100 conexÃµes normais
- 10 ataques

**Modelo detecta:**
- 95 conexÃµes normais corretamente (TN = 95)
- 5 falsos alarmes (FP = 5)
- 8 ataques corretamente (TP = 8)
- 2 ataques perdidos (FN = 2)

### Matriz de ConfusÃ£o

```
                 Predito
                 Ataque  Normal
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Ataque   â”‚   8 (TP) â”‚  2 (FN) â”‚  P = 10
  Real     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  Normal   â”‚   5 (FP) â”‚ 95 (TN) â”‚  N = 100
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Passo 1: AcurÃ¡cia na Classe Positiva (Ataques)

```
Sensibilidade = TP / (TP + FN)
              = 8 / (8 + 2)
              = 8 / 10
              = 0.80 = 80%
```

**InterpretaÃ§Ã£o:** O modelo detecta **80% dos ataques**.

### Passo 2: AcurÃ¡cia na Classe Negativa (Normais)

```
Especificidade = TN / (TN + FP)
               = 95 / (95 + 5)
               = 95 / 100
               = 0.95 = 95%
```

**InterpretaÃ§Ã£o:** O modelo classifica corretamente **95% do trÃ¡fego normal**.

### Passo 3: MÃ©dia das Duas

```
Balanced Accuracy = Â½ Ã— (80% + 95%)
                  = Â½ Ã— 175%
                  = 87.5%
```

### ComparaÃ§Ã£o

```
AcurÃ¡cia Tradicional = (TP + TN) / Total
                     = (8 + 95) / 110
                     = 103 / 110
                     = 93.6% âœ“

AcurÃ¡cia Balanceada = 87.5% âœ“
```

**Qual Ã© mais informativa?**
- AcurÃ¡cia tradicional: dominada pela classe majoritÃ¡ria (normal)
- AcurÃ¡cia balanceada: reflete desempenho **equilibrado** em ambas as classes

---

## âœ… Vantagens

### 1. Robusta a Desbalanceamento

DÃ¡ **peso igual** a cada classe, independente da quantidade de exemplos.

```
Dataset 1: 50/50 split
Dataset 2: 99/1 split

â†’ Ambos usam a mesma fÃ³rmula!
â†’ Resultados comparÃ¡veis!
```

### 2. Detecta Classificadores Enviesados

Modelos que "trapaceiam" explorando desbalanceamento sÃ£o penalizados:

```
Modelo que prevÃª sempre "majoritÃ¡ria":
â†’ 100% em uma classe
â†’ 0% na outra
â†’ BA = 50% (nÃ­vel do acaso)
```

### 3. InterpretaÃ§Ã£o Clara

**Significa:** "MÃ©dia de performance nas classes"
- BA = 50%: NÃ­vel do acaso
- BA = 100%: Perfeito em ambas
- BA entre 50-100%: Performance real

### 4. FÃ¡cil de Comparar Algoritmos

```
Algoritmo A: BA = 85%
Algoritmo B: BA = 78%

â†’ A Ã© melhor, considerando ambas as classes!
```

---

## âš ï¸ LimitaÃ§Ãµes

### 1. Assume Classes Igualmente Importantes

Se detectar ataques Ã© **3x mais importante** que nÃ£o dar falso alarme, BA simples nÃ£o reflete isso.

**SoluÃ§Ã£o:** Usar versÃ£o ponderada com custos.

### 2. InformaÃ§Ã£o Agregada

BA Ã© um nÃºmero Ãºnico, perde detalhes:
- Qual classe tem pior performance?
- Quantos FP vs FN?

**SoluÃ§Ã£o:** Reportar BA **junto com** matriz de confusÃ£o e mÃ©tricas individuais.

### 3. NÃ£o Considera DistribuiÃ§Ã£o Real

Em produÃ§Ã£o, classes podem ter proporÃ§Ã£o diferente do treino.

**Exemplo:**
- Treino: 50/50
- ProduÃ§Ã£o: 99/1
- BA otimiza para 50/50, pode nÃ£o ser ideal para 99/1

### 4. Multiclasse Complexo

Com K classes, todas recebem peso 1/K. Pode nÃ£o ser desejÃ¡vel.

---

## ğŸ“Š DistribuiÃ§Ã£o Posterior da Balanced Accuracy

### Abordagem Bayesiana (ContribuiÃ§Ã£o do [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo]])

Ao invÃ©s de reportar apenas um ponto, modelar a **distribuiÃ§Ã£o completa**.

### MatemÃ¡tica (ClassificaÃ§Ã£o BinÃ¡ria)

**AcurÃ¡cia em cada classe:**
```
A_pos ~ Beta(TP+1, FN+1)
A_neg ~ Beta(TN+1, FP+1)
```

**Balanced Accuracy:**
```
BA = Â½(A_pos + A_neg)
```

**DistribuiÃ§Ã£o de BA:** ConvoluÃ§Ã£o de duas Betas!

```
p_BA(x; TP, FP, FN, TN) = âˆ«â‚€Â¹ p_A(2(x-z); TP+1, FN+1) Â· p_A(2z; TN+1, FP+1) dz
```

Veja [[DistribuiÃ§Ã£o_Beta#ConvoluÃ§Ã£o|seÃ§Ã£o de convoluÃ§Ã£o]] para detalhes.

### Propriedades

- NÃ£o tem forma fechada analÃ­tica
- Requer integraÃ§Ã£o numÃ©rica
- Permite calcular intervalos de credibilidade

Detalhes completos em [[InferÃªncia_Bayesiana]].

---

## ğŸ§ª ImplementaÃ§Ã£o PrÃ¡tica

### Python (NumPy)

```python
import numpy as np

def balanced_accuracy(y_true, y_pred):
    """
    Calcula balanced accuracy para classificaÃ§Ã£o binÃ¡ria.
    
    Args:
        y_true: labels verdadeiros (0/1)
        y_pred: labels preditos (0/1)
    
    Returns:
        balanced accuracy
    """
    # Positivos e negativos
    pos_mask = (y_true == 1)
    neg_mask = (y_true == 0)
    
    # Sensibilidade (recall na classe positiva)
    sensitivity = np.sum(y_pred[pos_mask] == 1) / np.sum(pos_mask)
    
    # Especificidade (recall na classe negativa)
    specificity = np.sum(y_pred[neg_mask] == 0) / np.sum(neg_mask)
    
    # Balanced accuracy
    ba = 0.5 * (sensitivity + specificity)
    
    return ba

# Exemplo IoT-IDS
y_true = np.array([0,0,0,1,1,0,1,0,0,1,0,0,0,1])  # 4 ataques, 10 normais
y_pred = np.array([0,0,1,1,1,0,1,0,0,0,0,0,0,1])  # prediÃ§Ãµes

ba = balanced_accuracy(y_true, y_pred)
print(f"Balanced Accuracy: {ba:.2%}")  # 75%
```

### Python (Scikit-learn)

```python
from sklearn.metrics import balanced_accuracy_score, confusion_matrix

y_true = [0,0,0,1,1,0,1,0,0,1,0,0,0,1]
y_pred = [0,0,1,1,1,0,1,0,0,0,0,0,0,1]

# Balanced accuracy
ba = balanced_accuracy_score(y_true, y_pred)
print(f"Balanced Accuracy: {ba:.2%}")

# Para entender o resultado, veja a matriz
cm = confusion_matrix(y_true, y_pred)
print("\nMatriz de ConfusÃ£o:")
print(cm)
```

### Com DistribuiÃ§Ã£o Posterior

```python
from scipy import stats
import numpy as np

def balanced_accuracy_posterior(y_true, y_pred, n_samples=10000):
    """
    Calcula distribuiÃ§Ã£o posterior da balanced accuracy.
    
    Usa aproximaÃ§Ã£o por amostragem Monte Carlo da convoluÃ§Ã£o.
    """
    # Extrair TP, TN, FP, FN
    pos_mask = (y_true == 1)
    neg_mask = (y_true == 0)
    
    TP = np.sum((y_pred == 1) & pos_mask)
    FN = np.sum((y_pred == 0) & pos_mask)
    TN = np.sum((y_pred == 0) & neg_mask)
    FP = np.sum((y_pred == 1) & neg_mask)
    
    # Posteriors para cada classe
    pos_posterior = stats.beta(TP + 1, FN + 1)
    neg_posterior = stats.beta(TN + 1, FP + 1)
    
    # Amostrar da convoluÃ§Ã£o
    pos_samples = pos_posterior.rvs(n_samples)
    neg_samples = neg_posterior.rvs(n_samples)
    ba_samples = 0.5 * (pos_samples + neg_samples)
    
    return {
        'mean': np.mean(ba_samples),
        'median': np.median(ba_samples),
        'std': np.std(ba_samples),
        'ci_95': np.percentile(ba_samples, [2.5, 97.5]),
        'samples': ba_samples
    }

# Exemplo
y_true = np.random.randint(0, 2, 100)
y_pred = (np.random.rand(100) > 0.3).astype(int)

result = balanced_accuracy_posterior(y_true, y_pred)
print(f"BA mÃ©dia: {result['mean']:.3f}")
print(f"IC 95%: [{result['ci_95'][0]:.3f}, {result['ci_95'][1]:.3f}]")
```

### Multiclasse

```python
from sklearn.metrics import balanced_accuracy_score

# 3 classes: normal, DoS, reconnaissance
y_true = [0,0,0,1,1,2,1,0,0,2,0,0,0,1]
y_pred = [0,0,1,1,1,2,1,0,0,1,0,0,0,1]

ba = balanced_accuracy_score(y_true, y_pred)
print(f"Balanced Accuracy (multiclasse): {ba:.2%}")
```

---

## ğŸ“Š Quando Usar Balanced Accuracy?

### âœ… Use Quando:

1. **Dataset desbalanceado** (proporÃ§Ãµes muito diferentes)
2. **Todas as classes sÃ£o importantes** (nÃ£o pode ignorar minoritÃ¡rias)
3. **Comparar algoritmos** em diferentes datasets
4. **Reportar para academia** (mÃ©trica bem estabelecida)

### ğŸ¯ Contextos Ideais:

- [[AplicaÃ§Ã£o_ao_IoT_IDS|DetecÃ§Ã£o de intrusÃ£o]] (ataques raros)
- DetecÃ§Ã£o de fraude (transaÃ§Ãµes fraudulentas raras)
- DiagnÃ³stico mÃ©dico (doenÃ§as raras)
- DetecÃ§Ã£o de anomalias (eventos raros)

### âš ï¸ Considere Alternativas Quando:

1. **Classes tÃªm importÃ¢ncia diferente** â†’ Use F1-Score ponderado ou mÃ©trica customizada
2. **Precisa de threshold flexÃ­vel** â†’ Use ROC-AUC ou PR-AUC
3. **Foco em uma classe especÃ­fica** â†’ Use Precision/Recall daquela classe

---

## ğŸ”„ RelaÃ§Ã£o com Outras MÃ©tricas

### vs. [[AcurÃ¡cia]] Tradicional

```
Dataset balanceado: BA â‰ˆ Accuracy
Dataset desbalanceado: BA < Accuracy (geralmente)
```

### vs. F1-Score

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

- **F1:** Foca na classe positiva (mÃ©dia harmÃ´nica de precision e recall)
- **BA:** Considera ambas as classes igualmente (mÃ©dia aritmÃ©tica)

**Quando usar qual?**
- F1: Quando classe positiva Ã© mais importante
- BA: Quando ambas as classes sÃ£o igualmente importantes

### vs. ROC-AUC

```
ROC-AUC: Ãrea sob curva ROC
```

- **ROC-AUC:** Avalia em todos os thresholds possÃ­veis
- **BA:** Avalia em um threshold especÃ­fico

**Complementares:** Use ambos!

### Tabela Comparativa

| MÃ©trica | Balanceado | Desbalanceado | Classes Iguais | Threshold |
|---------|-----------|---------------|----------------|-----------|
| [[AcurÃ¡cia]] | âœ… | âŒ | âœ… | Fixo |
| **BA** | âœ… | âœ… | âœ… | Fixo |
| F1 | âœ… | âœ… | Foco em positiva | Fixo |
| ROC-AUC | âœ… | âœ… | âœ… | Todos |

---

## ğŸ“š ReferÃªncias

### Paper Original
- **Brodersen, K.H., et al.** (2010). "The balanced accuracy and its posterior distribution". *ICPR*. [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]

### Trabalhos Relacionados
- **Velez et al.** (2007). "A balanced accuracy function for epistasis modeling in imbalanced datasets". *Genetic Epidemiology*, 31(4), 306-315.
- **Japkowicz, N. & Stephen, S.** (2002). "The class imbalance problem: A systematic study". *Intelligent Data Analysis*, 6(5), 429-449.

### Livros
- **He, H. & Ma, Y.** (eds.) (2013). *Imbalanced Learning: Foundations, Algorithms, and Applications*. Wiley-IEEE Press.
- **Alpaydin, E.** (2020). *Introduction to Machine Learning* (4th ed.). MIT Press.

### Online
- [Scikit-learn: Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html)
- [Imbalanced-learn Library](https://imbalanced-learn.org/)

Veja [[ReferÃªncias_BibliogrÃ¡ficas]] para lista completa.

---

## ğŸ”— Conceitos Relacionados

### PrÃ©-requisitos
- [[AcurÃ¡cia]] - MÃ©trica bÃ¡sica
- [[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o]] - Para agregar resultados

### Teoria AvanÃ§ada
- [[DistribuiÃ§Ã£o_Beta]] - Modelagem probabilÃ­stica
- [[InferÃªncia_Bayesiana]] - Paradigma do artigo
- [[Intervalos_de_ConfianÃ§a]] - QuantificaÃ§Ã£o de incerteza

### Contexto
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]] - Artigo completo
- [[AplicaÃ§Ã£o_ao_IoT_IDS]] - AplicaÃ§Ã£o prÃ¡tica
- [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos]] - Abordagens de modelagem

---

## ğŸ¯ ExercÃ­cios

Veja [[ExercÃ­cios_PrÃ¡ticos#Balanced Accuracy]] para problemas.

---

## ğŸ“Œ Resumo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       BALANCED ACCURACY                      â”‚
â”‚                                              â”‚
â”‚  "MÃ©dia de acurÃ¡cia em cada classe"         â”‚
â”‚                                              â”‚
â”‚  FÃ³rmula: Â½(TP/P + TN/N)                    â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Classe +   â”‚      â”‚  Classe -   â”‚      â”‚
â”‚  â”‚  TP/P = 80% â”‚  +   â”‚  TN/N = 95% â”‚  Ã· 2 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â†“                    â†“              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                    â†“                        â”‚
â”‚              BA = 87.5%                     â”‚
â”‚                                              â”‚
â”‚  âœ… SoluÃ§Ã£o para desbalanceamento           â”‚
â”‚  âœ… Detecta classificadores enviesados      â”‚
â”‚  âœ… ComparÃ¡vel entre datasets               â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Tags:** #metrics #balanced-accuracy #classification #imbalanced-data #evaluation #IDS

**Voltar para:** [[INDEX]]  
**Artigo relacionado:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]  
**AplicaÃ§Ã£o:** [[AplicaÃ§Ã£o_ao_IoT_IDS]]

