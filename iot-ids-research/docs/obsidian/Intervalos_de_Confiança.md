# Intervalos de ConfianÃ§a

> **Tipo:** InferÃªncia EstatÃ­stica  
> **Complexidade:** â­â­â­â˜†â˜† (IntermediÃ¡rio)  
> **AplicaÃ§Ã£o:** QuantificaÃ§Ã£o de Incerteza

---

## ğŸ¯ O que Ã© um Intervalo de ConfianÃ§a?

Um **intervalo de confianÃ§a** (IC) expressa a **incerteza** sobre um parÃ¢metro desconhecido com base em dados observados.

**Pergunta que responde:**
> "Dado que observei estes dados, em que faixa de valores o verdadeiro parÃ¢metro provavelmente estÃ¡?"

---

## ğŸ§­ Duas Filosofias, Duas InterpretaÃ§Ãµes

### ğŸ”µ Abordagem Frequentista (ClÃ¡ssica)

**InterpretaÃ§Ã£o:**
> "Se repetirmos o experimento infinitas vezes, 95% dos intervalos construÃ­dos conterÃ£o o verdadeiro parÃ¢metro Î¸."

**CaracterÃ­sticas:**
- Î¸ Ã© **fixo mas desconhecido**
- O intervalo Ã© **aleatÃ³rio** (varia entre experimentos)
- NÃ£o se pode dizer "95% de probabilidade de Î¸ estar no intervalo"

**Analogia:**
Imagine jogar uma rede de pesca (o intervalo) em um ponto fixo no oceano (Î¸). Se vocÃª jogar 100 redes de tamanhos aleatÃ³rios, 95 delas capturarÃ£o aquele ponto.

### ğŸŸ¢ Abordagem Bayesiana (Do [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo]])

**InterpretaÃ§Ã£o:**
> "HÃ¡ 95% de probabilidade de Î¸ estar neste intervalo, dada a evidÃªncia observada."

**Nome alternativo:** **Intervalo de Credibilidade**

**CaracterÃ­sticas:**
- Î¸ Ã© **variÃ¡vel aleatÃ³ria** (tem distribuiÃ§Ã£o de probabilidade)
- O intervalo contÃ©m 95% da massa da distribuiÃ§Ã£o posterior
- InterpretaÃ§Ã£o probabilÃ­stica direta!

**Analogia:**
VocÃª tem um "mapa de probabilidade" mostrando onde Î¸ provavelmente estÃ¡. O intervalo marca a regiÃ£o que contÃ©m 95% da probabilidade.

Veja [[InferÃªncia_Bayesiana]] para detalhes do paradigma.

---

## ğŸ“Š ConstruÃ§Ã£o: Abordagem Frequentista

### Passo a Passo

**1. Coletar dados:** xâ‚, xâ‚‚, ..., xâ‚™

**2. Assumir distribuiÃ§Ã£o:** Ex: dados sÃ£o Normal(Î¼, ÏƒÂ²)

**3. Calcular estatÃ­stica:** Ex: xÌ„ (mÃ©dia amostral)

**4. Conhecer distribuiÃ§Ã£o amostral:** Ex: xÌ„ ~ Normal(Î¼, ÏƒÂ²/n)

**5. Construir intervalo:**
```
IC_{1-Î±} = [xÌ„ - z_{Î±/2} Ã— SE, xÌ„ + z_{Î±/2} Ã— SE]
```

### Exemplo: [[AcurÃ¡cia]] de IDS

```
Dados: 100 testes, 90 acertos
EstatÃ­stica: pÌ‚ = 90/100 = 0.90

DistribuiÃ§Ã£o amostral (aproximaÃ§Ã£o Normal):
pÌ‚ ~ Normal(p, p(1-p)/n)

Erro padrÃ£o:
SE = âˆš[pÌ‚(1-pÌ‚)/n] = âˆš[0.90Ã—0.10/100] = 0.03

IC 95% (z = 1.96):
[0.90 - 1.96Ã—0.03, 0.90 + 1.96Ã—0.03]
= [0.841, 0.959]
```

### Problema: [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos|Abordagem NÃ£o-ParamÃ©trica]]

**Se pÌ‚ = 0.98 e SE = 0.02:**
```
IC = [0.98 - 1.96Ã—0.02, 0.98 + 1.96Ã—0.02]
   = [0.941, 1.019]
```

**1.019?! 101.9%?!** ğŸš¨ AcurÃ¡cia nÃ£o pode ser > 100%!

**Problema fundamental:** A aproximaÃ§Ã£o Normal **nÃ£o respeita** os limites naturais [0, 1].

---

## ğŸ“ˆ ConstruÃ§Ã£o: Abordagem Bayesiana

### Passo a Passo

**1. Especificar prior:** P(Î¸) - crenÃ§a inicial

**2. Coletar dados:** X

**3. Calcular posterior:** P(Î¸|X) usando Teorema de Bayes

**4. Extrair intervalo:** RegiÃ£o que contÃ©m 95% da massa

### Exemplo: [[DistribuiÃ§Ã£o_Beta|AcurÃ¡cia com Beta]]

```
Prior: Î¸ ~ Beta(1, 1)  # Uniforme
Dados: 90 acertos, 10 erros
Posterior: Î¸ ~ Beta(91, 11)

IC 95% (intervalo de credibilidade):
[L, U] tal que âˆ«â‚—áµ˜ Beta(x; 91, 11) dx = 0.95

Usando scipy:
>>> from scipy import stats
>>> stats.beta.interval(0.95, 91, 11)
(0.838, 0.946)
```

**Vantagens:**
- âœ… Respeita limites [0, 1] naturalmente
- âœ… AssimÃ©trico quando apropriado
- âœ… InterpretaÃ§Ã£o probabilÃ­stica direta
- âœ… Funciona para qualquer n (nÃ£o precisa ser grande)

---

## ğŸšï¸ Tipos de Intervalos Bayesianos

### 1. Equal-Tailed Interval (Massa Central)

**DefiniÃ§Ã£o:** Deixa Î±/2 em cada cauda.

```
P(Î¸ < L) = Î±/2 = 0.025
P(Î¸ > U) = Î±/2 = 0.025
```

**CÃ¡lculo:**
```python
L = distribuicao.ppf(0.025)  # Quantil 2.5%
U = distribuicao.ppf(0.975)  # Quantil 97.5%
```

### 2. Highest Density Interval (HDI)

**DefiniÃ§Ã£o:** Menor intervalo que contÃ©m 95% da massa.

**Propriedade:** Todo ponto dentro tem densidade â‰¥ qualquer ponto fora.

**Vantagem:** Intervalo mais curto possÃ­vel!

```python
# Requer bibliotecas especiais (PyMC, arviz)
import arviz as az
hdi = az.hdi(samples, hdi_prob=0.95)
```

### ComparaÃ§Ã£o Visual

```
        Posterior Beta(91, 11)
           â•±â•²
          â•±  â•²
         â•±    â•²
        â•±      â•²___
       â•±            â•²
  â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€ Î¸
      L_et        U_et    (Equal-tailed)
      
      L_hdi    U_hdi      (HDI - mais curto!)
```

Para distribuiÃ§Ãµes simÃ©tricas: Equal-tailed = HDI  
Para assimÃ©tricas: HDI Ã© mais informativo

---

## ğŸ”„ ComparaÃ§Ã£o: Frequentista vs. Bayesiano

### Exemplo Lado a Lado

**Dados:** 98 acertos em 100 testes de [[AplicaÃ§Ã£o_ao_IoT_IDS|IDS]]

#### Frequentista (Normal Approximation)
```
pÌ‚ = 0.98
SE = âˆš[0.98Ã—0.02/100] = 0.014

IC 95% = [0.98 - 1.96Ã—0.014, 0.98 + 1.96Ã—0.014]
       = [0.953, 1.007]  â† 100.7%! âŒ
```

#### Frequentista (Wilson Score - corrigido)
```
IC 95% = [0.930, 0.995]  âœ…
(mais complexo, mas respeita limites)
```

#### Bayesiano (Beta)
```
Posterior: Beta(99, 3)

IC 95% = [0.932, 0.997]  âœ…
(natural, sem artifÃ­cios)
```

### Tabela Comparativa

| Aspecto | Frequentista | Bayesiano |
|---------|-------------|-----------|
| Î¸ Ã©... | Fixo desconhecido | VariÃ¡vel aleatÃ³ria |
| Interpreta 95% como... | % de intervalos que capturam Î¸ | Probabilidade de Î¸ estar lÃ¡ |
| Requer n grande? | Sim (para CLT) | NÃ£o |
| Respeita limites? | Depende do mÃ©todo | Sim (se prior adequado) |
| Incorpora conhecimento prÃ©vio? | NÃ£o | Sim |
| ComputaÃ§Ã£o | Geralmente analÃ­tica | Ã€s vezes numÃ©rica |

---

## ğŸ“ RelaÃ§Ã£o com [[DistribuiÃ§Ãµes_de_Probabilidade]]

### Por que Precisamos da DistribuiÃ§Ã£o?

**Sem distribuiÃ§Ã£o:**
```
Dados: 90/100
IC: ???  Â¯\_(ãƒ„)_/Â¯
```

**Com distribuiÃ§Ã£o (Beta):**
```
Dados: 90/100
Modelo: Î¸ ~ Beta(91, 11)
IC: [0.838, 0.946]  âœ…

AlÃ©m disso:
P(Î¸ > 0.85) = 0.973
P(Î¸ > 0.90) = 0.503
etc.
```

A distribuiÃ§Ã£o Ã© a **ponte** entre dados e inferÃªncia!

### Diferentes DistribuiÃ§Ãµes, Diferentes ICs

**Mesmo dado (90/100), diferentes modelos:**

```python
from scipy import stats

# Beta (para proporÃ§Ãµes)
beta_ic = stats.beta.interval(0.95, 91, 11)
# [0.838, 0.946]

# Normal (aproximaÃ§Ã£o)
from statsmodels.stats.proportion import proportion_confint
normal_ic = proportion_confint(90, 100, method='normal')
# [0.841, 0.959]

# Wilson Score (melhor aproximaÃ§Ã£o)
wilson_ic = proportion_confint(90, 100, method='wilson')
# [0.831, 0.946]
```

**A escolha da distribuiÃ§Ã£o importa!**

Veja [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos]] para discussÃ£o sobre escolhas de modelo.

---

## ğŸš€ AplicaÃ§Ã£o ao [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo Principal]]

### Problema 1 do Artigo: ICs Inadequados

**MÃ©todo tradicional ([[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o|com erro padrÃ£o]]):**
```
AcurÃ¡cia = 0.98 Â± 2Ã—SE
```

**Defeitos:**
- âŒ SimÃ©trico sempre
- âŒ Pode violar [0, 1]
- âŒ Assume normalidade

### SoluÃ§Ã£o do Artigo: Posterior Beta

**Para [[AcurÃ¡cia]]:**
```
A ~ Beta(C+1, I+1)
IC = quantis da posterior
```

**Para [[AcurÃ¡cia_Balanceada]]:**
```
BA distribuiÃ§Ã£o via convoluÃ§Ã£o de Betas
IC = quantis da posterior de BA
```

### Exemplo Comparativo do Artigo

**Dataset desbalanceado:** 45 positivos, 10 negativos  
**Classificador enviesado:** 48 pred. positivos, 7 pred. negativos

```
AcurÃ¡cia Tradicional:
IC 95%: [87%, 97%]  â† Sugere bom desempenho

AcurÃ¡cia Balanceada (Posterior):
IC 95%: [48%, 54%]  â† Revela nÃ­vel do acaso!
```

O intervalo da BA **expÃµe** o problema que acurÃ¡cia mascara!

---

## ğŸ§® ImplementaÃ§Ã£o PrÃ¡tica

### 1. Frequentista: ProporÃ§Ã£o

```python
from statsmodels.stats.proportion import proportion_confint

# Dados
sucessos = 90
tentativas = 100

# MÃ©todo Wilson (recomendado)
ci = proportion_confint(sucessos, tentativas, 
                        alpha=0.05, method='wilson')
print(f"IC 95%: [{ci[0]:.3f}, {ci[1]:.3f}]")
```

### 2. Bayesiano: Beta

```python
from scipy import stats

# Dados
C, I = 90, 10  # corretos, incorretos

# Posterior (prior uniforme)
posterior = stats.beta(C + 1, I + 1)

# Intervalo de credibilidade
ci = posterior.interval(0.95)
print(f"IC 95%: [{ci[0]:.3f}, {ci[1]:.3f}]")

# EstatÃ­sticas adicionais
print(f"MÃ©dia: {posterior.mean():.3f}")
print(f"Mediana: {posterior.median():.3f}")
print(f"Moda: {C/(C+I):.3f}")
```

### 3. Bayesiano: HDI

```python
import numpy as np
from scipy import stats

def hdi(distribution, credibility=0.95):
    """
    Calcula Highest Density Interval.
    
    Algoritmo: busca o menor intervalo que contÃ©m
    a massa de probabilidade desejada.
    """
    # Amostragem da posterior
    samples = distribution.rvs(100000)
    samples = np.sort(samples)
    
    # Tamanho do intervalo
    n = len(samples)
    interval_size = int(np.floor(credibility * n))
    
    # Buscar menor intervalo
    n_intervals = n - interval_size
    interval_widths = samples[interval_size:] - samples[:n_intervals]
    
    min_idx = np.argmin(interval_widths)
    hdi_min = samples[min_idx]
    hdi_max = samples[min_idx + interval_size]
    
    return (hdi_min, hdi_max)

# Uso
posterior = stats.beta(91, 11)
interval = hdi(posterior, 0.95)
print(f"HDI 95%: [{interval[0]:.3f}, {interval[1]:.3f}]")
```

### 4. Comparando MÃºltiplos Modelos

```python
from scipy import stats
import numpy as np

# Dois algoritmos
model_A = stats.beta(85 + 1, 15 + 1)  # 85/100
model_B = stats.beta(90 + 1, 10 + 1)  # 90/100

# Probabilidade de B > A
samples_A = model_A.rvs(100000)
samples_B = model_B.rvs(100000)
prob_B_better = np.mean(samples_B > samples_A)

print(f"P(B > A) = {prob_B_better:.3f}")
# Se > 0.95, B Ã© significativamente melhor!
```

---

## ğŸ“š ReferÃªncias

### Livros Fundamentais
- **Wasserman, L.** (2004). *All of Statistics*. Springer. [CapÃ­tulo 11: "Statistical Inference"]
- **Casella, G. & Berger, R.L.** (2002). *Statistical Inference* (2nd ed.). [SeÃ§Ã£o 9.2: "Interval Estimators"]
- **Gelman, A., et al.** (2013). *Bayesian Data Analysis* (3rd ed.). CRC Press. [CapÃ­tulo 4]

### Papers
- **Brodersen et al.** (2010). [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]
- **Agresti, A. & Coull, B.A.** (1998). "Approximate is better than 'exact' for interval estimation of binomial proportions". *The American Statistician*, 52(2), 119-126.
- **Brown, L.D., Cai, T.T., & DasGupta, A.** (2001). "Interval estimation for a binomial proportion". *Statistical Science*, 16(2), 101-133.

### Online
- [Seeing Theory: Confidence Intervals](https://seeing-theory.brown.edu/frequentist-inference/index.html)
- [3Blue1Brown: Bayesian Inference](https://www.youtube.com/watch?v=HZGCoVF3YvM)

Veja [[ReferÃªncias_BibliogrÃ¡ficas]] para lista completa.

---

## ğŸ”— Conceitos Relacionados

### Fundamentos
- [[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o]] - Base para construÃ§Ã£o
- [[DistribuiÃ§Ãµes_de_Probabilidade]] - Framework teÃ³rico
- [[DistribuiÃ§Ã£o_Beta]] - Para proporÃ§Ãµes/acurÃ¡cias

### Paradigmas
- [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos]] - Escolhas de modelagem
- [[InferÃªncia_Bayesiana]] - Paradigma probabilÃ­stico

### AplicaÃ§Ãµes
- [[AcurÃ¡cia]] - MÃ©trica a ser quantificada
- [[AcurÃ¡cia_Balanceada]] - Com incerteza
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]] - Artigo completo

---

## ğŸ¯ ExercÃ­cios

Veja [[ExercÃ­cios_PrÃ¡ticos#Intervalos de ConfianÃ§a]].

---

## ğŸ“Œ Resumo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INTERVALO DE CONFIANÃ‡A              â”‚
â”‚                                             â”‚
â”‚  "QuantificaÃ§Ã£o de incerteza"               â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FREQUENTISTA   â”‚  â”‚   BAYESIANO     â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ Î¸ fixo          â”‚  â”‚ Î¸ variÃ¡vel      â”‚ â”‚
â”‚  â”‚ IC varia        â”‚  â”‚ IC fixo p/ dadosâ”‚ â”‚
â”‚  â”‚ "95% capturam"  â”‚  â”‚ "95% prob."     â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ Pode violar     â”‚  â”‚ Respeita        â”‚ â”‚
â”‚  â”‚ limites [0,1]   â”‚  â”‚ limites         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                             â”‚
â”‚  Artigo usa BAYESIANO com Beta!            â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Tags:** #statistics #confidence-interval #credible-interval #inference #bayesian #frequentist

**Voltar para:** [[INDEX]]  
**Artigo relacionado:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]  
**Paradigma:** [[InferÃªncia_Bayesiana]]


