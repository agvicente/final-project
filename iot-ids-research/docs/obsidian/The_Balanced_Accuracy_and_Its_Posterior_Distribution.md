# The Balanced Accuracy and Its Posterior Distribution

> **Autores:** Kay H. Brodersen, Cheng Soon Ong, Klaas E. Stephan, Joachim M. Buhmann  
> **Confer√™ncia:** ICPR 2010 (International Conference on Pattern Recognition)  
> **Institui√ß√µes:** ETH Zurich, University of Zurich  
> **Relev√¢ncia:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

---

## üìã Resumo Executivo

Este artigo seminal prop√µe substituir a [[Acur√°cia]] tradicional pela [[Acur√°cia_Balanceada]] e modelar sua [[Distribui√ß√£o_Beta|distribui√ß√£o posterior usando Beta]], resolvendo dois problemas cr√≠ticos:

1. **[[Intervalos_de_Confian√ßa]] inadequados** com a abordagem [[M√©todos_Param√©tricos_vs_N√£o_Param√©tricos|n√£o-param√©trica]] tradicional
2. **Vi√©s otimista** em datasets desbalanceados

---

## üèõÔ∏è Contexto Hist√≥rico

**Ano:** 2010

**Problema na √©poca:** A comunidade de machine learning avaliava modelos usando [[Acur√°cia|acur√°cia m√©dia]] atrav√©s de cross-validation, mas essa abordagem tinha limita√ß√µes graves:

- Impossibilidade de derivar intervalos de confian√ßa significativos
- Falha em detectar classificadores enviesados explorando desbalanceamento de classes
- Uso inadequado de erro padr√£o da m√©dia levando a intervalos acima de 100%

**Impacto:** O artigo formalizou uma solu√ß√£o matem√°tica rigorosa usando [[Infer√™ncia_Bayesiana]] e a [[Distribui√ß√£o_Beta]].

---

## üéØ Problemas que Resolve

### Problema 1: Intervalos de Confian√ßa Inadequados

**M√©todo tradicional ([[M√©todos_Param√©tricos_vs_N√£o_Param√©tricos|n√£o-param√©trico]]):**
```
Acur√°cia m√©dia ¬± 2 √ó erro_padr√£o
```

**Defeitos:**
- ‚ùå Pode gerar intervalos > 100% ou < 0%
- ‚ùå Sempre sim√©trico (n√£o reflete realidade pr√≥xima aos limites)
- ‚ùå Depende de escolhas arbitr√°rias (n√∫mero de folds)

**Exemplo problem√°tico:**
```
Acur√°cia: 98%
Desvio padr√£o: 2%
Intervalo: [94%, 102%] ‚Üê 102%?! Imposs√≠vel!
```

### Problema 2: Vi√©s em Datasets Desbalanceados

**Cen√°rio cr√≠tico para [[Aplica√ß√£o_ao_IoT_IDS|IoT-IDS]]:**

Dataset com 95% tr√°fego normal, 5% ataques.

Um modelo "pregui√ßoso" que **sempre prev√™ "normal":**
- [[Acur√°cia]]: 95% ‚úÖ (enganoso!)
- [[Acur√°cia_Balanceada]]: 50% ‚ùå (revela a verdade!)

A acur√°cia tradicional **mascara** a incapacidade de detectar ataques.

---

## üî¨ Metodologia e Solu√ß√£o

### Componente 1: Abordagem Bayesiana para Acur√°cia

Ao inv√©s de ponto estimado, modela a **distribui√ß√£o posterior** da [[Acur√°cia]].

**Framework matem√°tico:**

```
Dados: C corretos, I incorretos
Prior: Uniforme Beta(1, 1)
Posterior: A ~ Beta(C+1, I+1)
```

Veja [[Infer√™ncia_Bayesiana]] para detalhes do paradigma.

**Vantagens:**
- ‚úÖ Respeita limites naturais [0, 1]
- ‚úÖ Intervalos assim√©tricos quando apropriado
- ‚úÖ Interpreta√ß√£o probabil√≠stica intuitiva

### Componente 2: Acur√°cia Balanceada

**Defini√ß√£o:**
```
Balanced Accuracy = ¬Ω(TP/P + TN/N)
```

- **TP/P:** Sensibilidade (recall na classe positiva)
- **TN/N:** Especificidade (recall na classe negativa)

Detalhes completos em [[Acur√°cia_Balanceada]].

**Propriedades:**
- Se reduz √† acur√°cia tradicional quando o desempenho √© igual em ambas as classes
- Cai para 50% (n√≠vel do acaso) quando modelo √© enviesado

### Componente 3: Distribui√ß√£o Posterior da Acur√°cia Balanceada

**Contribui√ß√£o principal do artigo:**

Derivar a [[Distribui√ß√£o_Beta|distribui√ß√£o posterior]] da acur√°cia balanceada atrav√©s da **convolu√ß√£o de duas distribui√ß√µes Beta**:

```
pB(x; TP, FP, FN, TN) = ‚à´‚ÇÄ¬π pA(2(x-z); TP+1, FN+1) ¬∑ pA(2z; TN+1, FP+1) dz
```

Onde:
- `pA(x)` √© a densidade da acur√°cia para cada classe
- `pB(x)` √© a densidade da acur√°cia balanceada

**Veja [[Distribui√ß√£o_Beta#Convolu√ß√£o para Balanced Accuracy|se√ß√£o de convolu√ß√£o]]** para detalhes matem√°ticos.

**Caracter√≠sticas:**
- N√£o tem forma anal√≠tica fechada
- Requer integra√ß√£o num√©rica
- C√≥digo MATLAB disponibilizado pelos autores

---

## üìä Resultados

### Experimento 1: Dataset Balanceado

**Configura√ß√£o:**
- 70 exemplos positivos
- 70 exemplos negativos
- Matriz de confus√£o: adequada

**Achados:**
- [[Acur√°cia|Acur√°cia tradicional]] com 2 SE: intervalo inclui > 100% ‚ùå
- [[Distribui√ß√£o_Beta|Posterior Beta]]: intervalos assim√©tricos corretos ‚úÖ
- Pouca diferen√ßa entre acur√°cia e acur√°cia balanceada (dataset equilibrado)

### Experimento 2: Dataset Desbalanceado com Classificador Enviesado

**Configura√ß√£o:**
- 45 exemplos positivos
- 10 exemplos negativos
- Classificador prev√™: 48 positivos, 7 negativos

**Achados cr√≠ticos:**

| M√©trica | Valor | Interpreta√ß√£o |
|---------|-------|---------------|
| [[Acur√°cia]] m√©dia | 92% | Sugere forte desempenho ‚ùå |
| Posterior [[Acur√°cia]] | 92% [88%, 95%] | Confirma alto desempenho ‚ùå |
| [[Acur√°cia_Balanceada]] | 51% [48%, 54%] | **Revela n√≠vel do acaso!** ‚úÖ |

**Conclus√£o:** Apenas a acur√°cia balanceada detectou que o modelo estava apenas explorando o desbalanceamento.

### Visualiza√ß√µes

O artigo apresenta:
1. Compara√ß√£o entre intervalos (Fig. 1)
2. Distribui√ß√µes posteriores completas (Fig. 2)
3. Estat√≠sticas: m√©dia, mediana, moda, intervalos de probabilidade

---

## üí° Conclus√µes do Artigo

### Contribui√ß√µes Principais

1. **Formaliza√ß√£o matem√°tica** da posterior da acur√°cia balanceada
2. **Demonstra√ß√£o emp√≠rica** da superioridade sobre acur√°cia tradicional
3. **C√≥digo disponibilizado** para comunidade (MATLAB)
4. **Generaliza√ß√£o poss√≠vel** para cen√°rios multiclasse (usando [[Distribui√ß√µes_de_Probabilidade#Dirichlet|Dirichlet]])

### Limita√ß√µes e Trabalhos Futuros

Os autores mencionam:
- Extens√£o para vari√°veis correlacionadas com classes
- Compara√ß√£o com ROC analysis
- Rela√ß√£o com binomial tail inversion

### Aplicabilidade

- ‚úÖ Qualquer n√∫mero de folds (s√≥ precisa da matriz de confus√£o agregada)
- ‚úÖ Classificadores individuais ou algoritmos completos
- ‚úÖ Cen√°rios com desbalanceamento de classes
- ‚úÖ Quando intervalos de confian√ßa rigorosos s√£o necess√°rios

---

## ‚ú® Insights Valiosos para [[Aplica√ß√£o_ao_IoT_IDS|Pesquisa IoT-IDS]]

### 1. Desbalanceamento √© Inevit√°vel em IDS

No dataset CICIoT2023:
- Tr√°fego normal >> Ataques
- [[Acur√°cia]] pode ser enganosa
- [[Acur√°cia_Balanceada]] √© **essencial**

### 2. Incerteza Quantific√°vel

A [[Distribui√ß√£o_Beta|distribui√ß√£o posterior Beta]] permite:
- Comparar algoritmos com rigor estat√≠stico
- Calcular P(Algoritmo A > Algoritmo B)
- Reportar intervalos de credibilidade ao inv√©s de pontos

### 3. Detec√ß√£o de Overfitting Enviesado

Modelo que "memoriza" classe majorit√°ria:
- [[Acur√°cia]] alta ‚úì
- [[Acur√°cia_Balanceada]] pr√≥xima de 50% ‚úó
- Posterior revela o problema!

### 4. Integra√ß√£o com Outras M√©tricas

[[Acur√°cia_Balanceada]] complementa:
- F1-score
- ROC-AUC
- Precision-Recall curves

### 5. Rigor Cient√≠fico

Para publica√ß√µes acad√™micas:
- Intervalos de credibilidade ao inv√©s de apenas m√©dia
- Base estat√≠stica s√≥lida ([[Infer√™ncia_Bayesiana]])
- Compara√ß√µes algor√≠tmicas significativas

### 6. Implementa√ß√£o Pr√°tica

```python
# Exemplo com dados do IoT-IDS
from scipy import stats

# Ap√≥s classifica√ß√£o
TP, FP, FN, TN = 450, 200, 50, 9300

# Posterior para cada classe
pos_posterior = stats.beta(TP+1, FN+1)
neg_posterior = stats.beta(TN+1, FP+1)

# Balanced accuracy (aproxima√ß√£o pela m√©dia das m√©dias)
ba_approx = 0.5 * (pos_posterior.mean() + neg_posterior.mean())

# Para distribui√ß√£o exata, usar convolu√ß√£o (Eq. 7 do artigo)
```

---

## üîó Conceitos Relacionados

### Fundamentos Necess√°rios
- [[M√©dia_Desvio_Padr√£o_Erro_Padr√£o]] - Base estat√≠stica
- [[Distribui√ß√µes_de_Probabilidade]] - Teoria geral
- [[Distribui√ß√£o_Beta]] - Distribui√ß√£o espec√≠fica usada
- [[M√©todos_Param√©tricos_vs_N√£o_Param√©tricos]] - Compara√ß√£o de abordagens

### Paradigma
- [[Infer√™ncia_Bayesiana]] - Framework filos√≥fico e matem√°tico
- [[Intervalos_de_Confian√ßa]] - Quantifica√ß√£o de incerteza

### Aplica√ß√£o
- [[Acur√°cia]] - M√©trica tradicional
- [[Acur√°cia_Balanceada]] - M√©trica proposta
- [[Aplica√ß√£o_ao_IoT_IDS]] - Seu contexto espec√≠fico

---

## üìö Refer√™ncias do Artigo

### Citadas no Paper
- **Bishop, C.M.** (2006). *Pattern Recognition and Machine Learning*. Springer. [Cap. 2.2, pp. 68-74]
- **Langford, J.** (2005). "Tutorial on practical prediction theory for classification". *JMLR*, 6, 273-306.
- **Chawla et al.** (2002). "SMOTE: synthetic minority over-sampling technique". *JAIR*, 16(3), 321-357.

### Para Aprofundamento
Veja [[Refer√™ncias_Bibliogr√°ficas]] para lista completa de materiais recomendados.

---

## üéØ Exerc√≠cios Pr√°ticos

Para fixar o conte√∫do, veja [[Exerc√≠cios_Pr√°ticos#Balanced Accuracy]].

---

## üìå Metadados

**Tags:** #paper #bayesian #balanced-accuracy #evaluation-metrics #beta-distribution #classification #imbalanced-data

**Cita√ß√£o:**
```bibtex
@inproceedings{brodersen2010balanced,
  title={The balanced accuracy and its posterior distribution},
  author={Brodersen, Kay H and Ong, Cheng Soon and Stephan, Klaas E and Buhmann, Joachim M},
  booktitle={2010 20th International Conference on Pattern Recognition},
  pages={3121--3124},
  year={2010},
  organization={IEEE}
}
```

**Links Externos:**
- [Paper PDF](../papers/The_Balanced_Accuracy_and_Its_Posterior_Distribution.pdf)
- [Paper TXT](../papers/The_Balanced_Accuracy_and_Its_Posterior_Distribution.txt)
- [C√≥digo MATLAB (original)](http://people.inf.ethz.ch/bkay/downloads)

---

**√öltima atualiza√ß√£o:** 2025-10-19  
**Voltar para:** [[INDEX]]

