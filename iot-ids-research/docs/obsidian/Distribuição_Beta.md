# DistribuiÃ§Ã£o Beta

> **Tipo:** DistribuiÃ§Ã£o de Probabilidade ContÃ­nua  
> **Complexidade:** â­â­â­â­â˜† (AvanÃ§ado)  
> **AplicaÃ§Ã£o:** Modelagem de ProporÃ§Ãµes, Probabilidades, [[AcurÃ¡cia]]

---

## ğŸ¯ O que Ã© a DistribuiÃ§Ã£o Beta?

A **distribuiÃ§Ã£o Beta** Ã© uma famÃ­lia de [[DistribuiÃ§Ãµes_de_Probabilidade|distribuiÃ§Ãµes contÃ­nuas]] definidas no intervalo **[0, 1]**, tornando-a **perfeita** para modelar:
- ProporÃ§Ãµes
- Probabilidades
- Taxas
- **[[AcurÃ¡cia|AcurÃ¡cias]] de modelos** â­

**Por que Ã© central no [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|artigo]]?**
Resolve o problema de [[Intervalos_de_ConfianÃ§a|intervalos de confianÃ§a]] que violam [0,1]!

---

## ğŸ“ DefiniÃ§Ã£o MatemÃ¡tica

### FunÃ§Ã£o Densidade de Probabilidade (PDF)

```
Beta(x; Î±, Î²) = [x^(Î±-1) Ã— (1-x)^(Î²-1)] / B(Î±, Î²)
```

Onde:
- **x âˆˆ [0, 1]:** Valor da variÃ¡vel (ex: acurÃ¡cia)
- **Î± > 0:** ParÃ¢metro de forma ("sucessos" + 1)
- **Î² > 0:** ParÃ¢metro de forma ("falhas" + 1)
- **B(Î±, Î²):** FunÃ§Ã£o Beta (constante normalizadora)

### FunÃ§Ã£o Beta

```
B(Î±, Î²) = âˆ«â‚€Â¹ t^(Î±-1) Ã— (1-t)^(Î²-1) dt

        = Î“(Î±) Ã— Î“(Î²) / Î“(Î± + Î²)
```

Onde **Î“** Ã© a funÃ§Ã£o Gamma (generalizaÃ§Ã£o do fatorial).

**Para inteiros:**
```
B(Î±, Î²) = (Î±-1)! Ã— (Î²-1)! / (Î±+Î²-1)!
```

---

## ğŸ¨ InterpretaÃ§Ã£o dos ParÃ¢metros

### Forma Intuitiva

**Contexto [[InferÃªncia_Bayesiana|Bayesiano]]:**
```
Î± = nÃºmero de "sucessos" + 1
Î² = nÃºmero de "falhas" + 1
```

**Exemplo [[AplicaÃ§Ã£o_ao_IoT_IDS|IDS]]:**
```
95 classificaÃ§Ãµes corretas
5 classificaÃ§Ãµes incorretas

â†’ Beta(96, 6)

Î± = 95 + 1 = 96
Î² = 5 + 1 = 6
```

### Efeito dos ParÃ¢metros

#### Î±: "ForÃ§a dos Sucessos"
- â†‘ Î±: distribui massa para **direita** (valores altos)
- â†“ Î±: distribui massa para **esquerda** (valores baixos)

#### Î²: "ForÃ§a das Falhas"  
- â†‘ Î²: distribui massa para **esquerda** (valores baixos)
- â†“ Î²: distribui massa para **direita** (valores altos)

#### Î± + Î²: "ForÃ§a das EvidÃªncias"
- â†‘ (Î±+Î²): distribuiÃ§Ã£o mais **concentrada** (menos incerteza)
- â†“ (Î±+Î²): distribuiÃ§Ã£o mais **espalhada** (mais incerteza)

---

## ğŸ“Š Formas da Beta

### VisualizaÃ§Ã£o de Formas ClÃ¡ssicas

```
Beta(1, 1): â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Uniforme (total ignorÃ¢ncia)

Beta(2, 2):    â•±â•²       SimÃ©trica suave
              â•±  â•²

Beta(5, 2):      â•±â•²     Pico Ã  direita (alta acurÃ¡cia)
                â•±  â•²___

Beta(2, 5): ___â•±  â•²     Pico Ã  esquerda (baixa acurÃ¡cia)
               â•²  â•±

Beta(0.5, 0.5): U       Forma de U (valores extremos)

Beta(20, 20):   â–²       Muito concentrada (muita evidÃªncia)
```

### Casos Especiais

**Beta(1, 1):**
```
Uniforme em [0,1]
f(x) = 1
```
Prior nÃ£o-informativo - total ignorÃ¢ncia.

**Beta(Î±, Î±) com Î± grande:**
```
Aproxima Normal
SimÃ©trica, concentrada em 0.5
```

**Beta(Î±, 1) ou Beta(1, Î²):**
```
DistribuiÃ§Ãµes crescentes/decrescentes
```

---

## ğŸ“ˆ Momentos e EstatÃ­sticas

### MÃ©dia (EsperanÃ§a)

```
E[X] = Î¼ = Î± / (Î± + Î²)
```

**Exemplo:**
```
Beta(91, 11):
Î¼ = 91 / (91 + 11) = 91/102 â‰ˆ 0.892 = 89.2%
```

### Moda

```
Moda = (Î± - 1) / (Î± + Î² - 2)   se Î±, Î² > 1
```

**Exemplo:**
```
Beta(91, 11):
Moda = (91-1) / (91+11-2) = 90/100 = 0.90 = 90%
```

**Interessante:** A moda â‰ˆ acurÃ¡cia observada (90/100)!

### Mediana

NÃ£o tem forma fechada, mas para simÃ©trica (Î±=Î²):
```
Mediana = 0.5
```

### VariÃ¢ncia

```
Var(X) = ÏƒÂ² = Î±Î² / [(Î±+Î²)Â²(Î±+Î²+1)]
```

**Exemplo:**
```
Beta(91, 11):
ÏƒÂ² = 91Ã—11 / [102Â² Ã— 103]
   â‰ˆ 0.000935
Ïƒ â‰ˆ 0.0306 = 3.06%
```

### Desvio PadrÃ£o

```
Ïƒ = âˆš[Î±Î² / [(Î±+Î²)Â²(Î±+Î²+1)]]
```

---

## ğŸ§® Por que Beta Ã© Perfeita para [[AcurÃ¡cia]]?

### 1. Suporte Natural [0,1]

**Problema com Normal:**
```
Normal(0.98, 0.02Â²) pode gerar valores > 1 âŒ
```

**Beta sempre respeita limites:**
```
Beta(Î±, Î²) sÃ³ gera valores em [0, 1] âœ…
```

### 2. Flexibilidade

Pode representar:
- IgnorÃ¢ncia total: Beta(1,1)
- Alta confianÃ§a: Beta(100, 10)
- Baixo desempenho: Beta(10, 100)
- Qualquer forma intermediÃ¡ria!

### 3. ConjugaÃ§Ã£o com Binomial

**ClassificaÃ§Ã£o binÃ¡ria** = sequÃªncia de Bernoulli = Binomial!

```
Prior: Î¸ ~ Beta(Î±â‚€, Î²â‚€)
Likelihood: k sucessos em n â†’ Binomial(n, Î¸)
Posterior: Î¸ ~ Beta(Î±â‚€+k, Î²â‚€+n-k)  âœ… TambÃ©m Ã© Beta!
```

**MatemÃ¡tica elegante!** Veja [[InferÃªncia_Bayesiana#Conjugate Priors]].

### 4. InterpretaÃ§Ã£o Intuitiva

```
Î± = "evidÃªncia de sucesso"
Î² = "evidÃªncia de falha"
Î¼ = Î±/(Î±+Î²) = "taxa de sucesso"
```

Faz sentido intuitivo! ğŸ’¡

---

## ğŸ”¬ Beta no [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo Brodersen]]

### Para [[AcurÃ¡cia]] Simples

**Dados:** C corretos, I incorretos

**Prior nÃ£o-informativo:** Beta(1, 1)

**Posterior:**
```
A ~ Beta(C+1, I+1)
```

**Exemplo:**
```
90 corretos, 10 incorretos
â†’ Beta(91, 11)

MÃ©dia: 89.2%
IC 95%: [83.8%, 94.6%]
```

### Para [[AcurÃ¡cia_Balanceada]]

**Dados:** TP, FN, TN, FP

**AcurÃ¡cia em cada classe:**
```
A_pos ~ Beta(TP+1, FN+1)
A_neg ~ Beta(TN+1, FP+1)
```

**Balanced Accuracy:**
```
BA = Â½(A_pos + A_neg)
```

**DistribuiÃ§Ã£o de BA:** ConvoluÃ§Ã£o! (seÃ§Ã£o abaixo)

---

## ğŸŒ€ ConvoluÃ§Ã£o para Balanced Accuracy

### O Problema

Queremos a distribuiÃ§Ã£o de:
```
BA = Â½(A_pos + A_neg)
```

Onde A_pos e A_neg sÃ£o **independentes** e seguem Betas.

### SoluÃ§Ã£o: ConvoluÃ§Ã£o

**Do artigo, EquaÃ§Ã£o (7):**

```
p_BA(x; TP, FP, FN, TN) = 
    âˆ«â‚€Â¹ p_A(2(x-z); TP+1, FN+1) Ã— p_A(2z; TN+1, FP+1) dz
```

Onde:
- `p_A(x)` Ã© a PDF da Beta (definida acima)
- `p_BA(x)` Ã© a PDF da balanced accuracy

### Propriedades

- âŒ NÃ£o tem forma analÃ­tica fechada
- âœ… Pode ser calculada numericamente
- âœ… Respeita [0,1] naturalmente
- âœ… Captura correlaÃ§Ã£o entre classes

### ImplementaÃ§Ã£o (AproximaÃ§Ã£o Monte Carlo)

```python
from scipy import stats
import numpy as np

def balanced_accuracy_distribution(TP, FN, TN, FP, n_samples=100000):
    """
    Aproxima distribuiÃ§Ã£o da balanced accuracy
    via amostragem Monte Carlo.
    """
    # Posteriors para cada classe
    pos_post = stats.beta(TP + 1, FN + 1)
    neg_post = stats.beta(TN + 1, FP + 1)
    
    # Amostrar
    pos_samples = pos_post.rvs(n_samples)
    neg_samples = neg_post.rvs(n_samples)
    
    # Balanced accuracy
    ba_samples = 0.5 * (pos_samples + neg_samples)
    
    return ba_samples

# Exemplo do artigo (C2)
# 45 positivos: 43 TP, 2 FN
# 10 negativos: 3 TN, 7 FP
TP, FN, TN, FP = 43, 2, 3, 7

ba_samples = balanced_accuracy_distribution(TP, FN, TN, FP)

print(f"BA mÃ©dia: {np.mean(ba_samples):.3f}")
print(f"IC 95%: [{np.percentile(ba_samples, 2.5):.3f}, "
      f"{np.percentile(ba_samples, 97.5):.3f}]")

# Resultado aproximado:
# BA mÃ©dia: 0.512
# IC 95%: [0.384, 0.639]
```

---

## ğŸ² SimulaÃ§Ã£o e VisualizaÃ§Ã£o

### Comparando Diferentes EvidÃªncias

```python
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats

x = np.linspace(0, 1, 1000)

# Diferentes nÃ­veis de evidÃªncia
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

configs = [
    (2, 2, "Pouca evidÃªncia balanceada"),
    (10, 10, "EvidÃªncia moderada balanceada"),
    (91, 11, "Muita evidÃªncia (90/100 acertos)"),
    (10, 91, "Muita evidÃªncia (10/100 acertos)")
]

for ax, (alpha, beta, title) in zip(axes.flat, configs):
    dist = stats.beta(alpha, beta)
    
    ax.plot(x, dist.pdf(x), 'b-', lw=2)
    ax.fill_between(x, dist.pdf(x), alpha=0.3)
    
    # EstatÃ­sticas
    mean = dist.mean()
    ci = dist.interval(0.95)
    
    ax.axvline(mean, color='r', linestyle='--', 
               label=f'MÃ©dia: {mean:.3f}')
    ax.axvline(ci[0], color='g', linestyle=':', alpha=0.5)
    ax.axvline(ci[1], color='g', linestyle=':', alpha=0.5,
               label=f'IC 95%: [{ci[0]:.3f}, {ci[1]:.3f}]')
    
    ax.set_title(f'{title}\nBeta({alpha}, {beta})')
    ax.set_xlabel('x (acurÃ¡cia)')
    ax.set_ylabel('Densidade')
    ax.legend()
    ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('beta_comparison.png', dpi=300)
plt.show()
```

### AtualizaÃ§Ã£o Bayesiana Sequencial

```python
# ComeÃ§ar com prior nÃ£o-informativo
prior = stats.beta(1, 1)

# Observar dados sequencialmente
observations = [(1,0), (1,0), (0,1), (1,0), (1,0)]  # (sucesso, falha)

alpha, beta = 1, 1

for i, (succ, fail) in enumerate(observations):
    # Atualizar
    alpha += succ
    beta += fail
    
    # Posterior atual
    posterior = stats.beta(alpha, beta)
    
    # Visualizar evoluÃ§Ã£o
    x = np.linspace(0, 1, 1000)
    plt.plot(x, posterior.pdf(x), 
             label=f'ApÃ³s {i+1} obs: Beta({alpha},{beta})')

plt.title('EvoluÃ§Ã£o da CrenÃ§a Bayesiana')
plt.xlabel('Î¸ (taxa de sucesso)')
plt.ylabel('Densidade')
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

---

## ğŸ“š Propriedades MatemÃ¡ticas AvanÃ§adas

### FunÃ§Ã£o Geradora de Momentos

NÃ£o tem forma fechada simples, mas momentos podem ser calculados:

```
E[X^n] = (Î±)_n / (Î±+Î²)_n
```

Onde `(a)_n` Ã© o sÃ­mbolo de Pochhammer (rising factorial).

### Entropia

```
H(X) = ln B(Î±,Î²) - (Î±-1)Ïˆ(Î±) - (Î²-1)Ïˆ(Î²) + (Î±+Î²-2)Ïˆ(Î±+Î²)
```

Onde Ïˆ Ã© a funÃ§Ã£o digamma.

### InformaÃ§Ã£o de Fisher

```
I(Î±,Î²) = matriz 2Ã—2 das segundas derivadas de ln L
```

---

## ğŸ”„ RelaÃ§Ãµes com Outras DistribuiÃ§Ãµes

### Beta e Uniforme

```
Beta(1, 1) = Uniforme(0, 1)
```

### Beta e Binomial

**ConjugaÃ§Ã£o:**
```
Prior: Beta(Î±, Î²)
+ Likelihood: Binomial
= Posterior: Beta(Î±+k, Î²+n-k)
```

### Beta e Dirichlet

**GeneralizaÃ§Ã£o multiclasse:**
```
Beta(Î±, Î²) Ã© caso especial de Dirichlet(Î±, Î²)
```

Para [[AcurÃ¡cia_Balanceada]] multiclasse!

### Beta e F de Fisher

```
Se X ~ Beta(Î±, Î²), entÃ£o
Y = (X/Î±) / ((1-X)/Î²) ~ F(2Î±, 2Î²)
```

---

## ğŸ’» ImplementaÃ§Ã£o Completa

### Classe Beta Helper

```python
from scipy import stats
import numpy as np

class BetaAccuracy:
    """Helper para trabalhar com acurÃ¡cias modeladas como Beta."""
    
    def __init__(self, correct, incorrect):
        """
        Args:
            correct: nÃºmero de classificaÃ§Ãµes corretas
            incorrect: nÃºmero de classificaÃ§Ãµes incorretas
        """
        self.C = correct
        self.I = incorrect
        self.alpha = correct + 1
        self.beta = incorrect + 1
        self.dist = stats.beta(self.alpha, self.beta)
    
    def mean(self):
        """AcurÃ¡cia mÃ©dia."""
        return self.dist.mean()
    
    def median(self):
        """Mediana."""
        return self.dist.median()
    
    def mode(self):
        """Moda (MLE)."""
        if self.alpha > 1 and self.beta > 1:
            return (self.alpha - 1) / (self.alpha + self.beta - 2)
        return np.nan
    
    def std(self):
        """Desvio padrÃ£o."""
        return self.dist.std()
    
    def interval(self, confidence=0.95):
        """Intervalo de credibilidade."""
        return self.dist.interval(confidence)
    
    def prob_greater_than(self, threshold):
        """P(acurÃ¡cia > threshold)."""
        return 1 - self.dist.cdf(threshold)
    
    def prob_between(self, lower, upper):
        """P(lower < acurÃ¡cia < upper)."""
        return self.dist.cdf(upper) - self.dist.cdf(lower)
    
    def compare_with(self, other_beta_acc, n_samples=100000):
        """
        Compara com outro modelo.
        Retorna P(este modelo > outro modelo).
        """
        samples_self = self.dist.rvs(n_samples)
        samples_other = other_beta_acc.dist.rvs(n_samples)
        return np.mean(samples_self > samples_other)
    
    def summary(self):
        """Resumo completo."""
        ci = self.interval(0.95)
        return f"""
        Beta({self.alpha}, {self.beta})
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        MÃ©dia:    {self.mean():.4f}
        Mediana:  {self.median():.4f}
        Moda:     {self.mode():.4f}
        Desvio:   {self.std():.4f}
        IC 95%:   [{ci[0]:.4f}, {ci[1]:.4f}]
        """

# Uso
model_A = BetaAccuracy(correct=90, incorrect=10)
print(model_A.summary())

# P(acurÃ¡cia > 85%)
print(f"P(acc > 0.85): {model_A.prob_greater_than(0.85):.3f}")

# Comparar modelos
model_B = BetaAccuracy(correct=85, incorrect=15)
prob = model_A.compare_with(model_B)
print(f"P(A > B): {prob:.3f}")
```

---

## ğŸ“š ReferÃªncias

### Livros EspecÃ­ficos
- **Gelman, A., et al.** (2013). *Bayesian Data Analysis* (3rd ed.). CRC Press. [SeÃ§Ã£o 2.4: "Bayesian inference for Binomial data"]
- **Kruschke, J.K.** (2014). *Doing Bayesian Data Analysis* (2nd ed.). Academic Press. [CapÃ­tulo 6: "Inferring a Binomial Probability"]
- **Bishop, C.M.** (2006). *Pattern Recognition and Machine Learning*. Springer. [SeÃ§Ã£o 2.2, pp. 68-74] â­ **Citado no artigo!**

### Papers
- **Brodersen et al.** (2010). [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|"The balanced accuracy and its posterior distribution"]]. ICPR.

### Online
- [Beta Distribution - Wikipedia](https://en.wikipedia.org/wiki/Beta_distribution)
- [Seeing Theory: Beta Distribution](https://seeing-theory.brown.edu/bayesian-inference/index.html)
- [Scipy Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)

Veja [[ReferÃªncias_BibliogrÃ¡ficas]] para lista completa.

---

## ğŸ”— Conceitos Relacionados

### Fundamentos
- [[DistribuiÃ§Ãµes_de_Probabilidade]] - Contexto geral
- [[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o]] - Momentos
- [[Intervalos_de_ConfianÃ§a]] - AplicaÃ§Ã£o principal

### Paradigma
- [[InferÃªncia_Bayesiana]] - Framework de uso
- [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos]] - Escolha paramÃ©trica

### AplicaÃ§Ãµes
- [[AcurÃ¡cia]] - Modelada como Beta
- [[AcurÃ¡cia_Balanceada]] - ConvoluÃ§Ã£o de Betas
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]] - Artigo principal
- [[AplicaÃ§Ã£o_ao_IoT_IDS]] - Uso prÃ¡tico

---

## ğŸ¯ ExercÃ­cios

Veja [[ExercÃ­cios_PrÃ¡ticos#DistribuiÃ§Ã£o Beta]].

---

## ğŸ“Œ Resumo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DISTRIBUIÃ‡ÃƒO BETA                  â”‚
â”‚                                               â”‚
â”‚  Beta(Î±, Î²) para x âˆˆ [0,1]                   â”‚
â”‚                                               â”‚
â”‚  Î± = "sucessos" + 1                          â”‚
â”‚  Î² = "falhas" + 1                            â”‚
â”‚                                               â”‚
â”‚  âœ… Suporte [0,1] - perfeito para proporÃ§Ãµes â”‚
â”‚  âœ… FlexÃ­vel - mÃºltiplas formas              â”‚
â”‚  âœ… Conjugada Ã  Binomial                     â”‚
â”‚  âœ… InterpretaÃ§Ã£o intuitiva                  â”‚
â”‚                                               â”‚
â”‚  Momentos:                                    â”‚
â”‚  â€¢ MÃ©dia: Î±/(Î±+Î²)                            â”‚
â”‚  â€¢ VariÃ¢ncia: Î±Î²/[(Î±+Î²)Â²(Î±+Î²+1)]            â”‚
â”‚                                               â”‚
â”‚  Uso: Modelar ACURÃCIAS!                     â”‚
â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Tags:** #beta-distribution #bayesian #probability #accuracy #proportion #conjugate-prior

**Voltar para:** [[INDEX]]  
**Contexto:** [[DistribuiÃ§Ãµes_de_Probabilidade]]  
**Artigo:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]  
**AplicaÃ§Ã£o:** [[AcurÃ¡cia_Balanceada]]

