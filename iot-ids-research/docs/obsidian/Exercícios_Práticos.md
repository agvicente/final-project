# Exerc√≠cios Pr√°ticos

> **Objetivo:** Fixar conceitos atrav√©s de problemas pr√°ticos  
> **Contexto:** [[Aplica√ß√£o_ao_IoT_IDS|Sistema IDS para IoT]]  
> **Dificuldade:** ‚≠ê B√°sico ‚Üí ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Avan√ßado

---

## üéØ Como Usar Este Documento

1. **Leia o conceito** relacionado antes de fazer os exerc√≠cios
2. **Tente resolver** sem olhar a solu√ß√£o
3. **Compare** sua resposta com a solu√ß√£o fornecida
4. **Implemente** em c√≥digo Python quando indicado

**Dica:** Use Jupyter Notebook para praticar!

---

## üìä Se√ß√£o 1: Estat√≠stica Descritiva

### Exerc√≠cio 1.1: [[M√©dia_Desvio_Padr√£o_Erro_Padr√£o|M√©dia e Desvio Padr√£o]] ‚≠ê

Um modelo IDS foi avaliado em 5 folds com as seguintes acur√°cias:
```
[0.89, 0.91, 0.88, 0.92, 0.90]
```

**Calcule:**
a) M√©dia  
b) Desvio padr√£o (amostral, use n-1)  
c) Erro padr√£o

<details>
<summary>üí° Solu√ß√£o</summary>

**a) M√©dia:**
```
xÃÑ = (0.89 + 0.91 + 0.88 + 0.92 + 0.90) / 5
  = 4.50 / 5
  = 0.90 = 90%
```

**b) Desvio padr√£o:**
```
Diferen√ßas: [0.89-0.90, 0.91-0.90, 0.88-0.90, 0.92-0.90, 0.90-0.90]
          = [-0.01, 0.01, -0.02, 0.02, 0.00]

Quadrados: [0.0001, 0.0001, 0.0004, 0.0004, 0.0000]

Soma: 0.0010

Vari√¢ncia: 0.0010 / (5-1) = 0.00025

Desvio padr√£o: ‚àö0.00025 ‚âà 0.0158 = 1.58%
```

**c) Erro padr√£o:**
```
SE = s / ‚àön
   = 0.0158 / ‚àö5
   = 0.0158 / 2.236
   ‚âà 0.0071 = 0.71%
```

**C√≥digo Python:**
```python
import numpy as np

acuracias = [0.89, 0.91, 0.88, 0.92, 0.90]

media = np.mean(acuracias)
desvio = np.std(acuracias, ddof=1)  # ddof=1 para amostral
erro_padrao = desvio / np.sqrt(len(acuracias))

print(f"M√©dia: {media:.2%}")
print(f"Desvio Padr√£o: {desvio:.2%}")
print(f"Erro Padr√£o: {erro_padrao:.2%}")
```

</details>

---

### Exerc√≠cio 1.2: Interpreta√ß√£o ‚≠ê‚≠ê

Dois modelos IDS foram avaliados:

**Modelo A:** M√©dia = 0.90, Desvio Padr√£o = 0.02  
**Modelo B:** M√©dia = 0.90, Desvio Padr√£o = 0.05

**Perguntas:**
a) Qual modelo √© mais consistente?  
b) Se voc√™ pudesse testar apenas uma vez, qual modelo escolheria?  
c) O que o maior desvio padr√£o do Modelo B pode indicar?

<details>
<summary>üí° Solu√ß√£o</summary>

**a)** Modelo A √© mais consistente (menor desvio padr√£o = menos varia√ß√£o).

**b)** Modelo A - maior probabilidade de resultado pr√≥ximo √† m√©dia.

**c)** Possibilidades:
- Desempenho varia muito entre folds (pode ser problema de overfitting)
- Sens√≠vel √† sele√ß√£o de dados
- Menos est√°vel para deployment

</details>

---

## üé≤ Se√ß√£o 2: [[Distribui√ß√£o_Beta]]

### Exerc√≠cio 2.1: Par√¢metros da Beta ‚≠ê‚≠ê

Seu IDS classificou 100 conex√µes: 85 acertos, 15 erros.

**Perguntas:**
a) Qual a distribui√ß√£o posterior com prior n√£o-informativo?  
b) Qual a m√©dia desta distribui√ß√£o?  
c) Qual a moda?

<details>
<summary>üí° Solu√ß√£o</summary>

**a) Distribui√ß√£o posterior:**
```
Prior: Beta(1, 1)
Dados: 85 acertos, 15 erros

Posterior: Beta(1+85, 1+15) = Beta(86, 16)
```

**b) M√©dia:**
```
Œº = Œ± / (Œ± + Œ≤)
  = 86 / (86 + 16)
  = 86 / 102
  ‚âà 0.843 = 84.3%
```

**c) Moda:**
```
Moda = (Œ± - 1) / (Œ± + Œ≤ - 2)
     = (86 - 1) / (86 + 16 - 2)
     = 85 / 100
     = 0.85 = 85%
```

**C√≥digo Python:**
```python
from scipy import stats

# Dados
corretos = 85
incorretos = 15

# Posterior
posterior = stats.beta(corretos + 1, incorretos + 1)

print(f"Distribui√ß√£o: Beta({corretos+1}, {incorretos+1})")
print(f"M√©dia: {posterior.mean():.3f}")
print(f"Moda: {corretos/(corretos+incorretos):.3f}")
print(f"Mediana: {posterior.median():.3f}")
```

</details>

---

### Exerc√≠cio 2.2: Visualiza√ß√£o ‚≠ê‚≠ê‚≠ê

Usando o exerc√≠cio anterior, visualize a distribui√ß√£o posterior e responda:

a) P(acur√°cia > 0.80)?  
b) P(acur√°cia > 0.85)?  
c) Intervalo de credibilidade 95%?

<details>
<summary>üí° Solu√ß√£o</summary>

```python
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# Posterior
posterior = stats.beta(86, 16)

# Probabilidades
prob_above_80 = 1 - posterior.cdf(0.80)
prob_above_85 = 1 - posterior.cdf(0.85)
ci_95 = posterior.interval(0.95)

print(f"P(acc > 0.80) = {prob_above_80:.3f}")
print(f"P(acc > 0.85) = {prob_above_85:.3f}")
print(f"IC 95% = [{ci_95[0]:.3f}, {ci_95[1]:.3f}]")

# Visualiza√ß√£o
x = np.linspace(0.7, 1.0, 1000)
pdf = posterior.pdf(x)

plt.figure(figsize=(10, 6))
plt.plot(x, pdf, 'b-', linewidth=2, label='Posterior Beta(86, 16)')
plt.fill_between(x, pdf, alpha=0.3)

# Marcar m√©dia
mean = posterior.mean()
plt.axvline(mean, color='r', linestyle='--', label=f'M√©dia: {mean:.3f}')

# Marcar IC 95%
plt.axvline(ci_95[0], color='g', linestyle=':', alpha=0.7, label=f'IC 95%')
plt.axvline(ci_95[1], color='g', linestyle=':', alpha=0.7)

plt.xlabel('Acur√°cia', fontsize=12)
plt.ylabel('Densidade', fontsize=12)
plt.title('Distribui√ß√£o Posterior da Acur√°cia\n85 acertos em 100 tentativas', fontsize=14)
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

**Resultado esperado:**
- P(acc > 0.80) ‚âà 0.989 (muito prov√°vel!)
- P(acc > 0.85) ‚âà 0.462 (n√£o t√£o certo)
- IC 95% ‚âà [0.772, 0.900]

</details>

---

## üìà Se√ß√£o 3: [[Acur√°cia_Balanceada]]

### Exerc√≠cio 3.1: C√°lculo B√°sico ‚≠ê

Matriz de confus√£o do seu IDS:

```
                Predito
                Ataque  Normal
Ataque    [     45        5    ]
Real
Normal    [     10      940    ]
```

**Calcule:**
a) Acur√°cia tradicional  
b) Sensibilidade (recall em ataques)  
c) Especificidade (recall em normais)  
d) Balanced Accuracy

<details>
<summary>üí° Solu√ß√£o</summary>

**Extrair valores:**
```
TP = 45  (ataques detectados)
FN = 5   (ataques perdidos)
FP = 10  (falsos alarmes)
TN = 940 (normais corretos)

Total = 1000
```

**a) Acur√°cia:**
```
Acc = (TP + TN) / Total
    = (45 + 940) / 1000
    = 0.985 = 98.5%
```

**b) Sensibilidade:**
```
Sens = TP / (TP + FN)
     = 45 / (45 + 5)
     = 45 / 50
     = 0.90 = 90%
```

**c) Especificidade:**
```
Spec = TN / (TN + FP)
     = 940 / (940 + 10)
     = 940 / 950
     ‚âà 0.989 = 98.9%
```

**d) Balanced Accuracy:**
```
BA = ¬Ω √ó (Sens + Spec)
   = ¬Ω √ó (0.90 + 0.989)
   = ¬Ω √ó 1.889
   ‚âà 0.945 = 94.5%
```

**C√≥digo Python:**
```python
import numpy as np
from sklearn.metrics import balanced_accuracy_score

# Dados
TP, FN, FP, TN = 45, 5, 10, 940

# Acur√°cia
acc = (TP + TN) / (TP + TN + FP + FN)

# Sensibilidade e Especificidade
sens = TP / (TP + FN)
spec = TN / (TN + FP)

# Balanced Accuracy
ba = 0.5 * (sens + spec)

print(f"Acur√°cia: {acc:.3%}")
print(f"Sensibilidade: {sens:.3%}")
print(f"Especificidade: {spec:.3%}")
print(f"Balanced Accuracy: {ba:.3%}")
```

</details>

---

### Exerc√≠cio 3.2: Detector Enviesado ‚≠ê‚≠ê‚≠ê

Um modelo "pregui√ßoso" SEMPRE prev√™ "Normal":

Dataset: 50 ataques, 950 normais

**Calcule:**
a) Matriz de confus√£o  
b) Acur√°cia  
c) Balanced Accuracy  
d) Por que BA √© melhor neste caso?

<details>
<summary>üí° Solu√ß√£o</summary>

**a) Matriz:**
```
TP = 0   (nenhum ataque detectado)
FN = 50  (todos os ataques perdidos)
FP = 0   (nunca prev√™ ataque)
TN = 950 (todos os normais corretos)
```

**b) Acur√°cia:**
```
Acc = 950 / 1000 = 95%  ‚Üê Parece √≥timo! (mas √© enganoso)
```

**c) Balanced Accuracy:**
```
Sens = 0 / 50 = 0%
Spec = 950 / 950 = 100%

BA = ¬Ω √ó (0 + 1) = 0.5 = 50%  ‚Üê N√≠vel do acaso!
```

**d) Por que BA √© melhor:**
BA revela que o modelo n√£o aprendeu nada √∫til! √â equivalente a um classificador aleat√≥rio para [[Aplica√ß√£o_ao_IoT_IDS|IDS]] - completamente in√∫til.

</details>

---

## üîµ Se√ß√£o 4: [[Infer√™ncia_Bayesiana]]

### Exerc√≠cio 4.1: Atualiza√ß√£o Bayesiana ‚≠ê‚≠ê‚≠ê

Voc√™ come√ßa com prior n√£o-informativo Beta(1,1) e observa dados sequencialmente:

```
Teste 1: Acerto
Teste 2: Acerto  
Teste 3: Erro
Teste 4: Acerto
Teste 5: Acerto
```

**Para cada etapa, calcule:**
- Posterior
- M√©dia posterior

<details>
<summary>üí° Solu√ß√£o</summary>

```python
from scipy import stats

# Come√ßar com prior
alpha, beta = 1, 1

observacoes = [1, 1, 0, 1, 1]  # 1=acerto, 0=erro

print("Atualiza√ß√£o Bayesiana Sequencial:")
print("="*50)

for i, obs in enumerate(observacoes, 1):
    # Atualizar
    if obs == 1:
        alpha += 1
    else:
        beta += 1
    
    # Posterior atual
    posterior = stats.beta(alpha, beta)
    mean = posterior.mean()
    
    print(f"Ap√≥s teste {i}: Beta({alpha}, {beta}), M√©dia = {mean:.3f}")

# Resultado final
print("\n" + "="*50)
print(f"Posterior final: Beta({alpha}, {beta})")
print(f"M√©dia final: {posterior.mean():.3f}")
print(f"IC 95%: {posterior.interval(0.95)}")
```

**Resultado:**
```
Ap√≥s teste 1: Beta(2, 1), M√©dia = 0.667
Ap√≥s teste 2: Beta(3, 1), M√©dia = 0.750
Ap√≥s teste 3: Beta(3, 2), M√©dia = 0.600
Ap√≥s teste 4: Beta(4, 2), M√©dia = 0.667
Ap√≥s teste 5: Beta(5, 2), M√©dia = 0.714

Posterior final: Beta(5, 2)
M√©dia final: 0.714
IC 95%: (0.362, 0.945)
```

</details>

---

### Exerc√≠cio 4.2: Prior Informativo ‚≠ê‚≠ê‚≠ê‚≠ê

Voc√™ sabe que sistemas IDS similares t√™m acur√°cia ~85%. Modele isso como Beta(17, 3) (m√©dia = 17/20 = 0.85).

Voc√™ testa seu sistema: 90 acertos, 10 erros.

**Compare:**
a) Posterior com prior n√£o-informativo  
b) Posterior com prior informativo  
c) Como o prior afetou o resultado?

<details>
<summary>üí° Solu√ß√£o</summary>

```python
from scipy import stats
import matplotlib.pyplot as plt
import numpy as np

# Dados
k, n = 90, 10  # acertos, erros

# Caso 1: Prior n√£o-informativo
prior_uninf = stats.beta(1, 1)
post_uninf = stats.beta(1 + k, 1 + n)

# Caso 2: Prior informativo
prior_inf = stats.beta(17, 3)
post_inf = stats.beta(17 + k, 3 + n)

# Comparar
print("PRIOR N√ÉO-INFORMATIVO:")
print(f"  Prior: Beta(1, 1)")
print(f"  Posterior: Beta({1+k}, {1+n})")
print(f"  M√©dia: {post_uninf.mean():.3f}")
print(f"  IC 95%: {post_uninf.interval(0.95)}")

print("\nPRIOR INFORMATIVO:")
print(f"  Prior: Beta(17, 3), m√©dia={prior_inf.mean():.3f}")
print(f"  Posterior: Beta({17+k}, {3+n})")
print(f"  M√©dia: {post_inf.mean():.3f}")
print(f"  IC 95%: {post_inf.interval(0.95)}")

# Visualiza√ß√£o
x = np.linspace(0.7, 1.0, 1000)

plt.figure(figsize=(12, 5))

plt.subplot(121)
plt.plot(x, prior_uninf.pdf(x), 'gray', linestyle='--', label='Prior')
plt.plot(x, post_uninf.pdf(x), 'b-', linewidth=2, label='Posterior')
plt.title('Prior N√£o-Informativo')
plt.xlabel('Acur√°cia')
plt.ylabel('Densidade')
plt.legend()
plt.grid(alpha=0.3)

plt.subplot(122)
plt.plot(x, prior_inf.pdf(x), 'gray', linestyle='--', label='Prior')
plt.plot(x, post_inf.pdf(x), 'r-', linewidth=2, label='Posterior')
plt.title('Prior Informativo')
plt.xlabel('Acur√°cia')
plt.legend()
plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()
```

**c) Impacto do prior:**
Com 100 dados, ambos convergem para regi√£o similar, mas:
- Prior informativo "puxa" ligeiramente para 0.85
- Diferen√ßa √© pequena (dados dominam)
- Com menos dados, prior teria mais influ√™ncia

</details>

---

## üéØ Se√ß√£o 5: [[Intervalos_de_Confian√ßa]]

### Exerc√≠cio 5.1: Problema do Intervalo >100% ‚≠ê‚≠ê

Dados: 98 acertos em 100 testes.

**Calcule:**
a) IC 95% usando aproxima√ß√£o Normal  
b) IC 95% usando Beta  
c) Qual est√° errado e por qu√™?

<details>
<summary>üí° Solu√ß√£o</summary>

```python
from scipy import stats
import numpy as np

# Dados
k, n = 98, 2  # corretos, incorretos
p_hat = 0.98

# a) Aproxima√ß√£o Normal
se = np.sqrt(p_hat * (1-p_hat) / (k+n))
ci_normal = [p_hat - 1.96*se, p_hat + 1.96*se]

print("APROXIMA√á√ÉO NORMAL:")
print(f"  pÃÇ = {p_hat:.3f}")
print(f"  SE = {se:.4f}")
print(f"  IC 95% = [{ci_normal[0]:.3f}, {ci_normal[1]:.3f}]")
if ci_normal[1] > 1.0:
    print(f"  ‚ùå PROBLEMA: Limite superior > 1.0!")

# b) Beta
posterior = stats.beta(k + 1, n + 1)
ci_beta = posterior.interval(0.95)

print("\nDISTRIBUI√á√ÉO BETA:")
print(f"  Posterior: Beta({k+1}, {n+1})")
print(f"  IC 95% = [{ci_beta[0]:.3f}, {ci_beta[1]:.3f}]")
print(f"  ‚úÖ Sempre respeita [0, 1]")
```

**c) Qual est√° errado:**
A aproxima√ß√£o Normal viola o limite [0,1]. Beta √© a abordagem correta para propor√ß√µes!

</details>

---

## üöÄ Se√ß√£o 6: Projeto Completo [[Aplica√ß√£o_ao_IoT_IDS]]

### Exerc√≠cio 6.1: Pipeline Completo ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Desafio:** Implemente avalia√ß√£o Bayesiana completa para comparar 3 algoritmos.

**Dados simulados:**
```python
# Resultados de 3 algoritmos no CICIoT2023
algorithms = {
    'Random Forest': {'TP': 450, 'FN': 50, 'TN': 9300, 'FP': 200},
    'XGBoost': {'TP': 460, 'FN': 40, 'TN': 9250, 'FP': 250},
    'MoT': {'TP': 440, 'FN': 60, 'TN': 9350, 'FP': 150}
}
```

**Implemente:**
1. Classe para calcular m√©tricas Bayesianas
2. Compara√ß√£o probabil√≠stica entre algoritmos
3. Visualiza√ß√£o das distribui√ß√µes posteriores
4. Recomenda√ß√£o do melhor algoritmo

<details>
<summary>üí° Esqueleto do C√≥digo</summary>

```python
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

class BayesianEvaluator:
    """Avalia√ß√£o Bayesiana de modelos IDS."""
    
    def __init__(self, confusion_matrix):
        """
        Args:
            confusion_matrix: dict com TP, FN, TN, FP
        """
        self.cm = confusion_matrix
        self.TP = confusion_matrix['TP']
        self.FN = confusion_matrix['FN']
        self.TN = confusion_matrix['TN']
        self.FP = confusion_matrix['FP']
    
    def balanced_accuracy_posterior(self, n_samples=100000):
        """Distribui√ß√£o posterior da BA."""
        # Posteriors por classe
        pos_post = stats.beta(self.TP + 1, self.FN + 1)
        neg_post = stats.beta(self.TN + 1, self.FP + 1)
        
        # Amostragem da convolu√ß√£o
        pos_samples = pos_post.rvs(n_samples)
        neg_samples = neg_post.rvs(n_samples)
        ba_samples = 0.5 * (pos_samples + neg_samples)
        
        return ba_samples
    
    def report(self):
        """Relat√≥rio completo."""
        ba_samples = self.balanced_accuracy_posterior()
        
        return {
            'mean': np.mean(ba_samples),
            'median': np.median(ba_samples),
            'std': np.std(ba_samples),
            'ci_95': np.percentile(ba_samples, [2.5, 97.5]),
            'samples': ba_samples
        }

# Avaliar algoritmos
algorithms = {
    'Random Forest': {'TP': 450, 'FN': 50, 'TN': 9300, 'FP': 200},
    'XGBoost': {'TP': 460, 'FN': 40, 'TN': 9250, 'FP': 250},
    'MoT': {'TP': 440, 'FN': 60, 'TN': 9350, 'FP': 150}
}

results = {}
for name, cm in algorithms.items():
    evaluator = BayesianEvaluator(cm)
    results[name] = evaluator.report()
    
    print(f"{name}:")
    print(f"  BA m√©dia: {results[name]['mean']:.3f}")
    print(f"  IC 95%: {results[name]['ci_95']}")
    print()

# Compara√ß√µes probabil√≠sticas
print("COMPARA√á√ïES:")
for alg1 in results:
    for alg2 in results:
        if alg1 < alg2:
            prob = np.mean(results[alg1]['samples'] > results[alg2]['samples'])
            print(f"P({alg1} > {alg2}) = {prob:.3f}")

# Visualiza√ß√£o
fig, ax = plt.subplots(figsize=(12, 6))

for name, result in results.items():
    ax.hist(result['samples'], bins=50, alpha=0.5, label=name, density=True)

ax.set_xlabel('Balanced Accuracy')
ax.set_ylabel('Densidade')
ax.set_title('Distribui√ß√µes Posteriores - Compara√ß√£o de Algoritmos IDS')
ax.legend()
ax.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('algorithm_comparison.png', dpi=300)
plt.show()

# COMPLETE VOC√ä: Adicione mais an√°lises!
```

</details>

---

## ‚úÖ Gabarito R√°pido

### Respostas dos Exerc√≠cios Principais

**1.1:** m√©dia=0.90, desvio=0.0158, SE=0.0071  
**2.1:** Beta(86,16), m√©dia=0.843, moda=0.85  
**3.1:** Acc=98.5%, BA=94.5%  
**3.2:** Acc=95%, BA=50% (modelo in√∫til!)  
**5.1:** Normal viola [0,1], Beta √© correto

---

## üìö Pr√≥ximos Passos

Depois de completar estes exerc√≠cios:

1. Aplique ao seu dataset CICIoT2023 real
2. Integre com seu pipeline DVC
3. Documente no seu projeto
4. Use nas compara√ß√µes de algoritmos

---

## üîó Conceitos Relacionados

- [[Acur√°cia]]
- [[Acur√°cia_Balanceada]]
- [[Distribui√ß√£o_Beta]]
- [[Infer√™ncia_Bayesiana]]
- [[Intervalos_de_Confian√ßa]]
- [[M√©dia_Desvio_Padr√£o_Erro_Padr√£o]]
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]
- [[Aplica√ß√£o_ao_IoT_IDS]]
- [[Refer√™ncias_Bibliogr√°ficas]]

---

**Tags:** #exercises #practice #hands-on #python #IDS #balanced-accuracy #bayesian

**Voltar para:** [[INDEX]]


