# MÃ©todos ParamÃ©tricos vs. NÃ£o-ParamÃ©tricos

> **Tipo:** Filosofia EstatÃ­stica  
> **Complexidade:** â­â­â­â˜†â˜† (IntermediÃ¡rio-AvanÃ§ado)  
> **AplicaÃ§Ã£o:** Escolha de Abordagem de Modelagem

---

## ğŸ¯ A DiferenÃ§a Fundamental

A distinÃ§Ã£o entre mÃ©todos **paramÃ©tricos** e **nÃ£o-paramÃ©tricos** estÃ¡ em **como modelamos os dados**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARAMÃ‰TRICO                           â”‚
â”‚  "Assumo que os dados seguem           â”‚
â”‚   distribuiÃ§Ã£o especÃ­fica com          â”‚
â”‚   parÃ¢metros fixos"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NÃƒO-PARAMÃ‰TRICO                       â”‚
â”‚  "NÃ£o assumo distribuiÃ§Ã£o especÃ­fica;  â”‚
â”‚   deixo os dados falarem"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”µ MÃ©todos ParamÃ©tricos

### DefiniÃ§Ã£o

Um mÃ©todo Ã© **paramÃ©trico** quando:
1. Assume que os dados seguem uma [[DistribuiÃ§Ãµes_de_Probabilidade|distribuiÃ§Ã£o especÃ­fica]]
2. A distribuiÃ§Ã£o Ã© caracterizada por um **conjunto finito e fixo de parÃ¢metros**

### Exemplo: [[AcurÃ¡cia]] como [[DistribuiÃ§Ã£o_Beta|Beta]]

```
Assumo: AcurÃ¡cia Î¸ ~ Beta(Î±, Î²)

ParÃ¢metros: Î±, Î²  (apenas 2!)

Toda a distribuiÃ§Ã£o Ã© descrita por Î± e Î²
```

### O que Significa "ParÃ¢metro"?

**ParÃ¢metro (Î¸):**
- CaracterÃ­stica da **populaÃ§Ã£o** (desconhecida)
- Exemplo: verdadeira acurÃ¡cia do modelo = Î¸

**EstatÃ­stica:**
- Valor calculado da **amostra** (observado)
- Exemplo: acurÃ¡cia observada = xÌ„

**Objetivo:** Estimar Î¸ a partir dos dados.

### Vantagens

âœ… **EficiÃªncia:** Usa toda a informaÃ§Ã£o dos dados de forma Ã³tima (se modelo correto)

âœ… **Poder:** Testes estatÃ­sticos mais poderosos

âœ… **PrecisÃ£o:** Estimativas mais precisas com menos dados

âœ… **InterpretaÃ§Ã£o:** ParÃ¢metros tÃªm significado claro

âœ… **InferÃªncia:** Intervalos de confianÃ§a matematicamente rigorosos

### Desvantagens

âŒ **SuposiÃ§Ã£o forte:** Se a distribuiÃ§Ã£o assumida estiver errada, resultados podem ser ruins

âŒ **Falta de flexibilidade:** Limitado Ã s formas da distribuiÃ§Ã£o escolhida

âŒ **VerificaÃ§Ã£o:** Precisa verificar se suposiÃ§Ãµes sÃ£o vÃ¡lidas

### Exemplos ClÃ¡ssicos

**Teste t de Student:**
```
Assume: dados ~ Normal(Î¼, ÏƒÂ²)
ParÃ¢metros: Î¼, ÏƒÂ²
Testa: Hâ‚€: Î¼ = Î¼â‚€
```

**RegressÃ£o Linear:**
```
Assume: y = Î²â‚€ + Î²â‚x + Îµ, onde Îµ ~ Normal(0, ÏƒÂ²)
ParÃ¢metros: Î²â‚€, Î²â‚, ÏƒÂ²
```

**[[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo Brodersen]]:**
```
Assume: AcurÃ¡cia ~ Beta(Î±, Î²)
ParÃ¢metros: Î±, Î²
```

---

## ğŸŸ¢ MÃ©todos NÃ£o-ParamÃ©tricos

### DefiniÃ§Ã£o

Um mÃ©todo Ã© **nÃ£o-paramÃ©trico** quando:
1. **NÃƒO assume** distribuiÃ§Ã£o especÃ­fica dos dados
2. NÃºmero de "parÃ¢metros" pode crescer com os dados (ou nÃ£o usa parÃ¢metros explÃ­citos)

**Nome enganoso:** "NÃ£o-paramÃ©trico" nÃ£o significa "sem parÃ¢metros", mas sim "livre de distribuiÃ§Ã£o"!

### Exemplo: [[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o|MÃ©dia Â± Erro PadrÃ£o]]

```
NÃ£o assumo distribuiÃ§Ã£o especÃ­fica

Apenas calculo:
- xÌ„ = âˆ‘xáµ¢ / n
- SE = s / âˆšn
- IC â‰ˆ xÌ„ Â± 2Ã—SE
```

### Vantagens

âœ… **Flexibilidade:** Funciona para qualquer distribuiÃ§Ã£o

âœ… **Robustez:** Menos sensÃ­vel a outliers e violaÃ§Ãµes de suposiÃ§Ãµes

âœ… **Simplicidade:** NÃ£o precisa verificar suposiÃ§Ãµes distributivas

âœ… **SeguranÃ§a:** Menos propenso a erros por modelo incorreto

### Desvantagens

âŒ **EficiÃªncia:** Pode precisar de mais dados para mesma precisÃ£o

âŒ **Poder:** Testes menos poderosos

âŒ **[[Intervalos_de_ConfianÃ§a|Intervalos inadequados]]:** Podem violar limites naturais

âŒ **InterpretaÃ§Ã£o:** Menos estrutura teÃ³rica

### Exemplos ClÃ¡ssicos

**Teste de Mann-Whitney U:**
```
NÃ£o assume distribuiÃ§Ã£o
Compara medianas de dois grupos
```

**Teste de Wilcoxon:**
```
NÃ£o assume normalidade
Testa diferenÃ§a entre pares
```

**Bootstrap:**
```
Reamostragem dos dados
Estima distribuiÃ§Ã£o empiricamente
```

---

## âš–ï¸ ComparaÃ§Ã£o Direta

### Tabela Comparativa

| Aspecto | ParamÃ©trico | NÃ£o-ParamÃ©trico |
|---------|-------------|-----------------|
| **SuposiÃ§Ãµes** | DistribuiÃ§Ã£o especÃ­fica | MÃ­nimas/Nenhuma |
| **ParÃ¢metros** | Fixos, finitos | FlexÃ­veis, podem crescer |
| **EficiÃªncia** | Alta (se correto) | Menor |
| **Robustez** | Baixa (se errado) | Alta |
| **Dados necessÃ¡rios** | Menos | Mais |
| **Complexidade** | Maior (modelagem) | Menor (cÃ¡lculos) |
| **InterpretaÃ§Ã£o** | Clara (parÃ¢metros) | Limitada |
| **Limites naturais** | Respeitados (se bem modelado) | Podem violar |

### Exemplo: [[AcurÃ¡cia]] 98% em 100 Testes

#### Abordagem NÃ£o-ParamÃ©trica
```
pÌ‚ = 0.98
SE = âˆš[pÌ‚(1-pÌ‚)/n] = âˆš[0.98Ã—0.02/100] = 0.014

IC 95% = [0.98 - 1.96Ã—0.014, 0.98 + 1.96Ã—0.014]
       = [0.953, 1.007]  â† 100.7%! âŒ
```

**Problema:** Viola limite [0,1]!

#### Abordagem ParamÃ©trica (Beta)
```
Modelo: Î¸ ~ Beta(99, 3)

IC 95% = [0.932, 0.997]  âœ…
```

**Vantagem:** Respeita limites naturalmente!

---

## ğŸ”„ Quando Usar Cada Um?

### Use ParamÃ©trico Quando:

1. âœ… **Conhece a distribuiÃ§Ã£o:** Processo gerador Ã© bem compreendido
   - Exemplo: ClassificaÃ§Ã£o binÃ¡ria â†’ Binomial/Beta

2. âœ… **Dados limitados:** Poucos dados disponÃ­veis
   - MÃ©todo paramÃ©trico usa informaÃ§Ã£o mais eficientemente

3. âœ… **Limites naturais:** VariÃ¡vel tem restriÃ§Ãµes (ex: [0,1])
   - Modelo paramÃ©trico respeita isso

4. âœ… **InferÃªncia rigorosa:** Precisa de intervalos de confianÃ§a precisos
   - Framework matemÃ¡tico mais sÃ³lido

5. âœ… **Paradigma [[InferÃªncia_Bayesiana|Bayesiano]]:** Incorporando conhecimento prÃ©vio
   - Precisa especificar prior paramÃ©trico

### Use NÃ£o-ParamÃ©trico Quando:

1. âœ… **DistribuiÃ§Ã£o desconhecida:** NÃ£o sabe qual distribuiÃ§Ã£o assumir
   - Seguro nÃ£o fazer suposiÃ§Ãµes

2. âœ… **ViolaÃ§Ãµes de suposiÃ§Ãµes:** Dados claramente nÃ£o seguem distribuiÃ§Ã£o padrÃ£o
   - Outliers, assimetrias extremas

3. âœ… **ExploraÃ§Ã£o inicial:** Primeira anÃ¡lise dos dados
   - Entender padrÃµes sem compromisso

4. âœ… **Muitos dados:** Dataset grande
   - NÃ£o precisa da eficiÃªncia paramÃ©trica

5. âœ… **Simplicidade:** AnÃ¡lise rÃ¡pida sem modelagem complexa
   - Trade-off entre simplicidade e rigor

---

## ğŸ¯ Contexto do [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo Brodersen]]

### O Problema Identificado

**Abordagem tradicional (nÃ£o-paramÃ©trica):**
```python
# Cross-validation tradicional
acuracias = [0.91, 0.89, 0.92, 0.88, 0.90]

# MÃ©dia e erro padrÃ£o
media = np.mean(acuracias)
se = np.std(acuracias, ddof=1) / np.sqrt(len(acuracias))

# IC "aproximado"
ic = [media - 1.96*se, media + 1.96*se]
# Pode violar [0,1]! âŒ
```

**Problemas:**
1. âŒ NÃ£o respeita limites [0, 1]
2. âŒ Assume normalidade (aproximaÃ§Ã£o CLT)
3. âŒ Sempre simÃ©trico
4. âŒ Depende de escolhas arbitrÃ¡rias (nÃºmero de folds)

### A SoluÃ§Ã£o Proposta (ParamÃ©trica)

**Abordagem Bayesiana com Beta:**
```python
from scipy import stats

# Agregar todos os resultados
corretos = 93
incorretos = 7

# Modelo paramÃ©trico
posterior = stats.beta(corretos + 1, incorretos + 1)

# IC correto
ic = posterior.interval(0.95)
# [0.873, 0.971] âœ… Sempre em [0,1]!
```

**Vantagens:**
1. âœ… Respeita limites naturalmente
2. âœ… NÃ£o assume normalidade
3. âœ… AssimÃ©trico quando apropriado
4. âœ… InterpretaÃ§Ã£o probabilÃ­stica direta

### Filosofia do Artigo

> "Substituir ponto estimado **nÃ£o-paramÃ©trico** por distribuiÃ§Ã£o **paramÃ©trica** completa"

**De:**
```
AcurÃ¡cia = 90% Â± 2%  (nÃ£o-paramÃ©trico)
```

**Para:**
```
AcurÃ¡cia ~ Beta(91, 11)  (paramÃ©trico)
```

Ganha toda a rica estrutura da distribuiÃ§Ã£o Beta!

---

## ğŸ§ª Exemplo Comparativo Completo

### CenÃ¡rio: [[AplicaÃ§Ã£o_ao_IoT_IDS|Sistema IDS]]

**Dados:** 10-fold cross-validation, acurÃ¡cias:
```
[0.89, 0.91, 0.88, 0.92, 0.90, 0.89, 0.91, 0.88, 0.93, 0.89]
```

### AnÃ¡lise NÃ£o-ParamÃ©trica

```python
import numpy as np
from scipy import stats as sp_stats

acuracias = [0.89, 0.91, 0.88, 0.92, 0.90, 
             0.89, 0.91, 0.88, 0.93, 0.89]

# EstatÃ­sticas
media = np.mean(acuracias)
desvio = np.std(acuracias, ddof=1)
se = desvio / np.sqrt(len(acuracias))

# IC com distribuiÃ§Ã£o t
ic_t = sp_stats.t.interval(0.95, df=len(acuracias)-1,
                            loc=media, scale=se)

print("NÃƒO-PARAMÃ‰TRICO:")
print(f"MÃ©dia: {media:.3f}")
print(f"SE: {se:.3f}")
print(f"IC 95%: [{ic_t[0]:.3f}, {ic_t[1]:.3f}]")
# IC 95%: [0.884, 0.916]
```

### AnÃ¡lise ParamÃ©trica (Beta)

```python
# Assumir cada fold teve 100 testes
# AcurÃ¡cias â†’ nÃºmero de acertos
acertos = [int(a * 100) for a in acuracias]
total_acertos = sum(acertos)
total_testes = len(acertos) * 100

# Modelo Beta
posterior = sp_stats.beta(total_acertos + 1, 
                          total_testes - total_acertos + 1)

# EstatÃ­sticas
media_beta = posterior.mean()
ic_beta = posterior.interval(0.95)

print("\nPARAMÃ‰TRICO (Beta):")
print(f"MÃ©dia: {media_beta:.3f}")
print(f"IC 95%: [{ic_beta[0]:.3f}, {ic_beta[1]:.3f}]")
# IC 95%: [0.884, 0.916]

# Probabilidades adicionais!
print(f"\nP(acc > 0.85): {1 - posterior.cdf(0.85):.3f}")
print(f"P(acc > 0.90): {1 - posterior.cdf(0.90):.3f}")
```

### ComparaÃ§Ã£o

```
MÃ©trica           | NÃ£o-ParamÃ©trico | ParamÃ©trico
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MÃ©dia             | 0.900           | 0.900
IC 95%            | [0.884, 0.916]  | [0.884, 0.916]
Respeita [0,1]    | Sim (por sorte) | Sim (sempre)
P(acc > 0.85)     | âŒ NÃ£o calcula  | âœ… 0.999
P(acc > 0.90)     | âŒ NÃ£o calcula  | âœ… 0.503
Comparar modelos  | âŒ DifÃ­cil      | âœ… FÃ¡cil
```

**Neste caso:** Resultados similares, mas abordagem paramÃ©trica oferece **mais informaÃ§Ã£o**!

---

## ğŸ’¡ Conceitos Relacionados

### "SemiparamÃ©trico"

Meio-termo: alguns parÃ¢metros, mas distribuiÃ§Ã£o flexÃ­vel.

**Exemplo:** RegressÃ£o de Cox (survival analysis)

### Bootstrap (NÃ£o-ParamÃ©trico AvanÃ§ado)

```python
# Reamostragem para estimar distribuiÃ§Ã£o
from sklearn.utils import resample

bootstrap_means = []
for _ in range(10000):
    sample = resample(acuracias)
    bootstrap_means.append(np.mean(sample))

# IC via percentis
ic_bootstrap = np.percentile(bootstrap_means, [2.5, 97.5])
```

**Vantagem:** NÃ£o assume distribuiÃ§Ã£o!  
**Desvantagem:** Computacionalmente intensivo.

---

## ğŸ“š ReferÃªncias

### Livros
- **Wasserman, L.** (2006). *All of Nonparametric Statistics*. Springer. [CapÃ­tulo 1: "Parametric vs Nonparametric"]
- **Sheskin, D.J.** (2011). *Handbook of Parametric and Nonparametric Statistical Procedures* (5th ed.). CRC Press.
- **Hollander, M., Wolfe, D.A., & Chicken, E.** (2013). *Nonparametric Statistical Methods* (3rd ed.). Wiley.

### Papers
- **Brodersen et al.** (2010). [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|"The balanced accuracy and its posterior distribution"]]. ICPR.

### Online
- [Scipy: stats module](https://docs.scipy.org/doc/scipy/reference/stats.html)
- [Khan Academy: Hypothesis Testing](https://www.khanacademy.org/math/statistics-probability)

Veja [[ReferÃªncias_BibliogrÃ¡ficas]] para lista completa.

---

## ğŸ”— Conceitos Relacionados

### Fundamentos
- [[DistribuiÃ§Ãµes_de_Probabilidade]] - Framework paramÃ©trico
- [[DistribuiÃ§Ã£o_Beta]] - Exemplo paramÃ©trico especÃ­fico
- [[MÃ©dia_Desvio_PadrÃ£o_Erro_PadrÃ£o]] - EstatÃ­sticas nÃ£o-paramÃ©tricas

### Paradigmas
- [[InferÃªncia_Bayesiana]] - Sempre paramÃ©trica
- [[Intervalos_de_ConfianÃ§a]] - Ambas as abordagens

### AplicaÃ§Ãµes
- [[AcurÃ¡cia]] - Pode usar ambas
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]] - Advocacia pela paramÃ©trica

---

## ğŸ¯ ExercÃ­cios

Veja [[ExercÃ­cios_PrÃ¡ticos#ParamÃ©trico vs NÃ£o-ParamÃ©trico]].

---

## ğŸ“Œ Resumo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PARAMÃ‰TRICO vs NÃƒO-PARAMÃ‰TRICO            â”‚
â”‚                                              â”‚
â”‚  PARAMÃ‰TRICO                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  â€¢ Assume distribuiÃ§Ã£o especÃ­fica            â”‚
â”‚  â€¢ ParÃ¢metros fixos                          â”‚
â”‚  â€¢ Mais eficiente (se correto)               â”‚
â”‚  â€¢ Respeita limites naturais                 â”‚
â”‚  âœ… Artigo usa este!                         â”‚
â”‚                                              â”‚
â”‚  NÃƒO-PARAMÃ‰TRICO                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚  â€¢ Sem assumir distribuiÃ§Ã£o                 â”‚
â”‚  â€¢ FlexÃ­vel                                  â”‚
â”‚  â€¢ Mais robusto                              â”‚
â”‚  â€¢ Pode violar limites                       â”‚
â”‚  âŒ Problema identificado                    â”‚
â”‚                                              â”‚
â”‚  Trade-off: EficiÃªncia vs. Robustez         â”‚
â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Tags:** #statistics #parametric #nonparametric #modeling #philosophy #methodology

**Voltar para:** [[INDEX]]  
**Fundamento:** [[DistribuiÃ§Ãµes_de_Probabilidade]]  
**AplicaÃ§Ã£o:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]


