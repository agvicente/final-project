# InferÃªncia Bayesiana

> **Tipo:** Paradigma EstatÃ­stico  
> **Complexidade:** â­â­â­â­â˜† (AvanÃ§ado)  
> **AplicaÃ§Ã£o:** Framework do [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo Principal]]

---

## ğŸ¯ O que Ã© InferÃªncia Bayesiana?

**InferÃªncia Bayesiana** Ã© um paradigma de raciocÃ­nio probabilÃ­stico onde:
- ParÃ¢metros sÃ£o tratados como **variÃ¡veis aleatÃ³rias** (tÃªm distribuiÃ§Ãµes)
- Usamos **Teorema de Bayes** para atualizar crenÃ§as com base em evidÃªncias
- Resultados sÃ£o **distribuiÃ§Ãµes de probabilidade**, nÃ£o pontos

**Contraste com Frequentismo:**
```
FREQUENTISTA:
Î¸ Ã© fixo (mas desconhecido)
Dados sÃ£o aleatÃ³rios
"Probabilidade" = frequÃªncia de longo prazo

BAYESIANO:
Î¸ Ã© variÃ¡vel aleatÃ³ria (tem distribuiÃ§Ã£o)
Dados sÃ£o fixos (observados)
"Probabilidade" = grau de crenÃ§a
```

---

## ğŸ“ Teorema de Bayes

### Forma Geral

```
P(Î¸|dados) = [P(dados|Î¸) Ã— P(Î¸)] / P(dados)

Posterior = [Likelihood Ã— Prior] / Evidence
```

**Componentes:**

1. **P(Î¸):** **Prior** - CrenÃ§a inicial sobre Î¸ (antes de ver dados)
2. **P(dados|Î¸):** **Likelihood** - Probabilidade dos dados dado Î¸
3. **P(dados):** **Evidence/Marginal** - Probabilidade total dos dados
4. **P(Î¸|dados):** **Posterior** - CrenÃ§a atualizada sobre Î¸ (apÃ³s ver dados)

### Evidence (NormalizaÃ§Ã£o)

```
P(dados) = âˆ« P(dados|Î¸) Ã— P(Î¸) dÎ¸
```

Frequentemente difÃ­cil de calcular, mas pode ser ignorado:

```
P(Î¸|dados) âˆ P(dados|Î¸) Ã— P(Î¸)

Posterior âˆ Likelihood Ã— Prior
```

---

## ğŸ”„ Ciclo Bayesiano

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PRIOR      â”‚  CrenÃ§a inicial P(Î¸)
â”‚     P(Î¸)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. DADOS      â”‚  ObservaÃ§Ãµes X
â”‚     X          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. LIKELIHOOD â”‚  P(X|Î¸) - Modelo dos dados
â”‚     P(X|Î¸)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. BAYES      â”‚  P(Î¸|X) = P(X|Î¸) Ã— P(Î¸) / P(X)
â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. POSTERIOR  â”‚  CrenÃ§a atualizada P(Î¸|X)
â”‚     P(Î¸|X)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚  (Pode virar novo prior!)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚
                     â–¼
              Novos dados...
```

---

## ğŸ² Exemplo Completo: [[AcurÃ¡cia]] de [[AplicaÃ§Ã£o_ao_IoT_IDS|IDS]]

### CenÃ¡rio

VocÃª desenvolveu um IDS e quer estimar sua verdadeira acurÃ¡cia Î¸.

### Passo 1: Especificar Prior

**Sem conhecimento prÃ©vio:**
```
Î¸ ~ Beta(1, 1)  = Uniforme(0, 1)
```

"Qualquer acurÃ¡cia entre 0% e 100% Ã© igualmente plausÃ­vel."

**Com conhecimento prÃ©vio:**
```
Î¸ ~ Beta(10, 3)  # MÃ©dia â‰ˆ 0.77
```

"Com base em sistemas similares, espero acurÃ¡cia em torno de 77%."

### Passo 2: Coletar Dados

```
Teste o IDS em 100 conexÃµes
Resultado: 90 acertos, 10 erros
```

### Passo 3: Definir Likelihood

**Modelo:** Cada classificaÃ§Ã£o Ã© Bernoulli(Î¸)

```
P(dados|Î¸) = Î¸^90 Ã— (1-Î¸)^10  (ignorando constantes)
```

Mais formalmente:
```
X | Î¸ ~ Binomial(100, Î¸)
P(X=90|Î¸) = C(100,90) Ã— Î¸^90 Ã— (1-Î¸)^10
```

### Passo 4: Aplicar Bayes

**Com prior nÃ£o-informativo:**
```
Prior: Beta(1, 1)
Likelihood: Binomial(90 | 100, Î¸)

Posterior: Beta(1+90, 1+10) = Beta(91, 11)
```

**Com prior informativo:**
```
Prior: Beta(10, 3)
Likelihood: Binomial(90 | 100, Î¸)

Posterior: Beta(10+90, 3+10) = Beta(100, 13)
```

### Passo 5: Interpretar Posterior

```python
from scipy import stats

# Sem prior
post_uninformative = stats.beta(91, 11)
print(f"MÃ©dia: {post_uninformative.mean():.3f}")  # 0.892
print(f"IC 95%: {post_uninformative.interval(0.95)}")  # [0.838, 0.946]

# Com prior
post_informative = stats.beta(100, 13)
print(f"MÃ©dia: {post_informative.mean():.3f}")  # 0.885
print(f"IC 95%: {post_informative.interval(0.95)}")  # [0.835, 0.929]
```

**InterpretaÃ§Ã£o:**
> "Dado que observei 90 acertos em 100 tentativas, hÃ¡ 95% de probabilidade da verdadeira acurÃ¡cia estar entre 83.8% e 94.6%."

---

## âš–ï¸ ComparaÃ§Ã£o: Bayesiano vs. Frequentista

### Filosofia

| Aspecto | Frequentista | Bayesiano |
|---------|-------------|-----------|
| **ParÃ¢metro Î¸** | Fixo, desconhecido | VariÃ¡vel aleatÃ³ria |
| **Dados** | AleatÃ³rios | Fixos (observados) |
| **Probabilidade** | FrequÃªncia longo prazo | Grau de crenÃ§a |
| **Prior** | NÃ£o existe | Essencial |
| **Resultado** | Ponto + IC | DistribuiÃ§Ã£o completa |
| **InterpretaÃ§Ã£o IC** | "95% dos ICs capturam Î¸" | "95% prob. de Î¸ estar ali" |

### Exemplo: 90 Acertos em 100 Testes

#### Abordagem Frequentista
```
Estimativa: pÌ‚ = 0.90
IC 95%: [0.831, 0.946]  (Wilson score)

InterpretaÃ§Ã£o:
"Se repetirmos o experimento infinitas vezes,
95% dos intervalos conterÃ£o o verdadeiro Î¸."

NÃ£o podemos dizer: "95% de probabilidade de Î¸ estar em [0.831, 0.946]"
(Î¸ Ã© fixo, ou estÃ¡ ou nÃ£o estÃ¡!)
```

#### Abordagem Bayesiana
```
Posterior: Î¸ ~ Beta(91, 11)
IC 95%: [0.838, 0.946]

InterpretaÃ§Ã£o:
"HÃ¡ 95% de probabilidade de Î¸ estar em [0.838, 0.946]"

AlÃ©m disso:
P(Î¸ > 0.85) = 0.973
P(Î¸ > 0.90) = 0.503
```

**Vantagem Bayesiana:** InterpretaÃ§Ã£o probabilÃ­stica direta!

---

## ğŸ”— Priors Conjugados

### DefiniÃ§Ã£o

Um **prior conjugado** para uma likelihood Ã© aquele cuja posterior tem a **mesma famÃ­lia de distribuiÃ§Ãµes** do prior.

```
Prior: FamÃ­lia F
+ Likelihood: DistribuiÃ§Ã£o D
= Posterior: FamÃ­lia F (mesma!)
```

**Vantagem:** Posterior tem forma analÃ­tica fechada!

### Principais Pares Conjugados

| Likelihood | Prior Conjugado | Posterior | Uso |
|------------|-----------------|-----------|-----|
| **Binomial(n, Î¸)** | **[[DistribuiÃ§Ã£o_Beta\|Beta(Î±, Î²)]]** | **Beta(Î±+k, Î²+n-k)** | **ProporÃ§Ãµes** â­ |
| Poisson(Î») | Gamma(Î±, Î²) | Gamma(Î±+âˆ‘x, Î²+n) | Contagens |
| Normal(Î¼, ÏƒÂ²) | Normal(Î¼â‚€, Ï„Â²) | Normal(...) | MÃ©dias |
| Exponencial(Î») | Gamma(Î±, Î²) | Gamma(Î±+n, Î²+âˆ‘x) | Tempos |
| Multinomial | Dirichlet | Dirichlet | Multiclasse |

### Beta-Binomial (Do [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo]])

**Setup:**
```
Prior: Î¸ ~ Beta(Î±, Î²)
Likelihood: X ~ Binomial(n, Î¸), observamos k sucessos
Posterior: Î¸ | X ~ Beta(Î± + k, Î² + n - k)
```

**Por que Ã© mÃ¡gico:**
```python
# AtualizaÃ§Ã£o sequencial Ã© trivial!
alpha, beta = 1, 1  # Prior

# ObservaÃ§Ã£o 1: acerto
alpha += 1

# ObservaÃ§Ã£o 2: acerto
alpha += 1

# ObservaÃ§Ã£o 3: erro
beta += 1

# Posterior: Beta(3, 2)
# MÃ©dia = 3/(3+2) = 0.6 = 60%
```

---

## ğŸ“Š Escolhendo o Prior

### Tipos de Priors

#### 1. NÃ£o-Informativo (Uninformative)

**Objetivo:** Deixar dados falarem.

**Exemplos:**
```
Beta(1, 1) = Uniforme(0, 1)
Beta(0.5, 0.5)  # Jeffreys prior
```

**Uso:** Quando nÃ£o tem conhecimento prÃ©vio.

#### 2. Informativo (Informative)

**Objetivo:** Incorporar conhecimento de domÃ­nio.

**Exemplo:**
```
# Sei que sistemas similares tÃªm acc ~ 85%
# Com moderada confianÃ§a (equivalente a ~20 observaÃ§Ãµes)
Beta(17, 3)  # MÃ©dia = 17/20 = 0.85
```

**Uso:** Quando tem informaÃ§Ã£o prÃ©via valiosa.

#### 3. Fracamente Informativo (Weakly Informative)

**Objetivo:** RegularizaÃ§Ã£o suave, evitar valores absurdos.

**Exemplo:**
```
# AcurÃ¡cia deve ser razoÃ¡vel, mas sem certeza forte
Beta(2, 2)  # SimÃ©trico, suavemente centrado em 0.5
```

**Uso:** BalanÃ§o entre informaÃ§Ã£o e flexibilidade.

### Sensibilidade ao Prior

**Com poucos dados:** Posterior dominado pelo prior

**Com muitos dados:** Dados dominam, prior tem pouco efeito

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Diferentes priors
priors = [
    (1, 1, "NÃ£o-informativo"),
    (10, 3, "Informativo (otimista)"),
    (3, 10, "Informativo (pessimista)")
]

# Dados: 90/100 acertos
k, n = 90, 10

x = np.linspace(0, 1, 1000)

for alpha0, beta0, label in priors:
    posterior = stats.beta(alpha0 + k, beta0 + n)
    plt.plot(x, posterior.pdf(x), label=f"{label}: Beta({alpha0+k},{beta0+n})")

plt.xlabel('Î¸ (acurÃ¡cia)')
plt.ylabel('Densidade')
plt.title('Posteriors com Diferentes Priors (90/100 acertos)')
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

**ConclusÃ£o:** Com 100 dados, todos convergem para regiÃ£o similar!

---

## ğŸ¯ AplicaÃ§Ã£o no [[The_Balanced_Accuracy_and_Its_Posterior_Distribution|Artigo]]

### Para [[AcurÃ¡cia]] Simples

```python
from scipy import stats

# Dados agregados de cross-validation
corretos = 93
incorretos = 7

# Prior nÃ£o-informativo
prior = stats.beta(1, 1)

# Posterior
posterior = stats.beta(corretos + 1, incorretos + 1)

# EstatÃ­sticas
print(f"MÃ©dia: {posterior.mean():.3f}")
print(f"IC 95%: {posterior.interval(0.95)}")

# Probabilidades
print(f"P(acc > 0.85): {1 - posterior.cdf(0.85):.3f}")
```

### Para [[AcurÃ¡cia_Balanceada]]

**Mais complexo:** Duas distribuiÃ§Ãµes independentes.

```python
# Dados por classe
TP, FN = 450, 50  # Classe positiva
TN, FP = 9300, 200  # Classe negativa

# Posteriors independentes
pos_posterior = stats.beta(TP + 1, FN + 1)
neg_posterior = stats.beta(TN + 1, FP + 1)

# BA via amostragem (convoluÃ§Ã£o)
n_samples = 100000
pos_samples = pos_posterior.rvs(n_samples)
neg_samples = neg_posterior.rvs(n_samples)
ba_samples = 0.5 * (pos_samples + neg_samples)

# EstatÃ­sticas
print(f"BA mÃ©dia: {np.mean(ba_samples):.3f}")
print(f"IC 95%: {np.percentile(ba_samples, [2.5, 97.5])}")
```

---

## ğŸ§® ComparaÃ§Ã£o de Modelos Bayesiana

### Bayes Factor

```
BF = P(dados|Modelo A) / P(dados|Modelo B)
```

**InterpretaÃ§Ã£o:**
- BF > 10: EvidÃªncia forte para A
- BF > 100: EvidÃªncia muito forte para A
- BF < 0.1: EvidÃªncia forte para B

### Probabilidade Direta

Mais simples: amostrar de ambas posteriors!

```python
# Dois algoritmos
model_A_post = stats.beta(90 + 1, 10 + 1)
model_B_post = stats.beta(85 + 1, 15 + 1)

# Amostrar
samples_A = model_A_post.rvs(100000)
samples_B = model_B_post.rvs(100000)

# P(A > B)
prob_A_better = np.mean(samples_A > samples_B)
print(f"P(A > B) = {prob_A_better:.3f}")

if prob_A_better > 0.95:
    print("A Ã© significativamente melhor que B!")
```

---

## ğŸ’» Ferramentas Computacionais

### Python: Scipy (AnalÃ­tico)

Para casos simples com conjugaÃ§Ã£o:

```python
from scipy import stats

posterior = stats.beta(91, 11)
samples = posterior.rvs(10000)
```

### Python: PyMC (MCMC)

Para modelos complexos:

```python
import pymc as pm

with pm.Model() as model:
    # Prior
    theta = pm.Beta('theta', alpha=1, beta=1)
    
    # Likelihood
    obs = pm.Binomial('obs', n=100, p=theta, observed=90)
    
    # Sample
    trace = pm.sample(2000, return_inferencedata=True)

# AnÃ¡lise
print(pm.summary(trace))
```

### R: rstan, brms

Framework robusto para modelos hierÃ¡rquicos.

---

## ğŸ“š ReferÃªncias

### Livros Essenciais
- **McElreath, R.** (2020). *Statistical Rethinking* (2nd ed.). CRC Press. â­ **MAIS DIDÃTICO!**
- **Gelman, A., et al.** (2013). *Bayesian Data Analysis* (3rd ed.). CRC Press. â­ **REFERÃŠNCIA DEFINITIVA**
- **Kruschke, J.K.** (2014). *Doing Bayesian Data Analysis* (2nd ed.). Academic Press. **Excelente para iniciantes**

### Fundamentos
- **Sivia, D.S. & Skilling, J.** (2006). *Data Analysis: A Bayesian Tutorial* (2nd ed.). Oxford University Press.
- **Jaynes, E.T.** (2003). *Probability Theory: The Logic of Science*. Cambridge University Press.

### Aplicado
- **Bishop, C.M.** (2006). *Pattern Recognition and Machine Learning*. Springer. [SeÃ§Ã£o 2.2] **Citado no artigo!**

### Online
- [3Blue1Brown: Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM)
- [Seeing Theory: Bayesian Inference](https://seeing-theory.brown.edu/bayesian-inference/)
- [PyMC Documentation](https://www.pymc.io/)

Veja [[ReferÃªncias_BibliogrÃ¡ficas]] para lista completa.

---

## ğŸ”— Conceitos Relacionados

### Fundamentos
- [[DistribuiÃ§Ãµes_de_Probabilidade]] - Priors e posteriors
- [[DistribuiÃ§Ã£o_Beta]] - Prior/posterior para proporÃ§Ãµes
- [[Intervalos_de_ConfianÃ§a]] - Intervalos de credibilidade

### Filosofia
- [[MÃ©todos_ParamÃ©tricos_vs_NÃ£o_ParamÃ©tricos]] - Bayesiano Ã© paramÃ©trico

### AplicaÃ§Ãµes
- [[AcurÃ¡cia]] - Modelagem Bayesiana
- [[AcurÃ¡cia_Balanceada]] - Com posteriors
- [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]] - Artigo usa framework Bayesiano
- [[AplicaÃ§Ã£o_ao_IoT_IDS]] - Uso prÃ¡tico

---

## ğŸ¯ ExercÃ­cios

Veja [[ExercÃ­cios_PrÃ¡ticos#InferÃªncia Bayesiana]].

---

## ğŸ“Œ Resumo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         INFERÃŠNCIA BAYESIANA                  â”‚
â”‚                                               â”‚
â”‚  Teorema de Bayes:                            â”‚
â”‚  P(Î¸|dados) = P(dados|Î¸) Ã— P(Î¸) / P(dados)   â”‚
â”‚                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚  â”‚  PRIOR  â”‚  CrenÃ§a inicial                 â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                 â”‚
â”‚       â”‚                                       â”‚
â”‚       â”œâ”€â”€â–º + LIKELIHOOD (dados)              â”‚
â”‚       â”‚                                       â”‚
â”‚       â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  â”‚ POSTERIORâ”‚  CrenÃ§a atualizada             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                               â”‚
â”‚  Para AcurÃ¡cia:                              â”‚
â”‚  â€¢ Prior: Beta(Î±, Î²)                         â”‚
â”‚  â€¢ Likelihood: Binomial                      â”‚
â”‚  â€¢ Posterior: Beta(Î±+k, Î²+n-k) âœ…            â”‚
â”‚                                               â”‚
â”‚  Artigo usa este framework!                  â”‚
â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Tags:** #bayesian #inference #prior #posterior #likelihood #bayes-theorem #beta-binomial

**Voltar para:** [[INDEX]]  
**Framework:** [[DistribuiÃ§Ã£o_Beta]]  
**Artigo:** [[The_Balanced_Accuracy_and_Its_Posterior_Distribution]]  
**AplicaÃ§Ã£o:** [[AplicaÃ§Ã£o_ao_IoT_IDS]]


